{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PAGESK/Fake_news_detector/blob/main/main_fake_news_detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nature et intérêt du projet\n",
        "\n",
        "**Chaque année, le coût de la désinformation est estimé à [78 milliards de dollars](https://www.odwyerpr.com/story/public/13448/2019-11-26/cost-fake-news-78-billion.html).**\n",
        "En 2018, en analysant les tweets de 3 millions d'internautes, une étude a démontré que les fake news se propagent [6 fois plus rapidement sur X](https://pubmed.ncbi.nlm.nih.gov/29590045/) (Twitter) que les vrais articles.\n",
        "\n",
        "\n",
        "\n",
        "* À une époque où l'information n'a jamais été aussi accessible, sa qualité est menacée par la course au sensationnalisme et la rapidité des réseaux sociaux, ce qui rend de plus en plus difficile pour le public de distinguer le vrai du faux. Récemment, les IA sont arrivées sur le devant de la scène pour le public, soulevant de nouveaux enjeux, et amplifiant parfois les problématiques déjà présentes en permettant de générer un grand nombre de données, dont la véracité n'est pas toujours le premier critère.\n",
        "* Face à ce défi, le développement d'outils de détection automatisée est devenu essentiel. Cependant, ces modèles d'IA, bien que performants, sont souvent perçus comme des \"boîtes noires\" difficiles à interpréter. Ce projet vise à construire un système de détection de fake news efficace, tout en démystifiant son fonctionnement, étape par étape.\n",
        "En parcourant ce projet, n'importe qui sera capable de comprendre le fonctionnement du modèle, ses limites ainsi que les enjeux éthiques et sécuritaires dans lesquels il s'inscrit.\n"
      ],
      "metadata": {
        "id": "loGlaEYfMA1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "github_token = userdata.get('github_token')"
      ],
      "metadata": {
        "id": "fTq7rNJVrJMw"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf Fake_news_detector"
      ],
      "metadata": {
        "id": "Urh7sAiWbkOS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!git config --global user.name \"Anasviel\"\n",
        "!git config --global user.email \"kevinpages2002@gmail.com\"\n",
        "!git config --global credential.helper store"
      ],
      "metadata": {
        "id": "ihAfpzp6KTps"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://Anasviel:{github_token}@github.com/Anasviel/Fake_news_detector.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wji5Ruo3pVm_",
        "outputId": "33842c1c-f326-48e2-ee31-9f457c2efdf5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Fake_news_detector'...\n",
            "remote: Enumerating objects: 121, done.\u001b[K\n",
            "remote: Counting objects: 100% (121/121), done.\u001b[K\n",
            "remote: Compressing objects: 100% (101/101), done.\u001b[K\n",
            "remote: Total 121 (delta 61), reused 52 (delta 17), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (121/121), 4.19 MiB | 2.82 MiB/s, done.\n",
            "Resolving deltas: 100% (61/61), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Fake_news_detector/"
      ],
      "metadata": {
        "id": "1DGDDPpOLNvj",
        "outputId": "0d6c5617-0ea7-4868-be68-e85d552f94e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Fake_news_detector\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f82B7KXfcC47",
        "outputId": "0033386f-a63d-48da-b60a-549e97ab1430"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWEAtAsutRql",
        "outputId": "3813dc4f-e600-4bbf-bbcc-1c4d6dcdf3e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main 7877c5e] Pull nécessaire dû à une divergence sur github\n",
            "From https://github.com/Anasviel/Fake_news_detector\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add .\n",
        "!git commit -m\"Modification d'un article plus long et plus complet dans le df_fake_true\"\n",
        "!git push origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcC7LEEu4kjC",
        "outputId": "e0395505-b49a-4931-da21-276c97030cd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main ebadb22] Modification d'un article plus long et plus complet dans le df_fake_true\n",
            " 2 files changed, 6 insertions(+), 1 deletion(-)\n",
            " rewrite logistic_regression_pipeline.joblib (94%)\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 110.69 KiB | 10.06 MiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "remote: This repository moved. Please use the new location:\u001b[K\n",
            "remote:   https://github.com/PAGESK/Fake_news_detector.git\u001b[K\n",
            "To https://github.com/Anasviel/Fake_news_detector.git\n",
            "   c2be69a..ebadb22  main -> main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I. Construction des bases du Détecteur de Fake News"
      ],
      "metadata": {
        "id": "ZcOaCcdl-TXu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous commençons par importer les bibliothèques Python requises pour ce projet. Ces modules contiennent des fonctions et des classes prédéfinies qui nous permettent de réaliser des tâches spécifiques (comme la manipulation de données ou l'entraînement de modèles de machine learning) de manière efficace.\n",
        "\n",
        "Chaque bibliothèque (ou module) est un ensemble d'outils spécialisés. Ainsi, la bibliothèque Pandas est utilisée pour lire et organiser nos données sous forme de tableaux, tandis que Scikit-learn regroupe toutes les fonctions dont nous avons besoin pour nos algorithmes de machine learning.\n",
        "\n",
        "Cette approche nous évite de réinventer la roue pour chaque étape. C'est l'équivalent, pour un développeur, d'utiliser des outils spécialisés pour une tâche donnée plutôt que de les construire à partir de zéro."
      ],
      "metadata": {
        "id": "A_-j6Vzu-jxr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpMVp75IGdjL",
        "outputId": "37b8f3fb-3654-4121-ffdb-bdeffa55899f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lime\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/275.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from lime) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from lime) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from lime) (1.16.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from lime) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.12/dist-packages (from lime) (1.6.1)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.12/dist-packages (from lime) (0.25.2)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (11.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (2025.6.11)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.18->lime) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.18->lime) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.17.0)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283834 sha256=9d4c4bde37d2ace4ce9df7350967096fab118998cae1c5b6ecc2888681292fed\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/5d/0e/4b4fff9a47468fed5633211fb3b76d1db43fe806a17fb7486a\n",
            "Successfully built lime\n",
            "Installing collected packages: lime\n",
            "Successfully installed lime-0.2.0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "!pip install lime\n",
        "import lime\n",
        "import lime.lime_text\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 : Préparation des données, nettoyage et séparation"
      ],
      "metadata": {
        "id": "fnljWhEj8Ovh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La première étape est de préparer les données avec pandas.\n",
        "\n",
        "Le dataframe WELFake comprend 72 134 articles tous labellés ou étiquetés, vrais (1) ou faux (0). Le second dataframe df_fake_true est un tableau contenant 10 textes sélectionnés aléatoirement dans la mesure du possible, de mon côté. Une fois notre modèle entraîné sur WELFake, il donnera ses prédictions sur ces textes là afin de vérifier qu'il a bien appris.\n",
        "\n",
        "Une métaphore souvent utilisée est celle de l'élève apprenant sa leçon. Pour vérifier qu'il a appris et **compris** son contenu, on le testera sur une leçon différente de celle qu'il a révisé. Si on le teste sur la même leçon, l'élève pourrait avoir appris par coeur sa leçon sans réellement comprendre, c'est ce qu'on appelle le suraprentissage.\n",
        "\n",
        "Le but de ce df_fake_true est de tester (dans une optique de démonstration car 10 textes ne sont pas un échantillon suffisant en réalité) si le modèle est capable de transposer son apprentissage à de nouvelles données ou s'il s'avère inefficace."
      ],
      "metadata": {
        "id": "7kfA6sQjCWf8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "z35-0eHMIC-c"
      },
      "outputs": [],
      "source": [
        "df_welfake = pd.read_csv(\"/content/Fake_news_detector/WELFake_Dataset.csv\")\n",
        "df_custom = pd.read_csv(\"/content/Fake_news_detector/df_fake_true.csv\", sep=\";\")\n",
        "\n",
        "df_filtered = df_custom[df_custom[\"text\"].notnull() & df_custom[\"label\"].notnull()]\n",
        "texts_to_predict = df_filtered[\"text\"].tolist()\n",
        "true_labels = df_filtered[\"label\"].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Affichons le df welfake d'origine\n",
        "# head(10) affiche les 10 premières lignes d'un dataframe\n",
        "df_welfake.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "SddK2YqkScWx",
        "outputId": "79bf4711-caa6-42cf-9cc5-da5adfeeaa02"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                              title  \\\n",
              "0           0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...   \n",
              "1           1                                                NaN   \n",
              "2           2  UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...   \n",
              "3           3  Bobby Jindal, raised Hindu, uses story of Chri...   \n",
              "4           4  SATAN 2: Russia unvelis an image of its terrif...   \n",
              "5           5  About Time! Christian Group Sues Amazon and SP...   \n",
              "6           6  DR BEN CARSON TARGETED BY THE IRS: “I never ha...   \n",
              "7           7  HOUSE INTEL CHAIR On Trump-Russia Fake Story: ...   \n",
              "8           8  Sports Bar Owner Bans NFL Games…Will Show Only...   \n",
              "9           9  Latest Pipeline Leak Underscores Dangers Of Da...   \n",
              "\n",
              "                                                text  label  \n",
              "0  No comment is expected from Barack Obama Membe...      1  \n",
              "1     Did they post their votes for Hillary already?      1  \n",
              "2   Now, most of the demonstrators gathered last ...      1  \n",
              "3  A dozen politically active pastors came here f...      0  \n",
              "4  The RS-28 Sarmat missile, dubbed Satan 2, will...      1  \n",
              "5  All we can say on this one is it s about time ...      1  \n",
              "6  DR. BEN CARSON TELLS THE STORY OF WHAT HAPPENE...      1  \n",
              "7                                                         1  \n",
              "8  The owner of the Ringling Bar, located south o...      1  \n",
              "9  FILE – In this Sept. 15, 2005 file photo, the ...      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1264bb30-7114-4e9d-a409-ddc3ad4eb808\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>LAW ENFORCEMENT ON HIGH ALERT Following Threat...</td>\n",
              "      <td>No comment is expected from Barack Obama Membe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Did they post their votes for Hillary already?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...</td>\n",
              "      <td>Now, most of the demonstrators gathered last ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Bobby Jindal, raised Hindu, uses story of Chri...</td>\n",
              "      <td>A dozen politically active pastors came here f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>SATAN 2: Russia unvelis an image of its terrif...</td>\n",
              "      <td>The RS-28 Sarmat missile, dubbed Satan 2, will...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>About Time! Christian Group Sues Amazon and SP...</td>\n",
              "      <td>All we can say on this one is it s about time ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>DR BEN CARSON TARGETED BY THE IRS: “I never ha...</td>\n",
              "      <td>DR. BEN CARSON TELLS THE STORY OF WHAT HAPPENE...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>HOUSE INTEL CHAIR On Trump-Russia Fake Story: ...</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>Sports Bar Owner Bans NFL Games…Will Show Only...</td>\n",
              "      <td>The owner of the Ringling Bar, located south o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>Latest Pipeline Leak Underscores Dangers Of Da...</td>\n",
              "      <td>FILE – In this Sept. 15, 2005 file photo, the ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1264bb30-7114-4e9d-a409-ddc3ad4eb808')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1264bb30-7114-4e9d-a409-ddc3ad4eb808 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1264bb30-7114-4e9d-a409-ddc3ad4eb808');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-381fa5d7-76b8-4969-a57b-c34e72df2b48\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-381fa5d7-76b8-4969-a57b-c34e72df2b48')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-381fa5d7-76b8-4969-a57b-c34e72df2b48 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_welfake",
              "summary": "{\n  \"name\": \"df_welfake\",\n  \"rows\": 72134,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20823,\n        \"min\": 0,\n        \"max\": 72133,\n        \"num_unique_values\": 72134,\n        \"samples\": [\n          61370,\n          2189,\n          60609\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 62347,\n        \"samples\": [\n          \"BBC Under Fire for \\u2018Transgender Diaries\\u2019 Program Aimed at Children as Young as Six\",\n          \" Hillary\\u2019s Running Mate Tim Kaine: The NRA Hates Him, And He Kicked Their Butts (VIDEO)\",\n          \" Trump Outrageously Refers To Elizabeth Warren As \\u2018Pocahontas\\u2019 During Meeting With Senators\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 62718,\n        \"samples\": [\n          \"WASHINGTON (Reuters) - Michael Cohen, one of President Donald Trump\\u2019s closest business advisers, said on Sunday he would testify on Tuesday to the U.S. Senate Intelligence Committee, as the panel investigates alleged Russian interference in the 2016 U.S. election. The timing of Cohen\\u2019s testimony was first reported by NBC. Cohen confirmed that he would testify to the committee on Tuesday and said he did not know whether it would be in a closed session or public. Aides to the committee\\u2019s leaders did not immediately respond to requests for comment. Cohen said previously he had received a subpoena from at least one of the congressional committees investigating what U.S. intelligence has determined were Russia\\u2019s efforts to influence the election on Trump\\u2019s behalf, and whether Trump associates colluded with Russia. Russia denies such activity. The White House denies any collusion, but concerns about the issue and Trump\\u2019s ties to Russia have shadowed the first months of the Republican\\u2019s presidency. Cohen, a personal attorney to Trump, would be one of a series of close associates of the president to testify in Congress. Members of both the Senate and House of Representatives committees conducting investigations have said they expect to call more. Trump\\u2019s oldest son, Donald Trump Jr., testified to the Senate Judiciary Committee earlier this month. \",\n          \"HARARE (Reuters) - Zimbabwe s main opposition leader said on Monday President Robert Mugabe s refusal to resign had dampened people s spirits and called for an inclusive political process in the aftermath of a military intervention last week. Morgan Tsvangirai said there should be an all-stakeholders meeting to chart the country s future and that the next elections due next year should be supervised by the international community. \",\n          \"There is no word yet about whether or not the Hispanics in question were referred to by the plaintiff as  White Hispanics, (the George Zimmerman variety) Legendary restaurant Roscoe s House of Chicken  n Waffles has to cough up $1.6 million in an unlawful termination suit to an African American man who claimed he was discriminated against because he was black.The claim proves to be somewhat ironic given that the owner of the eatery, where President Barack Obama once dined when visiting Compton, is African American.CBS Los Angeles reported that Daniel Beasley sued Roscoe s for firing him after he complained to human resources that the managers harassed him for being black and gave preferential treatment, such as better work hours, to the Hispanic employees. It s owned by an African American owner, but he gives full authority to the Hispanics to run it,  Beasley told reporters.  It just caught me by surprise because here I am getting fired when I m trying to fix the problem. Beasley was frustrated that his complaints to management never got addressed, so he sued.  It s owned by an African American owner, but he gives full authority to the Hispanics to run it,  he told reporters.  It just caught me by surprise because here I am getting fired when I m trying to fix the problem. Beasley explained to CBS that he became homeless after he lost his job, so the hefty settlement becomes a huge victory for the grandfather from Compton.His lawyer Scott Cummings hopes that this win sends a message to other businesses out there.  Racism, racial harassment can occur really anywhere even in a black-owned business,  he asserted. Beasley added,  You can t treat people like that and get away with it constantly.  Via: Breitbart News\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour des raisons de clarté, nous renommons d'abord la colonne label en veracity. Cette colonne est notre variable cible (y), que nous cherchons à prédire : un article vrai (1) ou faux (0).\n",
        "\n",
        "Ensuite, nous mélangeons l'ensemble du DataFrame. La méthode sample(frac=1) sélectionne de manière aléatoire 100% des lignes, ce qui permet de réorganiser l'intégralité des données. Cette étape est cruciale pour éviter tout biais d'entraînement. En fixant le random_state à 42, nous nous assurons que ce mélange soit toujours identique, garantissant ainsi la reproductibilité de nos résultats. En modifiant la valeur 42 manuellement vous pouvez observer que le mélange sera toujours identique pour le nombre que vous fixez.\n",
        "\n",
        "Nous développerons cette notion de reproductibilité plus en détail par la suite.\n"
      ],
      "metadata": {
        "id": "JrZsyzBdS1rE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cEsQ6MnPLQEz"
      },
      "outputs": [],
      "source": [
        "df_news = df_welfake\n",
        "df_news.rename(columns={\"label\":\"veracity\"}, inplace=True)\n",
        "random_state = 42\n",
        "df_news = df_news.sample(frac=1, random_state=random_state).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "578Lm2XSLiDH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "a729cc8c-4b50-4b17-8a7e-57d8f25b522f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                              title  \\\n",
              "0       61370  ARNOLD SCHWARZENEGGER Sends A Message To Liber...   \n",
              "1        2189  WOW! “We Mexicans Need To Kill Donald Trump Be...   \n",
              "2       60609  Jimmy Carter recovers from dehydration scare i...   \n",
              "3       51565  2 Friars’ Mission: Reviving a Brooklyn Church ...   \n",
              "4       39431  Boy With Autism Makes His First Friend Ever An...   \n",
              "5       47839   Something Truly Extraordinary, And Refreshing...   \n",
              "6       42729                      #Hashtag Hell & The Fake Left   \n",
              "7       37882  Vice President-elect Pence says 'new hope dawn...   \n",
              "8       10893  Trump to Republican senators: Don't leave town...   \n",
              "9       46977  White House: Obama May Leave the Country if Tr...   \n",
              "\n",
              "                                                text  veracity  \n",
              "0                                                            1  \n",
              "1  And now a message of peace and unity from one ...         1  \n",
              "2  WINNIPEG, Manitoba (Reuters) - Former U.S. Pre...         0  \n",
              "3  The two Franciscan friars, complete with   rob...         0  \n",
              "4  Approximately 1 in 68 children has an autism s...         1  \n",
              "5  The CNN debate between Democratic candidates H...         1  \n",
              "6   By Dady Chery and Gilbert MercierAll writers ...         1  \n",
              "7  WASHINGTON (Reuters) - U.S. Vice President-ele...         0  \n",
              "8  WASHINGTON (Reuters) - U.S. President Donald T...         0  \n",
              "9  0 comments \\nThe White house is refusing to de...         1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4be3009e-104e-483c-ae96-97ae2cadbda1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>veracity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>61370</td>\n",
              "      <td>ARNOLD SCHWARZENEGGER Sends A Message To Liber...</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2189</td>\n",
              "      <td>WOW! “We Mexicans Need To Kill Donald Trump Be...</td>\n",
              "      <td>And now a message of peace and unity from one ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60609</td>\n",
              "      <td>Jimmy Carter recovers from dehydration scare i...</td>\n",
              "      <td>WINNIPEG, Manitoba (Reuters) - Former U.S. Pre...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>51565</td>\n",
              "      <td>2 Friars’ Mission: Reviving a Brooklyn Church ...</td>\n",
              "      <td>The two Franciscan friars, complete with   rob...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>39431</td>\n",
              "      <td>Boy With Autism Makes His First Friend Ever An...</td>\n",
              "      <td>Approximately 1 in 68 children has an autism s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>47839</td>\n",
              "      <td>Something Truly Extraordinary, And Refreshing...</td>\n",
              "      <td>The CNN debate between Democratic candidates H...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>42729</td>\n",
              "      <td>#Hashtag Hell &amp; The Fake Left</td>\n",
              "      <td>By Dady Chery and Gilbert MercierAll writers ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>37882</td>\n",
              "      <td>Vice President-elect Pence says 'new hope dawn...</td>\n",
              "      <td>WASHINGTON (Reuters) - U.S. Vice President-ele...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>10893</td>\n",
              "      <td>Trump to Republican senators: Don't leave town...</td>\n",
              "      <td>WASHINGTON (Reuters) - U.S. President Donald T...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>46977</td>\n",
              "      <td>White House: Obama May Leave the Country if Tr...</td>\n",
              "      <td>0 comments \\nThe White house is refusing to de...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4be3009e-104e-483c-ae96-97ae2cadbda1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4be3009e-104e-483c-ae96-97ae2cadbda1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4be3009e-104e-483c-ae96-97ae2cadbda1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4370d29f-1de4-4fa4-9e7d-cb3f7d3f4fb6\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4370d29f-1de4-4fa4-9e7d-cb3f7d3f4fb6')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4370d29f-1de4-4fa4-9e7d-cb3f7d3f4fb6 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_news",
              "summary": "{\n  \"name\": \"df_news\",\n  \"rows\": 72134,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20823,\n        \"min\": 0,\n        \"max\": 72133,\n        \"num_unique_values\": 72134,\n        \"samples\": [\n          42039,\n          18874,\n          30203\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 62347,\n        \"samples\": [\n          \" Trump Accidentally Says He Wants Single Payer In Latest Tweet \\u2013 Twitter Lets Him Know (TWEETS)\",\n          \"(VIDEO) JUDGE JEANINE: FREE SPEECH IS NON-NEGOTIABLE \\u2013 PERIOD!\",\n          \"Hispanic claims victory in Harlem race to replace Rangel in U.S. Congress\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 62718,\n        \"samples\": [\n          \"For some reason, Donald Trump decided to speak to a group of women at a women s empowerment event on Wednesday, on one of the final days of Women s History Month. It didn t go well.First he bragged about the number of women in his cabinet. There are six women. Out of 24. That s 25 percent. Less than half of what would be representative of the nation as a whole. It s also the whitest and most male cabinet since Ronald Reagan.It got worse. Trump went on to name women, famous women, although there s no indication that Trump knew why many of them were famous. The first part wasn t soooooo bad: Since the very beginning, women have driven, and I mean, each generation of Americans, towards a more free and more prosperous future,  Trump said.  These patriots are women like the legendary Abigail Adams, right? Who, during the founding, urged her husband to remember the rights of women. She was very much a pioneer in that way. We ve been blessed with courageous heroes like Harriet Tubman who escaped slavery. And went on to deliver hundreds of others to freedom, first in the underground railroad and then as a spy for the union army. She was very, very courageous, believe me. Source: Raw StoryIt very quickly became clear he was out of his intellectual element when he completed that thought with:Around we ve had leaders like Susan B. Anthony. Have you heard of Susan B. Anthony? I m shocked that you ve heard of her   who dreamed of a much more fair and equal future and an America where women themselves as she said helped to make laws and elect the lawmakers, and that s what s happening more and more. Of course, it s not shocking at all that a group of women have in fact heard of the suffragette and all around social justice warrior. There was even a coin with her face on it, but to be fair, it s doubtful Trump carries cash. Other people pay all of his bills.Trump, though, had clearly never heard of Anthony, at least before someone briefed him right before the event.Here s the video:Perhaps Trump s handlers (whoever they are) need to remind the orange dictator that he should never, ever speak to people who aren t white and male.Featured image via video screen capture\",\n          \"President-elect Donald J. Trump s economic advisor Steve Moore told Neil Cavuto the incoming administration may introduce two separate tax bills to increase chances of prompt Congressional approval. Moore says Trump s tax reform plan should primarily focus on slashing the corporate tax rate to somewhere between 15% and 20%. \",\n          \"The majestic giraffe, the world\\u2019s tallest land mammal and a prime attraction at zoos worldwide, is threatened with extinction because of illegal hunting and a loss of its habitat, according to a report published on Thursday by an international monitoring group. The giraffe population has declined by 40 percent over the past three decades and now stands at about 97, 600, according to the findings by the International Union for the Conservation of Nature, which designates endangered species. While the largest giraffe populations reside in national parks and reserves, those protected areas have proved to be inadequate, one of several alarming conclusions about the animals\\u2019 future in the group\\u2019s latest Red List of Threatened Species report. \\u201cWhile global attention has been on threats to elephants and rhinos, giraffes have been off the radar, and we\\u2019ve been losing them in significant numbers,\\u201d said Liz Bennett, the vice president for species conservation for the Wildlife Conservation Society, which was not involved in the report. \\u201cPeople and governments need to start acting to save giraffes, fast. \\u201d With their soaring heights of up to 20 feet and their stunning necks, which are typically about six feet long, giraffes have long been the stuff of dreams  \\u2014   for children who love to draw them and for adults who retain an awe for the otherworldly creatures. Their tongues can extend a foot or more, making feeding times an especially popular sight at zoos and on safari. Yet the animals\\u2019 rare size and regal visage have made them a prime target of poachers in Africa, who drop   snares from tree canopies or stalk and shoot giraffes with rifles, wildlife experts say. The threat to giraffes is so great that the Red List upgraded the species from the \\u201cleast concern\\u201d category to \\u201cvulnerable,\\u201d skipping over the intermediary \\u201c \\u201d designation. Graver categories include \\u201ccritically endangered,\\u201d \\u201cextinct in the wild\\u201d and, ultimately, \\u201cextinct. \\u201d The animals are divided into nine subspecies according to the Red List report, five have decreasing populations, three are on the increase, and one is stable. One bright spot: The numbers of West African giraffes are on the rise, numbering about 400 now, up from 50 in the 1990s. This remains the smallest of the subspecies. Asked if it was possible for giraffes to become extinct in the wild in the next 20 years if nothing is done, Derek Lee, an ecologist who contributed to the Red List report, paused for several moments during a phone interview on Thursday from Tanzania. He then said, \\u201cI think we\\u2019d see drastic declines at the very least. \\u201d Giraffes are found mostly in southern and eastern Africa, with smaller populations in West and Central Africa. Some of those populations are particularly vulnerable because of war and other civil unrest in countries on the Continent, like Sudan. Poaching and the loss of habitat are \\u201cequally dangerous threats that vary in degree from place to place,\\u201d said Dr. Lee, who is a founder of the Wild Nature Institute. While governments and organizations could take stronger actions against poaching by enforcing laws and animal protection rules, habitat loss can be harder to stop because it involves curbing economic activity, such as land development, mining and scavenging. \\u201cThese are problems everywhere for giraffes,\\u201d Dr. Lee said. \\u201cYou need to stop both threats. \\u201d The threat to giraffes is not expected to affect their numbers at zoos in New York and other cities around the world, wildlife specialists said, because zookeepers have a good record helping the animals with reproduction. Still, zoo leaders are likely to consider changing signs at their exhibits to stress the animals\\u2019 vulnerability to extinction as a way to raise public awareness. \\u201cThat would be the best way to get the word out to people that we need to do more to protect these animals,\\u201d said Dr. Bennett, of the conservation society, which runs the Bronx Zoo, the New York Aquarium and other zoos in the city.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"veracity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#Pour comparer les changements, affichons les 10 première lignes après shuffle et modification de la colonne label\n",
        "#Si tout a fonctionné correctment, la première ligne affichée contient le nom d'un célèbre bodybuilder (avec random_state=42)\n",
        "df_news.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La première étape est le prétraitement des données. Pour que notre modèle puisse interpréter et apprendre de nos textes, nous devons d'abord les nettoyer et les formater correctement. La fonction stop_words.update([ ]) contient une liste de mots que nous pourrons ajouter plus tard pour écarter d'autres mots.\n",
        "\n",
        "Les stop words, comme \"we\", \"the\" ou \"is\", sont des mots très fréquents en anglais qui n'apportent pas d'informations pertinentes pour la classification. Comme ils sont très fréquents dans tous les types de textes, le modèle ne peut pas discriminer la nature d'un texte à partir de ceux-ci. Les supprimer permet de réduire le bruit dans nos données.\n",
        "\n",
        "Nous utilisons également la lemmatisation, une technique qui consiste à réduire les mots à leur forme de base ou \"racine\". Par exemple, \"dancing\" et \"danced\" deviennent \"dance\", et \"is\" devient \"be\". Cela simplifie le vocabulaire du texte et améliore la capacité du modèle à généraliser ses apprentissages."
      ],
      "metadata": {
        "id": "sSVEdwuOVFtN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "xLkmrRXZLrSa"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words(\"english\"))\n",
        "initial_stop_words = stop_words.copy()\n",
        "stop_words.update([\"words to replace\"])\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Une étape cruciale du prétraitement des données est la création d'une fonction de nettoyage personnalisée. Le code ci-dessous définit une telle fonction, qui prépare nos textes pour l'analyse en effectuant plusieurs opérations :\n",
        "\n",
        "- Uniformiser le texte : Chaque texte est converti en minuscules pour que le modèle traite \"The\" et \"the\" comme un seul et même mot.\n",
        "\n",
        "- Gérer les nombres : Tous les chiffres sont remplacés par un token unique (_num_). Cette approche permet au modèle de reconnaître la présence d'un nombre sans se concentrer sur sa valeur exacte.\n",
        "\n",
        "- Nettoyer la ponctuation : Les caractères spéciaux et la ponctuation sont supprimés afin de ne garder que les lettres.\n",
        "\n",
        "- Lemmatisation et suppression des stop words : Le texte est tokenisé (divisé en mots). [\"Le chat mange la souris.\"] devient : [\"Le\", \"chat\", \"mange\", \"la\", \"souris\", \".\"].\n",
        "\n",
        " Puis chaque mot est ramené à sa forme de base (lemmatisation). En même temps, les stop words sont retirés.\n",
        "\n",
        "Ce code définit également une seconde fonction de nettoyage, qui effectue les mêmes étapes mais supprime complètement les nombres au lieu de les remplacer. Cette variante nous permettra de tester plus tard si la présence de chiffres améliore les prédictions du modèle ou les impacte négativement.\n",
        "\n",
        "Enfin, les deux fonctions sont encapsulées dans un FunctionTransformer. Cet outil de Scikit-learn est indispensable car il nous permet d'intégrer nos fonctions de prétraitement personnalisées directement dans le pipeline du modèle, rendant ainsi le processus plus fluide et standardisé.\n",
        "\n",
        "👉 Imaginez que nous voulions nettoyer une surface. Nous créons deux mélanges nettoyants pour supprimer les corps gras, les tâches de fruits rouges, et éliminer les bactéries. Nous ne sommes pas certain du dosage exact d'un des produits, alors nous allons définir deux mélanges identiques à l'exception de ce produit. Puis nous testerons ces deux mélanges pour voir lequel est le plus efficace, avant de l'utiliser sur la surface à nettoyer."
      ],
      "metadata": {
        "id": "SMDPcwhUY60D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "O1cSf4FUSMTc"
      },
      "outputs": [],
      "source": [
        "def clean_text_func(text):\n",
        "  if not isinstance(text, str):\n",
        "        return \"\"\n",
        "  text = text.lower()\n",
        "  text = re.sub(r'\\d+', '_num_', text)\n",
        "  text = re.sub(r'[^a-z0-9\\s_]', '', text)\n",
        "  words = nltk.word_tokenize(text)\n",
        "  words = [lemmatizer.lemmatize(word, pos='n') for word in words if word not in stop_words]\n",
        "  return ' '.join(words)\n",
        "\n",
        "def apply_clean_text(texts):\n",
        "    return [clean_text_func(text) for text in texts]\n",
        "text_cleaning_transformer = FunctionTransformer(apply_clean_text, validate=False, accept_sparse=False)\n",
        "\n",
        "\n",
        "def clean_text_no_numbers(text):\n",
        "  if not isinstance(text, str):\n",
        "        return \"\"\n",
        "  text = text.lower()\n",
        "  text = re.sub(r'\\d+', '', text)\n",
        "  text = re.sub(r'[^a-z0-9\\s_]', '', text)\n",
        "  words = nltk.word_tokenize(text)\n",
        "  words = [lemmatizer.lemmatize(word, pos='n') for word in words if word not in stop_words]\n",
        "  return ' '.join(words)\n",
        "\n",
        "def apply_clean_text_no_numbers(texts):\n",
        "    return [clean_text_no_numbers(text) for text in texts]\n",
        "text_cleaning_transformer_no_numbers = FunctionTransformer(apply_clean_text_no_numbers, validate=False, accept_sparse=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En machine learning, on distingue les données d'entrée (X ou features ou output) de la variable cible (y ou labels ou input). L'input (X) représente les données utilisées pour entraîner le modèle (dans notre cas, le texte des articles), tandis que l'output (y) est la réponse que le modèle doit apprendre à prédire (la véracité de l'article).\n",
        "\n",
        "Étant donné que notre colonne \"véracité\" est déjà entièrement étiquetée, nous disposons de la vérité terrain. Le modèle va faire ses prédictions sur ces données, et nous pourrons ensuite comparer ses réponses (y prédit) aux étiquettes réelles (y réel) pour évaluer sa performance.\n",
        "\n",
        "On parle d'apprentissage supervisé car les labels sont déjà connues. C'est la méthode que nous utilisons pour notre détecteur de fausses nouvelles. Il existe d'autres types d'apprentissage mais nous nous concentrerons exclusivement sur l'apprentissage supervisé pour notre détecteur de fake news."
      ],
      "metadata": {
        "id": "9in5Y1L6C0YS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "uVgG_L3dS2-y"
      },
      "outputs": [],
      "source": [
        "X = df_news[\"text\"]\n",
        "y = df_news[\"veracity\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous utilisons la fonction train_test_split de la bibliothèque Scikit-learn pour diviser notre jeu de données en deux parties :\n",
        "\n",
        "Un ensemble d'entraînement (X_train, y_train), sur lequel le modèle apprendra à faire le lien entre le texte et la véracité.\n",
        "\n",
        "Un ensemble de test (X_test, y_test), qui sera utilisé pour évaluer la performance du modèle sur des données qu'il n'a jamais vues.\n",
        "\n",
        "Cette approche est essentielle pour éviter le surapprentissage. C'est comme si, pour un ensemble de 10 exercices de mathématiques, on donnait à un élève 8 exercices avec le corrigé pour ses révisions, puis qu'on l'évaluait sur les 2 exercices restants, sans lui fournir le corrigé cette fois.\n",
        "\n",
        "Analyse des ensembles de données\n",
        "La commande .shape permet de vérifier les dimensions de nos jeux de données. Nous pouvons ainsi confirmer que l'ensemble de test (X_test) représente bien 20% des données (comme spécifié par l'argument test_size=0.2), tandis que 80% sont alloués à l'entraînement.\n",
        "\n",
        "L'argument stratify=y est crucial : il garantit que la répartition des labels (la proportion d'articles vrais et faux) est la même dans l'ensemble d'entraînement et de test. Cela assure que notre modèle n'est pas biaisé et que l'évaluation est juste. Comme le montrent les résultats ci-dessous, la distribution des labels 0 et 1 est relativement équilibrée et cohérente entre les deux ensembles."
      ],
      "metadata": {
        "id": "Uf_6NiXnLsEf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "2hRdyexRHNkO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db18fac4-3e69-4d67-9de2-e04f29bb554d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original data shape : (72134,)\n",
            "Training data shape : (57707,)\n",
            "Testing data shape : (14427,) \n",
            "\n",
            "Training labels distribution: \n",
            " veracity\n",
            "1    29685\n",
            "0    28022\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Testing labels distribution: \n",
            " veracity\n",
            "1    7421\n",
            "0    7006\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "print(f\"Original data shape : {X.shape}\")\n",
        "print(f\"Training data shape : {X_train.shape}\")\n",
        "print(f\"Testing data shape : {X_test.shape} \\n\")\n",
        "print(f\"Training labels distribution: \\n {y_train.value_counts()}\\n\")\n",
        "print(f\"Testing labels distribution: \\n {y_test.value_counts()}\")\n",
        "\n",
        "df_news[\"text\"] = df_news[\"text\"].fillna('')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tout au long de ce notebook, trois modèles différents seront mentionnés. Nous travaillerons principalement avec un seul de ces trois, mais si vous désirez comprendre leurs spécificités, cette fiche explicative est faite pour vous :\n",
        "\n",
        "## 2 : Fiche explicative des trois modèles 📄\n",
        "**1. MultinomialNB (Naïve Bayes multinomial)**\n",
        "\n",
        "C’est l’algorithme le plus « simple » des trois.\n",
        "Il repose sur une hypothèse forte : les mots d’un texte sont indépendants les uns des autres.\n",
        "Pour chaque classe (vrai / faux), le modèle calcule la probabilité de chaque mot d’appartenir à cette classe.\n",
        "Pour prédire la classe d’un texte, il additionne ces probabilités (ou plus exactement les log-probabilités) pour chaque mot, puis choisit la classe la plus probable.\n",
        "\n",
        "- Avantages : rapide, facile à comprendre, fonctionne bien avec des données textuelles simples.\n",
        "- Limites : l’hypothèse d’indépendance est rarement vraie et peut ignorer des relations importantes entre les mots.\n",
        "\n",
        "**2. Logistic Regression**\n",
        "\n",
        "La régression logistique attribue un poids à chaque mot, reflétant son influence sur la probabilité qu’un texte appartienne à la classe vrai ou faux.\n",
        "Elle combine ensuite ces poids pour calculer directement la probabilité de chaque classe pour un texte donné.\n",
        "\n",
        "Différence clé avec Naïve Bayes :\n",
        "\n",
        "- Avantages : rapide à entraîner, robuste, fonctionne bien sur du texte\n",
        "- Inconvénients : suppose que la relation est linéaire, peut manquer des relations plus complexes\n",
        "\n",
        "Naïve Bayes part de la classe et estime la probabilité des mots (P(mots | classe)). On dit \"Quelle est la probabilité de trouver ce mot, sachant la probabilité de cette classe ?\"\n",
        "\n",
        "La régression logistique estime directement la probabilité de la classe à partir des mots (P(classe | mots)) : \"Quelle est la probabilité de cette classe, sachant ce mot ?\"\n",
        "\n",
        "**Métaphore :** si ces modèles étaient des détectives,\n",
        "\n",
        "Naïve Bayes additionnerait les probabilités de chaque indice indépendamment.\n",
        "\n",
        "Régression logistique analyserait le poids combiné de tous les indices pour décider du verdict.\n",
        "\n",
        "**3. LinearSVC (Linear Support Vector Machine)**\n",
        "\n",
        "LinearSVC cherche également à séparer les textes vrais des textes faux, mais sa stratégie est différente.\n",
        "Il trace une frontière de décision (hyperplan) dans un espace à plusieurs dimensions (une dimension par mot), de manière à maximiser la marge entre cette frontière et les textes les plus proches (appelés vecteurs de support).\n",
        "\n",
        "- Avantages : robuste aux données bruitées, efficace pour des jeux de données complexes.\n",
        "- Limites : ne donne pas directement de probabilités, nécessite un réglage attentif des hyperparamètres et plus long à entraîner."
      ],
      "metadata": {
        "id": "2-K9RpumNyGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Note : Ce code n'est pas nécessaire au fonctionnement du modèle. Il sert à afficher les graphiques pour mieux visualier le fonctionnement de nos trois algorithmes.\n",
        "#Par défaut, la cellule ne s'exécute pas pour permettre un parcours plus efficace du notebook,\n",
        "#Si vous souhaitez tout de même lancer le code, retirer la ligne bleue : %%script echo skip.\n",
        "#Pensez à réécrire la ligne une fois le code exécuté, sinon cette cellule de code optionnelle s'exécutera inutilement à chaque lancement du notebook.\n",
        "\n",
        "random_state = 42\n",
        "models = [\n",
        "    (\"MultinomialNB\", MultinomialNB(alpha=1, fit_prior=False, class_prior=[0.5, 0.5])),\n",
        "    (\"Logistic Regression\", LogisticRegression(C=0.1, max_iter=1000, random_state=random_state, solver=\"liblinear\")),\n",
        "    (\"LinearSVC\", LinearSVC(C=0.1, max_iter=1000, random_state=random_state))\n",
        "]\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "for ax, (name, clf) in zip(axes, models):\n",
        "    pipeline = Pipeline([\n",
        "        (\"cleaner\", text_cleaning_transformer),\n",
        "        (\"tfidf\", TfidfVectorizer(max_features=1000, ngram_range=(1,1))),\n",
        "        (\"classifier\", clf)\n",
        "    ])\n",
        "\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    vectorizer = pipeline.named_steps[\"tfidf\"]\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "    if name == \"MultinomialNB\":\n",
        "        log_prob_fake = clf.feature_log_prob_[0]\n",
        "        log_prob_true = clf.feature_log_prob_[1]\n",
        "        scores = log_prob_true - log_prob_fake\n",
        "    else:\n",
        "        scores = pipeline.named_steps[\"classifier\"].coef_[0]\n",
        "\n",
        "    df_scores = pd.DataFrame({\"word\": feature_names, \"score\": scores})\n",
        "    top_words = pd.concat([df_scores.nsmallest(10, \"score\"), df_scores.nlargest(10, \"score\")]).sort_values(by=\"score\")\n",
        "\n",
        "    colors = [\"red\" if s < 0 else \"green\" for s in top_words[\"score\"]]\n",
        "    ax.barh(top_words[\"word\"], top_words[\"score\"], color=colors)\n",
        "    ax.set_title(name, fontsize=14)\n",
        "    ax.set_xlabel(\"Score / Poids\")\n",
        "    ax.axvline(0, color=\"black\", linewidth=0.8)\n",
        "\n",
        "fig.suptitle(\"Mots les plus influents par algorithme\", fontsize=18)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "id": "pz-XXZuvTmgV",
        "outputId": "ec087ffe-8cb1-4e2c-d097-cfbc0819b93e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2144544176.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     ])\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tfidf\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0mrouted_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_method_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrouted_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pipeline\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, routed_params, raw_params)\u001b[0m\n\u001b[1;32m    586\u001b[0m             )\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[1;32m    589\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[1;32m   1549\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m             res = transformer.fit(X, y, **params.get(\"fit\", {})).transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    919\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/preprocessing/_function_transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \"\"\"\n\u001b[1;32m    259\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkw_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m         \u001b[0moutput_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_output_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"transform\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dense\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/preprocessing/_function_transformer.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, X, func, kw_args)\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_identity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkw_args\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkw_args\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__sklearn_is_fitted__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3493367763.py\u001b[0m in \u001b[0;36mapply_clean_text\u001b[0;34m(texts)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapply_clean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclean_text_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mtext_cleaning_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapply_clean_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3493367763.py\u001b[0m in \u001b[0;36mclean_text_func\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\d+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_num_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'[^a-z0-9\\s_]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/re/__init__.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[0;32m--> 186\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x600 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 : Visualisation des résultats des modèles"
      ],
      "metadata": {
        "id": "h6Sp7fwFZZs_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Graphique MultinomialNB :**\n",
        "\n",
        "On observe ici le fonctionnement du modèle MultinomialNB, qui attribue à chaque mot de notre corpus un score de probabilité logarithmique. On peut voir ce score comme une empreinte numérique indiquant à quel point un mot est \"typique\" d’une classe donnée (vrai ou faux article).\n",
        "\n",
        "En calculant la différence entre ces scores pour les deux classes, on met en évidence les mots les plus discriminants. Ces mots jouent un rôle semblable à celui d’indices dans une enquête policière : certains sont anodins, d’autres permettent de résoudre l’énigme presque à eux seuls.\n",
        "\n",
        "On note par exemple la présence de termes très prédictifs comme \"reuters\", qui trahissent une fuite de données (data leakage). Le modèle utilise ici des indices qu’il n’aurait pas dû avoir à disposition pour prédire la classe, ce qui menace sa capacité à généraliser à de nouvelles données. Nous verrons plus loin comment corriger ce biais.\n",
        "\n",
        "**Graphique Logistic Regression :**\n",
        "\n",
        "Dans ce graphique, le modèle de régression logisitique utilise un autre mécanisme : il assigne un poids (ou coefficient) à chaque mot, plutôt qu’un score probabiliste. On peut l’imaginer comme un système de balance : les mots à poids élevé penchent fortement la prédiction vers une classe donnée.\n",
        "\n",
        "On constate que les mots jugés les plus prédictifs ne sont pas exactement les mêmes que pour MultinomialNB, ce qui illustre la différence de fonctionnement entre les deux modèles. Pourtant, les termes en tête, tels que \"reuters\", \"via\" et \"image\", sont identiques à ceux du modèle précédent et affichent un poids bien supérieur aux autres.\n",
        "\n",
        "Cela renforce l’hypothèse d’un data leakage : ces termes ne font pas partie du contenu sémantique de l’article, mais sont des métadonnées (indices liés à la source ou au format). Un modèle qui fonctionne ainsi ne distingue pas vraiment le vrai du faux sur le fond, mais sur la forme.\n",
        "\n",
        "Cette stratégie peut donner d’excellents résultats sur un jeu de données comme WELFake, mais elle échouera face à de nouveaux articles plus variés.\n",
        "\n",
        "**Graphique LinearSVC :**\n",
        "\n",
        "Enfin, pour LinearSVC, on observe la même tendance : malgré des différences internes dans leur mécanique, les trois classifieurs (MultinomialNB, Logistic Regression, LinearSVC) placent étonnamment les mêmes mots au sommet : \"reuters\", \"via\", \"image\".\n",
        "\n",
        "Ces termes sont des marqueurs externes, pas du contenu. Leur forte corrélation avec les étiquettes de classe agit comme une marque invisible qui oriente directement la prédiction.\n",
        "\n",
        "Ce phénomène, appelé surapprentissage (overfitting), donne l’illusion d’un modèle performant : il brille sur l’entraînement, mais se révèle fragile face à l’inconnu. Tant que ce data leakage n’est pas corrigé, il est impossible de juger de la véritable efficacité de nos modèles."
      ],
      "metadata": {
        "id": "_fa8cVRlYOPN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# II. Première implémentation de notre Détecteur de Fake News   "
      ],
      "metadata": {
        "id": "B2Yix5-0M8jy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous allons procéder en plusieurs étapes :    \n",
        "\n",
        "\n",
        "*   1. Explication synthétique du fonctionnement du code (Logistic Regression)\n",
        "*   2. Exécution du code et observation de ses prédictions\n",
        "*   3. Résolution du problème de data leakage\n",
        "*   4. Nouvelle évaluation du modèle\n",
        "*   5. Améliorations\n",
        "\n",
        "\n",
        "## 1 : Explication synthétique du fonctionnement du code (Logistic Regression)\n",
        "\n",
        "Habituellement, après avoir nettoyé le texte, il est vectorisé puis le modèle est entraîné et évalué. La cellule de code optionnelle ci-dessus a déjà utilisé trois modèles afin d'illustrer leurs différences graphiquement. Ces graphiques nous ont aussi permis de mettre en évidence un problème important : le data leakage (fuite de données). Abstraction faite de cette cellule de code, revenons sur l'architecture logique de notre modèle en suivant l'ordre :\n",
        "\n",
        "nettoyage ✅ --> vectorisation ✅ --> entraînement ⏳ (nous allons entamer cette étape) --> évaluation ⏳\n",
        "\n",
        "\n",
        "**Le pipeline : Un processus en chaîne** ⛓\n",
        "\n",
        "Imaginez que la préparation et l'entraînement de votre modèle soient une chaîne de montage. Un pipeline est un outil qui vous permet d'assembler toutes les étapes de cette chaîne en une seule séquence logique, de l'entrée à la sortie.\n",
        "\n",
        "Votre pipeline est composé de trois étapes qui s'exécutent automatiquement dans l'ordre, chacune passant son résultat à la suivante :\n",
        "\n",
        "(\"cleaner\", text_cleaning_transformer) : La phase de nettoyage\n",
        "\n",
        "Cette première étape prend les textes bruts de vos articles. Elle les fait passer par notre fonction de nettoyage personnalisée définie plus haut (text_cleaning_transformer), qui se charge de les uniformiser, de supprimer la ponctuation et les mots non pertinents, et de les lemmatiser.\n",
        "\n",
        "Le texte ressort de cette étape propre et prêt à être analysé.\n",
        "\n",
        "(\"tfidf\", TfidfVectorizer()) : La phase de vectorisation\n",
        "\n",
        "Les modèles de machine learning ne comprennent pas le texte, ils travaillent avec des nombres. Chaque mot sera transformé en une suite de nombres. Cette étape utilise le TfidfVectorizer pour convertir chaque texte nettoyé en un tableau de nombres.\n",
        "\n",
        "Le TF-IDF (Text Frequency - Inverse Document Frequency) est une méthode puissante qui attribue un score à chaque mot en fonction de son importance dans le document et dans l'ensemble du jeu de données. Plus le mot est présent dans un document et rare dans l'ensemble du corpus, plus le mot aura un poids important pour le modèle. Inversement, les mots fréquents dans le corpus ont un poids faible.\n",
        "\n",
        "(\"classifier\", MultinomialNB()) : La phase d'entraînement\n",
        "\n",
        "Le tableau de nombres généré par l'étape précédente est transmis à l'algorithme de classification.\n",
        "\n",
        "Ici, la régression logistique est le \"cerveau\" de votre pipeline. C'est un algorithme simple, mais très efficace pour des tâches de classification de texte comme la détection de fake news. Il apprend à prédire la véracité d'un article à partir des scores TF-IDF.\n",
        "\n",
        "L'un des grands avantages du pipeline est qu'il permet de changer facilement d'algorithme de classification (par exemple, LinearSVC ou Logistic Regression). Cette flexibilité nous permettra de tester automatiquement différentes configurations pour notre modèle et de conserver la plus optimale, une étape que nous aborderons prochainement.\n",
        "\n"
      ],
      "metadata": {
        "id": "NBzv8h2TmIuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Exécutez cette cellule et les deux suivantes pour observer les prédictions du modèle \"brut\"\n",
        "\n",
        "random_state = 42\n",
        "\n",
        "logistic_regression_pipeline = Pipeline([\n",
        "    (\"cleaner\", text_cleaning_transformer),\n",
        "\n",
        "    #max_features représente le nombre de mots que le modèle doit apprendre. Plus le nombre est élevé plus le modèle pourra saisir des relations complexes, mais plus il risque le surapprentissage.\n",
        "    #ngram_range indique combien de mots successifs le modèle doit apprendre (1, 2 ou plus). Ce paramètre permet lui aussi de saisir des relations plus complexes et peut augmenter le surapprentissage\n",
        "    (\"tfidf\", TfidfVectorizer(max_features=5000, ngram_range=(1,2))),\n",
        "\n",
        "    #Ici, la valeur de C oblige le modèle à choisir des coefficients plus petits et réduire le surapprentissage\n",
        "    #random_state sert à fixer le pseudo-aléatoire du modèle et ainsi obtenir toujours les mêmes résultats\n",
        "    #class_weight pénalise plus les erreurs de prédictions sur la classe minoritaire pour éviter que le modèle prédise plus la classe majoritaire\n",
        "    (\"classifier\", LogisticRegression(C=1, max_iter=1000, random_state=random_state, solver=\"liblinear\", class_weight=\"balanced\"))\n",
        "])"
      ],
      "metadata": {
        "id": "_WrVtm1jmHMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 : Exécution du code et observation de ses prédictions"
      ],
      "metadata": {
        "id": "NaNOoFKRo-Yd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Exécutez cette cellule et la suivante pour observer les résultats du modèle \"brut\"\n",
        "\n",
        "#L'entrainement du modèle prendra quelques minutes (5 environ).\n",
        "#Si l'exécution est vraiment trop longue ou que vous rencontrer un problème, relancez la cellule. Si cela ne fonctionne pas, relancez le notebook.\n",
        "\n",
        "#NB : Les prints() ne sont pas nécessaires au code,\n",
        "#ils affichent seulement le message ou le code contenu entre parenthèse pour un meilleur suivi dans la console\n",
        "\n",
        "print(\"\\n---Entrainement du modèle Logistic Regression---\")\n",
        "\n",
        "#Cette ligne aussi courte soit-elle est la pierre angulaire du modèle.\n",
        "#C'est ici qu'il s'entraîne sur le dataset WELFake en comparant les articles avec leurs labels, il apprend les mots les plus prédictifs de chaque classe.\n",
        "logistic_regression_pipeline.fit(X_train, y_train)\n",
        "print(\"Modèle Logistic Regression entraîné\")\n",
        "\n",
        "\n",
        "#Le modèle effectue ses prédictions sur le set de test (les 20% d'articles non vus lors de l'entraînement). C'est ici qu'il prédit si le texte est vrai ou faux.\n",
        "y_pred_test = logistic_regression_pipeline.predict(X_test)\n",
        "\n",
        "#Le modèle donne un seuil de confiance en probabilité pour chacune de ses prédictions.\n",
        "y_proba_test = logistic_regression_pipeline.predict_proba(X_test)\n",
        "\n",
        "\n",
        "print(f\"\\n---Performance du modèle sur le test set sans ajout des stop_words\")\n",
        "\n",
        "#Notre algorithme compare les y_test (les vrais labels par ex : [0, 1, 0, 0, 0, 1...] aux y_pred_test (soit les labels prédits par le modèle par ex : [0, 1, 0, 0, 0, 0...] ))\n",
        "#Il se corrige seul, comme un élève à qui l'on donnerait la correction après l'examen, pour comparer ses réponses avec le corrigé. L'accuracy (ou précision) calculée représente le nombre de prédictions correctes divisé par le nombre total de labels.\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_test):.2f}\")\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "\n",
        "#La ligne ci-dessous permet d'afficher un \"rapport\" contenant la précision, et le recall (rappel). Le rappel représente le nombre de réponses correctes que le modèle a trouvées pour une classe donnée,\n",
        "# divisé par le nombre total de réponses qui étaient réellement correctes pour cette classe.\n",
        "print(classification_report(y_test, y_pred_test, target_names=[\"Fake News\", \"True News\"]))\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "\n",
        "\n",
        "#La matrice de confusion est un tableau à deux entrées qui compare les labels aux prédictions du modèle. On rencence les vrais négatifs, les faux positifs, les faux négatifs et les vrais positifs.\n",
        "#On parle aussi de correct rejection, false alarm, miss, et hit.\n",
        "print(confusion_matrix(y_test, y_pred_test))\n",
        "\n",
        "\n",
        "\n",
        "#On utilise ces lignes de code pour récupérer les 60 mots les plus influents pour le modèle.\n",
        "#Cela nous permettra d'avoir un aperçut correct des mots à supprimer ensuite\n",
        "tfidf_vectorizer = logistic_regression_pipeline.named_steps[\"tfidf\"]\n",
        "classifier = logistic_regression_pipeline.named_steps[\"classifier\"]\n",
        "\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "coefs = classifier.coef_[0]\n",
        "\n",
        "df_words = pd.DataFrame({\"word\":feature_names, \"score\":coefs})\n",
        "df_words = df_words.sort_values(by=\"score\", ascending=False)\n",
        "\n",
        "top_true_words = df_words.head(30)\n",
        "top_fake_words = df_words.tail(30)\n",
        "\n",
        "df_top_words = pd.concat([top_fake_words, top_true_words]).sort_values(by=\"score\")\n",
        "\n",
        "df_top_words[\"prédicteur\"] = np.where(df_top_words[\"score\"] > 0, \"prédicteur de vrai article\", \"prédicteur de faux article\")\n",
        "\n",
        "df_top_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qQHoxtwKm29v",
        "outputId": "7d37fbbf-447b-4df5-8ebe-60fe1cb07069"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---Entrainement du modèle Logistic Regression---\n",
            "Modèle Logistic Regression entraîné\n",
            "\n",
            "---Performance du modèle sur le test set sans ajout des stop_words\n",
            "Accuracy: 0.95\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Fake News       0.95      0.95      0.95      7006\n",
            "   True News       0.95      0.95      0.95      7421\n",
            "\n",
            "    accuracy                           0.95     14427\n",
            "   macro avg       0.95      0.95      0.95     14427\n",
            "weighted avg       0.95      0.95      0.95     14427\n",
            "\n",
            "Confusion Matrix:\n",
            "[[6627  379]\n",
            " [ 349 7072]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    word      score                  prédicteur\n",
              "3759             reuters -25.810711  prédicteur de faux article\n",
              "3853                said -13.745006  prédicteur de faux article\n",
              "1783              follow -10.642283  prédicteur de faux article\n",
              "4657             twitter  -9.009893  prédicteur de faux article\n",
              "4841  washington reuters  -8.621352  prédicteur de faux article\n",
              "3375    president donald  -8.511300  prédicteur de faux article\n",
              "864                  com  -7.688359  prédicteur de faux article\n",
              "1355                dont  -6.087939  prédicteur de faux article\n",
              "4467               thats  -5.537480  prédicteur de faux article\n",
              "3028              obamas  -5.243709  prédicteur de faux article\n",
              "3264         pic twitter  -5.170396  prédicteur de faux article\n",
              "1276               didnt  -5.112724  prédicteur de faux article\n",
              "4472               there  -5.057216  prédicteur de faux article\n",
              "2880                  mr  -5.033035  prédicteur de faux article\n",
              "2032                  he  -5.006892  prédicteur de faux article\n",
              "4505            thursday  -4.888430  prédicteur de faux article\n",
              "588      breitbart texas  -4.810182  prédicteur de faux article\n",
              "2181                  im  -4.802096  prédicteur de faux article\n",
              "1850              friday  -4.765643  prédicteur de faux article\n",
              "4644             tuesday  -4.682629  prédicteur de faux article\n",
              "4335              sunday  -4.662987  prédicteur de faux article\n",
              "2846              monday  -4.566343  prédicteur de faux article\n",
              "4477              theyre  -4.442361  prédicteur de faux article\n",
              "3263                 pic  -4.354327  prédicteur de faux article\n",
              "586            breitbart  -4.218722  prédicteur de faux article\n",
              "4861           wednesday  -4.114933  prédicteur de faux article\n",
              "2804                milo  -3.969329  prédicteur de faux article\n",
              "2331       islamic state  -3.751137  prédicteur de faux article\n",
              "1784      follow twitter  -3.729568  prédicteur de faux article\n",
              "4923              womens  -3.702977  prédicteur de faux article\n",
              "233              america   2.732090  prédicteur de vrai article\n",
              "277               anyone   2.803352  prédicteur de vrai article\n",
              "3380     president trump   2.839095  prédicteur de vrai article\n",
              "2141             however   2.885535  prédicteur de vrai article\n",
              "3830                  rt   2.924919  prédicteur de vrai article\n",
              "4523               today   2.960062  prédicteur de vrai article\n",
              "723         century wire   3.153753  prédicteur de vrai article\n",
              "4910                wire   3.238696  prédicteur de vrai article\n",
              "4146              source   3.298266  prédicteur de vrai article\n",
              "1684                 fbi   3.307834  prédicteur de vrai article\n",
              "4672                  uk   3.329160  prédicteur de vrai article\n",
              "1135                  dc   3.354484  prédicteur de vrai article\n",
              "1350              donate   3.406064  prédicteur de vrai article\n",
              "2454                know   3.433735  prédicteur de vrai article\n",
              "3290              please   3.444630  prédicteur de vrai article\n",
              "4025               share   3.692985  prédicteur de vrai article\n",
              "58              _num_the   3.813054  prédicteur de vrai article\n",
              "62          _num_yearold   4.039455  prédicteur de vrai article\n",
              "1518              entire   4.270647  prédicteur de vrai article\n",
              "3010            november   4.531253  prédicteur de vrai article\n",
              "50       _num__num__num_   5.031178  prédicteur de vrai article\n",
              "3024               obama   5.649007  prédicteur de vrai article\n",
              "42            _num__num_   5.698836  prédicteur de vrai article\n",
              "3049             october   6.031343  prédicteur de vrai article\n",
              "2079             hillary   6.943174  prédicteur de vrai article\n",
              "2184           image via   7.234105  prédicteur de vrai article\n",
              "3050       october _num_   7.458940  prédicteur de vrai article\n",
              "3011      november _num_   8.007087  prédicteur de vrai article\n",
              "2183               image   8.809948  prédicteur de vrai article\n",
              "4761                 via  14.756388  prédicteur de vrai article"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-02a16db4-09b9-42ff-ad1d-01af2776eb20\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>score</th>\n",
              "      <th>prédicteur</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3759</th>\n",
              "      <td>reuters</td>\n",
              "      <td>-25.810711</td>\n",
              "      <td>prédicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3853</th>\n",
              "      <td>said</td>\n",
              "      <td>-13.745006</td>\n",
              "      <td>prédicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1783</th>\n",
              "      <td>follow</td>\n",
              "      <td>-10.642283</td>\n",
              "      <td>prédicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4657</th>\n",
              "      <td>twitter</td>\n",
              "      <td>-9.009893</td>\n",
              "      <td>prédicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4841</th>\n",
              "      <td>washington reuters</td>\n",
              "      <td>-8.621352</td>\n",
              "      <td>prédicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3375</th>\n",
              "      <td>president donald</td>\n",
              "      <td>-8.511300</td>\n",
              "      <td>prédicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>864</th>\n",
              "      <td>com</td>\n",
              "      <td>-7.688359</td>\n",
              "      <td>prédicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1355</th>\n",
              "      <td>dont</td>\n",
              "      <td>-6.087939</td>\n",
              "      <td>prédicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4467</th>\n",
              "      <td>thats</td>\n",
              "      <td>-5.537480</td>\n",
              "      <td>prédicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3028</th>\n",
              "      <td>obamas</td>\n",
              "      <td>-5.243709</td>\n",
              "      <td>prédicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3264</th>\n",
              "      <td>pic twitter</td>\n",
              "      <td>-5.170396</td>\n",
              "      <td>prédicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1276</th>\n",
              "      <td>didnt</td>\n",
              "      <td>-5.112724</td>\n",
              "      <td>prédicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4472</th>\n",
              "      <td>there</td>\n",
              "      <td>-5.057216</td>\n",
              "      <td>prédicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2880</th>\n",
              "      <td>mr</td>\n",
              "      <td>-5.033035</td>\n",
              "      <td>prédicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2032</th>\n",
              "      <td>he</td>\n",
              "      <td>-5.006892</td>\n",
              "      <td>prédicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4505</th>\n",
              "      <td>thursday</td>\n",
              "      <td>-4.888430</td>\n",
              "      <td>prédicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>588</th>\n",
              "      <td>breitbart texas</td>\n",
              "      <td>-4.810182</td>\n",
              "      <td>prédicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2181</th>\n",
              "      <td>im</td>\n",
              "      <td>-4.802096</td>\n",
              "      <td>prédicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1850</th>\n",
              "      <td>friday</td>\n",
              "      <td>-4.765643</td>\n",
              "      <td>prédicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4644</th>\n",
              "      <td>tuesday</td>\n",
              "      <td>-4.682629</td>\n",
              "      <td>prédicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4335</th>\n",
              "      <td>sunday</td>\n",
              "      <td>-4.662987</td>\n",
              "      <td>prédicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2846</th>\n",
              "      <td>monday</td>\n",
              "      <td>-4.566343</td>\n",
              "      <td>prédicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4477</th>\n",
              "      <td>theyre</td>\n",
              "      <td>-4.442361</td>\n",
              "      <td>prédicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3263</th>\n",
              "      <td>pic</td>\n",
              "      <td>-4.354327</td>\n",
              "      <td>prédicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>586</th>\n",
              "      <td>breitbart</td>\n",
              "      <td>-4.218722</td>\n",
              "      <td>prédicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4861</th>\n",
              "      <td>wednesday</td>\n",
              "      <td>-4.114933</td>\n",
              "      <td>prédicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2804</th>\n",
              "      <td>milo</td>\n",
              "      <td>-3.969329</td>\n",
              "      <td>prédicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2331</th>\n",
              "      <td>islamic state</td>\n",
              "      <td>-3.751137</td>\n",
              "      <td>prédicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1784</th>\n",
              "      <td>follow twitter</td>\n",
              "      <td>-3.729568</td>\n",
              "      <td>prédicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4923</th>\n",
              "      <td>womens</td>\n",
              "      <td>-3.702977</td>\n",
              "      <td>prédicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>america</td>\n",
              "      <td>2.732090</td>\n",
              "      <td>prédicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>277</th>\n",
              "      <td>anyone</td>\n",
              "      <td>2.803352</td>\n",
              "      <td>prédicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3380</th>\n",
              "      <td>president trump</td>\n",
              "      <td>2.839095</td>\n",
              "      <td>prédicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2141</th>\n",
              "      <td>however</td>\n",
              "      <td>2.885535</td>\n",
              "      <td>prédicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3830</th>\n",
              "      <td>rt</td>\n",
              "      <td>2.924919</td>\n",
              "      <td>prédicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4523</th>\n",
              "      <td>today</td>\n",
              "      <td>2.960062</td>\n",
              "      <td>prédicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>723</th>\n",
              "      <td>century wire</td>\n",
              "      <td>3.153753</td>\n",
              "      <td>prédicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4910</th>\n",
              "      <td>wire</td>\n",
              "      <td>3.238696</td>\n",
              "      <td>prédicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4146</th>\n",
              "      <td>source</td>\n",
              "      <td>3.298266</td>\n",
              "      <td>prédicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1684</th>\n",
              "      <td>fbi</td>\n",
              "      <td>3.307834</td>\n",
              "      <td>prédicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4672</th>\n",
              "      <td>uk</td>\n",
              "      <td>3.329160</td>\n",
              "      <td>prédicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1135</th>\n",
              "      <td>dc</td>\n",
              "      <td>3.354484</td>\n",
              "      <td>prédicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1350</th>\n",
              "      <td>donate</td>\n",
              "      <td>3.406064</td>\n",
              "      <td>prédicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2454</th>\n",
              "      <td>know</td>\n",
              "      <td>3.433735</td>\n",
              "      <td>prédicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3290</th>\n",
              "      <td>please</td>\n",
              "      <td>3.444630</td>\n",
              "      <td>prédicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4025</th>\n",
              "      <td>share</td>\n",
              "      <td>3.692985</td>\n",
              "      <td>prédicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>_num_the</td>\n",
              "      <td>3.813054</td>\n",
              "      <td>prédicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>_num_yearold</td>\n",
              "      <td>4.039455</td>\n",
              "      <td>prédicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1518</th>\n",
              "      <td>entire</td>\n",
              "      <td>4.270647</td>\n",
              "      <td>prédicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3010</th>\n",
              "      <td>november</td>\n",
              "      <td>4.531253</td>\n",
              "      <td>prédicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>_num__num__num_</td>\n",
              "      <td>5.031178</td>\n",
              "      <td>prédicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3024</th>\n",
              "      <td>obama</td>\n",
              "      <td>5.649007</td>\n",
              "      <td>prédicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>_num__num_</td>\n",
              "      <td>5.698836</td>\n",
              "      <td>prédicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3049</th>\n",
              "      <td>october</td>\n",
              "      <td>6.031343</td>\n",
              "      <td>prédicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2079</th>\n",
              "      <td>hillary</td>\n",
              "      <td>6.943174</td>\n",
              "      <td>prédicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2184</th>\n",
              "      <td>image via</td>\n",
              "      <td>7.234105</td>\n",
              "      <td>prédicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3050</th>\n",
              "      <td>october _num_</td>\n",
              "      <td>7.458940</td>\n",
              "      <td>prédicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3011</th>\n",
              "      <td>november _num_</td>\n",
              "      <td>8.007087</td>\n",
              "      <td>prédicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2183</th>\n",
              "      <td>image</td>\n",
              "      <td>8.809948</td>\n",
              "      <td>prédicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4761</th>\n",
              "      <td>via</td>\n",
              "      <td>14.756388</td>\n",
              "      <td>prédicteur de vrai article</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02a16db4-09b9-42ff-ad1d-01af2776eb20')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-02a16db4-09b9-42ff-ad1d-01af2776eb20 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-02a16db4-09b9-42ff-ad1d-01af2776eb20');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0a6460dd-e1bd-44de-95a4-d369bd958b4d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0a6460dd-e1bd-44de-95a4-d369bd958b4d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0a6460dd-e1bd-44de-95a4-d369bd958b4d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_d8cf18e3-813c-4aab-9769-7a4ec082db2f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_top_words')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d8cf18e3-813c-4aab-9769-7a4ec082db2f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_top_words');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_top_words",
              "summary": "{\n  \"name\": \"df_top_words\",\n  \"rows\": 60,\n  \"fields\": [\n    {\n      \"column\": \"word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 60,\n        \"samples\": [\n          \"reuters\",\n          \"president donald\",\n          \"century wire\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.641061492658534,\n        \"min\": -25.810710673094665,\n        \"max\": 14.756388394891026,\n        \"num_unique_values\": 60,\n        \"samples\": [\n          -25.810710673094665,\n          -8.511299792332865,\n          3.1537530287828472\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pr\\u00e9dicteur\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"pr\\u00e9dicteur de vrai article\",\n          \"pr\\u00e9dicteur de faux article\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "À présent que notre algorithme est entraîné et a donné ses prédictions (pour les articles non vus lors de l'entraînement) sur le dataset WELFake, examinons ses réponses.\n",
        "\n",
        "👉 Notons aussi que nous avons récupéré les 60 mots les plus prédictifs pour l'algorithme pour pouvoir régler le problème de data leakage.\n",
        "\n",
        "L'accuracy est indiquée à 95 % : le modèle a correctement classé 95 % des articles du set de test, ce qui est une très bonne performance.\n",
        "\n",
        "Le classification_report fournit des métriques plus détaillées. Pour la classe \"True News\", la précision (precision ici, à distinguer de l’accuracy : il s’agit de la proportion de réponses correctes parmi toutes les prédictions de cette même classe) et le rappel (recall) sont à 95 %, tandis que pour la classe \"Fake News\", la précision et le rappel sont également à 95 %. Cela signifie que le modèle est très performant et équilibré dans sa capacité à identifier correctement les articles des deux catégories.\n",
        "\n",
        "Enfin, la matrice de confusion nous permet de voir que la régression logistique a correctement prédit 7072 vrais articles (vrais positifs) et 6627 faux articles (vrais négatifs). Elle s’est trompée pour 349 vrais articles (faux négatifs) et 379 faux articles (faux positifs).\n",
        "\n",
        "Un rapide calcul nous permet de retrouver le nombre total d'articles.\n",
        "\n",
        "- La ligne du bas de la matrice de confusion représente les vrais articles (349 + 7072 = 7421)\n",
        "\n",
        "- La ligne du haut représente les faux articles (6627 + 379 = 7006)\n",
        "\n",
        "Ces nombres sont affichés dans la colonne support de notre classification report.\n",
        "\n",
        "7006 + 7421 = 14 427 articles au total pour le set de test.\n",
        "Nous avons utilisé 20 % de nos données (articles) pour le set de test. Multiplier 14 427 par 5 devrait nous donner notre nombre d'articles initial (5 * 20 % = 100 %).\n",
        "\n",
        "14 427 * 5 = 72 135.\n",
        "Le compte est bon.\n",
        "Notre DataFrame WELFake contient 72 134 : lors de notre split de données, scikit-learn a simplement arrondi 14 426,8 au supérieur, ce qui explique la différence.\n",
        "\n",
        "Cependant, nous ne savons toujours pas si notre modèle est performant dans un contexte réel. Il aurait pu apprendre par cœur les données de WELFake sans être capable de généraliser à de nouveaux textes différents.\n",
        "\n",
        "C'est pour cette raison que nous allons le tester sur des articles indépendants du dataset WELFake 👇\n"
      ],
      "metadata": {
        "id": "CnDuo94Vc9ke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Nous récupérons les prédictions du modèle sur nos nouveaux textes\n",
        "y_pred_new = logistic_regression_pipeline.predict(texts_to_predict)\n",
        "#Nous récupérons le seuil de confiance du modèle pour chaque article afin de pouvoir les afficher ensuite\n",
        "new_probabilities = logistic_regression_pipeline.predict_proba(texts_to_predict)\n",
        "\n",
        "#Une boucle va parcourir chaque texte de notre df custom (soit 10 articles)\n",
        "#Pour chacun de ces articles nous récupérons son index et sa prédiction avec enumerate\n",
        "for i, article in enumerate(texts_to_predict):\n",
        "\n",
        "  # Les probabilités sont récupérées pour les deux classes :\n",
        "  # classe 0 (faux) et classe 1 (vrai)\n",
        "  # [i][0] est une manière courante d'accéder à un élément en python. [i] indique le i + 1ème élément (soit les 10 textes, un par un) et [0] indique la probabilité \"fake\",\n",
        "  # car la fonction predict_proba renvoie des tableaux de probabilités [0.439 0.561] par exemple pour le premier article. [0] accède au premier élément et [1] au deuxième.\n",
        "  proba_fake = new_probabilities[i][0] * 100\n",
        "  proba_true = new_probabilities[i][1] * 100\n",
        "\n",
        "  #On indique que si la probabilité fake est supérieure à la probabilité vrai, alors le texte est classé comme faux, sinon il est vrai.\n",
        "  predicted_class = 0 if proba_fake > proba_true else 1\n",
        "  predicted_veracity = \"Faux article\" if predicted_class == 0 else \"Vrai article\"\n",
        "  #On affiche simplement nos résultats, les noms de chaque texte, leur vrai label, leur probabilité selon le modèle et sa prédiction finale\n",
        "  print(f\"\\nL'article {i+1} est vrai\" if true_labels[i] == 1 else f\"\\nL'article {i+1} est faux\")\n",
        "  print(f\"Probabilité 'Faux article': {proba_fake:.2f}%\")\n",
        "  print(f\"Probabilité 'Vrai article': {proba_true:.2f}%\")\n",
        "  print(f\"Prédiction finale du modèle: {predicted_veracity}\")\n",
        "\n",
        "#Enfin, on affiche un rapport de classification pour évaluer la performance globale du modèle sur les nouveaux articles\n",
        "report_brut = classification_report(true_labels, y_pred_new, target_names=[\"Fake News\", \"True News\"], output_dict=True)\n",
        "df_brut = pd.DataFrame(report_brut).transpose()\n",
        "\n",
        "print(\"\\n-- Performance du modèle sur les nouveaux articles\")\n",
        "print(classification_report(true_labels, y_pred_new, target_names=[\"Fake News\", \"True News\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfu6yfPDqmim",
        "outputId": "a27b9cd2-2739-4b9d-ba18-8bff8f120a00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "L'article 1 est faux\n",
            "Probabilité 'Faux article': 58.46%\n",
            "Probabilité 'Vrai article': 41.54%\n",
            "Prédiction finale du modèle: Faux article\n",
            "\n",
            "L'article 2 est faux\n",
            "Probabilité 'Faux article': 37.59%\n",
            "Probabilité 'Vrai article': 62.41%\n",
            "Prédiction finale du modèle: Vrai article\n",
            "\n",
            "L'article 3 est faux\n",
            "Probabilité 'Faux article': 34.96%\n",
            "Probabilité 'Vrai article': 65.04%\n",
            "Prédiction finale du modèle: Vrai article\n",
            "\n",
            "L'article 4 est faux\n",
            "Probabilité 'Faux article': 5.51%\n",
            "Probabilité 'Vrai article': 94.49%\n",
            "Prédiction finale du modèle: Vrai article\n",
            "\n",
            "L'article 5 est faux\n",
            "Probabilité 'Faux article': 9.91%\n",
            "Probabilité 'Vrai article': 90.09%\n",
            "Prédiction finale du modèle: Vrai article\n",
            "\n",
            "L'article 6 est vrai\n",
            "Probabilité 'Faux article': 66.11%\n",
            "Probabilité 'Vrai article': 33.89%\n",
            "Prédiction finale du modèle: Faux article\n",
            "\n",
            "L'article 7 est vrai\n",
            "Probabilité 'Faux article': 1.83%\n",
            "Probabilité 'Vrai article': 98.17%\n",
            "Prédiction finale du modèle: Vrai article\n",
            "\n",
            "L'article 8 est vrai\n",
            "Probabilité 'Faux article': 4.63%\n",
            "Probabilité 'Vrai article': 95.37%\n",
            "Prédiction finale du modèle: Vrai article\n",
            "\n",
            "L'article 9 est vrai\n",
            "Probabilité 'Faux article': 27.08%\n",
            "Probabilité 'Vrai article': 72.92%\n",
            "Prédiction finale du modèle: Vrai article\n",
            "\n",
            "L'article 10 est vrai\n",
            "Probabilité 'Faux article': 19.67%\n",
            "Probabilité 'Vrai article': 80.33%\n",
            "Prédiction finale du modèle: Vrai article\n",
            "\n",
            "-- Performance du modèle sur les nouveaux articles\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Fake News       0.50      0.20      0.29         5\n",
            "   True News       0.50      0.80      0.62         5\n",
            "\n",
            "    accuracy                           0.50        10\n",
            "   macro avg       0.50      0.50      0.45        10\n",
            "weighted avg       0.50      0.50      0.45        10\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Au premier regard, on constate que notre modèle est très mauvais pour détecter les fake news, en réalité, il n'en détecte qu'une (recall fake news : 0.20). De l'autre côté, bien qu'il soit biaisé vers la classe \"vrai\" il échoue à classer le 6ème article comme vrai.\n",
        "\n",
        "Le classification report est intéressant car il nous permet de voir le tableau dans son ensemble. Bien que le recall soit de 80% pour les vrais articles, la précision du modèle est seulement de 50% pour cette classe. Le modèle est parvenu à détecter 80% des vrais articles, ce qui paraît convenable, mais la précision nous suggère que le modèle est trop optimiste, il tend à dire \"vrai\" trop souvent.\n",
        "\n",
        "Pour les fake news, le recall et à 20% et la précision à 50% car même au sein de ses rares articles classifiés en tant que fake news il se trompe une fois sur deux.\n",
        "\n",
        "Le score f1 global est à 0.45, bien en dessous d'un seuil acceptable qui devrait se rapprocher de 1.\n",
        "\n",
        "Avec une telle chute de performance, passant d'un f1-score de 95% à 45%, on comprends l'importance de tester le modèle sur de nouvelles données. Une performance élevée sur le jeu de données initial ne signifie pas que le modèle sera capable de généraliser dans un contexte réel.\n",
        "\n",
        "Pour améliorer la généralisabilité du modèle, occupons-nous du problème de data leakage.\n",
        "\n",
        "\n",
        "Exécutons à présent l'exact même code, en ajoutant à la liste de stop_words, (les mots que le modèle doit ignorer), les 60 mots que nous avons récupéré juste au-dessus."
      ],
      "metadata": {
        "id": "OLyf9u5amzve"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 : Résolution du problème de data leakage"
      ],
      "metadata": {
        "id": "Sf5OtnVf6NYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# On met à jour la liste de stop_words à partir des mots observés sur le graphique pour le modèle de régression linéaire car c'est celui que nous utilisons actuellement\n",
        "stop_words.update([\n",
        "    'reuters', 'said', 'follow', 'twitter', 'washington', 'president donald', 'com',\n",
        "    'dont', 'thats', 'obamas', 'pic twitter', 'didnt', 'there', 'mr', 'he',\n",
        "    'thursday', 'breitbart texas', 'im', 'friday', 'tuesday', 'sunday', 'monday',\n",
        "    'theyre', 'pic', 'breitbart', 'wednesday', 'milo', 'islamic state',\n",
        "    'follow twitter', 'womens', 'america', 'anyone', 'president trump', 'however',\n",
        "    'rt', 'today', 'century wire', 'wire', 'source', 'fbi', 'uk', 'dc',\n",
        "    'donate', 'know', 'please', 'share', 'the', 'yearold', 'entire',\n",
        "    'november', 'obama', 'october', 'hillary', 'image via', 'image', 'via'\n",
        "])\n",
        "\n",
        "#On exécute le même code pour obtenir nos nouvelles prédictions sans data leakage\n",
        "\n",
        "logistic_regression_pipeline = Pipeline([\n",
        "    (\"cleaner\", text_cleaning_transformer),\n",
        "    (\"tfidf\", TfidfVectorizer(max_features=5000, ngram_range=(1,2), stop_words=list(stop_words))),\n",
        "    (\"classifier\", LogisticRegression(C=1, max_iter=1000, random_state=random_state, solver=\"liblinear\", class_weight=\"balanced\"))\n",
        "])\n",
        "\n",
        "print(\"\\n---Entrainement du modèle Logistic Regression---\")\n",
        "logistic_regression_pipeline.fit(X_train, y_train)\n",
        "print(\"Modèle Logistic Regression entraîné\")\n",
        "\n",
        "new_probabilities = logistic_regression_pipeline.predict_proba(texts_to_predict)\n",
        "\n",
        "y_pred_test = logistic_regression_pipeline.predict(X_test)\n",
        "y_proba_test = logistic_regression_pipeline.predict_proba(X_test)\n",
        "\n",
        "print(f\"\\n---Performance du modèle sur le test set après correction des stop_words\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_test):.2f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_test, target_names=['Fake News', 'True News']))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_test))\n",
        "\n",
        "\n",
        "y_pred_new = logistic_regression_pipeline.predict(texts_to_predict)\n",
        "\n",
        "for i, article in enumerate(texts_to_predict):\n",
        "  proba_fake = new_probabilities[i][0] * 100\n",
        "  proba_true = new_probabilities[i][1] * 100\n",
        "  predicted_class = 0 if proba_fake > proba_true else 1\n",
        "  predicted_veracity = \"Faux article\" if predicted_class == 0 else \"Vrai article\"\n",
        "\n",
        "  print(f\"\\nArticle {i+1} :\")\n",
        "  print(f\"Probabilité 'Faux article': {proba_fake:.2f}%\")\n",
        "  print(f\"Probabilité 'Vrai article': {proba_true:.2f}%\")\n",
        "  print(f\"Prédiction finale: {predicted_veracity}\")\n",
        "\n",
        "print(\"\\n-- Performance du modèle sur les nouveaux articles\")\n",
        "print(f\"Accuracy: {accuracy_score(true_labels, y_pred_new):.2f}\")\n",
        "print(classification_report(true_labels, y_pred_new, target_names=[\"Fake News\", \"True News\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eREUyIY9myIW",
        "outputId": "cbb91c0b-e01f-4f50-bb29-3d267cb072a9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---Entrainement du modèle Logistic Regression---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['century', 'donald', 'islamic', 'president', 'replace', 'state', 'texas', 'trump', 'words'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modèle Logistic Regression entraîné\n",
            "\n",
            "---Performance du modèle sur le test set après correction des stop_words\n",
            "Accuracy: 0.92\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Fake News       0.91      0.92      0.91      7006\n",
            "   True News       0.92      0.92      0.92      7421\n",
            "\n",
            "    accuracy                           0.92     14427\n",
            "   macro avg       0.92      0.92      0.92     14427\n",
            "weighted avg       0.92      0.92      0.92     14427\n",
            "\n",
            "Confusion Matrix:\n",
            "[[6414  592]\n",
            " [ 600 6821]]\n",
            "\n",
            "Article 1 :\n",
            "Probabilité 'Faux article': 82.32%\n",
            "Probabilité 'Vrai article': 17.68%\n",
            "Prédiction finale: Faux article\n",
            "\n",
            "Article 2 :\n",
            "Probabilité 'Faux article': 36.22%\n",
            "Probabilité 'Vrai article': 63.78%\n",
            "Prédiction finale: Vrai article\n",
            "\n",
            "Article 3 :\n",
            "Probabilité 'Faux article': 53.46%\n",
            "Probabilité 'Vrai article': 46.54%\n",
            "Prédiction finale: Faux article\n",
            "\n",
            "Article 4 :\n",
            "Probabilité 'Faux article': 6.47%\n",
            "Probabilité 'Vrai article': 93.53%\n",
            "Prédiction finale: Vrai article\n",
            "\n",
            "Article 5 :\n",
            "Probabilité 'Faux article': 21.90%\n",
            "Probabilité 'Vrai article': 78.10%\n",
            "Prédiction finale: Vrai article\n",
            "\n",
            "Article 6 :\n",
            "Probabilité 'Faux article': 85.87%\n",
            "Probabilité 'Vrai article': 14.13%\n",
            "Prédiction finale: Faux article\n",
            "\n",
            "Article 7 :\n",
            "Probabilité 'Faux article': 3.09%\n",
            "Probabilité 'Vrai article': 96.91%\n",
            "Prédiction finale: Vrai article\n",
            "\n",
            "Article 8 :\n",
            "Probabilité 'Faux article': 13.83%\n",
            "Probabilité 'Vrai article': 86.17%\n",
            "Prédiction finale: Vrai article\n",
            "\n",
            "Article 9 :\n",
            "Probabilité 'Faux article': 32.22%\n",
            "Probabilité 'Vrai article': 67.78%\n",
            "Prédiction finale: Vrai article\n",
            "\n",
            "Article 10 :\n",
            "Probabilité 'Faux article': 20.02%\n",
            "Probabilité 'Vrai article': 79.98%\n",
            "Prédiction finale: Vrai article\n",
            "\n",
            "-- Performance du modèle sur les nouveaux articles\n",
            "Accuracy: 0.60\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Fake News       0.67      0.40      0.50         5\n",
            "   True News       0.57      0.80      0.67         5\n",
            "\n",
            "    accuracy                           0.60        10\n",
            "   macro avg       0.62      0.60      0.58        10\n",
            "weighted avg       0.62      0.60      0.58        10\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous avons choisi d'ajouter plusieurs mots à la liste des stop_words, afin de limiter le data leakage. Ce faisant, on rend le modèle un peu moins performant sur le training set (et le test set), mais cela nous permet d'éviter qu'il apprenne par coeur. Retirer les mots doit se faire de manière réfléchie, car on pourrait retirer par malchance un ou plusieurs mots qui n'étaient pas de la fuite de données et qui auraient vraiment permis au modèle de généraliser. Nous aurions pu envisager de retirer certains mots de manière sélective, en fonction de notre appréciation de sa pertinence ou non, mais cela aurait là aussi introduit une forme de biais de subjectivité.\n",
        "\n",
        "\n",
        "En supprimant les mots les plus importants, nous privons le modèle des indices les plus forts sur lesquels il se basait pour effectuer ses prédictions, et espérons que cela l'obligera à se concentrer sur des indices sémantiques plus subtils présents dans le training set et par conséquent d'autres articles.\n",
        "\n",
        "## 4 : Nouvelle évaluation du modèle\n",
        "\n",
        "Le modèle obtient un f1-score de 58% ce qui est une amélioration notable par rapport à sa version précédente (45%). Soyons prudents dans notre interprétation néanmoins, car la faible taille de l'échantillon ne permet pas de généraliser.\n",
        "En réalité, la seule différence est que le troisième article est désormais correctement classifié comme faux. Pour obtenir un résultat rigoureux nous aurions besoin d'un échantillon bien plus vaste.\n",
        "\n",
        "Cependant, pour les besoins de notre démonstration cette différence est suffisante pour mettre en évidence un changement dans les prédictions de notre modèle.\n",
        "\n",
        "Malheureusement une accuracy de 60% et un f1-score de 58% peuvent difficilement être considérés comme de bonnes métriques dans un contexte réel."
      ],
      "metadata": {
        "id": "Uuln-_HnBfPA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5 : Améliorations"
      ],
      "metadata": {
        "id": "QGlG2WfuBU76"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maintenant que notre problème de data leakage est résolu, notre objectif est d’améliorer le détecteur de fake news afin d’obtenir de meilleures performances sur notre df_fake_true (texts_to_predict).\n",
        "Un modèle d’apprentissage automatique peut être ajusté grâce à différents paramètres appelés hyperparamètres, qui influencent la manière dont il apprend et prend ses décisions.\n",
        "Plutôt que de tester toutes les configurations manuellement, nous allons demander à l’ordinateur d’explorer automatiquement plusieurs combinaisons d’hyperparamètres, puis de sélectionner celle offrant les meilleures performances.\n",
        "\n",
        "Au lieu de tester toutes les combinaisons manuellement (ce qui serait long et fastidieux), nous allons utiliser un outil intégré à scikit-learn : RandomGridSearch. Cet outil permet d’automatiser la recherche de la meilleure combinaison d’hyperparamètres parmi celles que nous lui indiquons.\n",
        "\n",
        "Cependant, il est important de ne pas tester un nombre excessif de combinaisons. Si nous explorons trop de possibilités, nous risquons d’optimiser uniquement sur notre jeu d’entraînement et donc de créer un modèle qui a “appris par cœur” ce jeu de données (surapprentissage ou overfitting).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9k-KNsGB-JZt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si vous vous souvenez de la métaphore du mélange nettoyant, c’est ici que nous allons mettre en place la structure qui permettra de décider quel mélanges (quels hyperparamètres et quel modèle) est le plus efficace.\n",
        "\n",
        "Pour plus de lisibilité, le code ci-dessous est organisé en trois blocs :\n",
        "chaque bloc correspond à un modèle de machine learning différent, indiqué à la ligne \"classifier\". Ce sont trois modèles dont nous avons éclairé le fonctionnement dans la fiche explicative 📄\n"
      ],
      "metadata": {
        "id": "8duLNAXYH69j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = [\n",
        "    {\n",
        "        \"cleaner\":[text_cleaning_transformer, text_cleaning_transformer_no_numbers],\n",
        "        \"tfidf__max_features\":[5000], #max_features est le nombre maximal de mots appris par le modèle, l'augmenter peut augmenter la performance mais aussi l'overfitting\n",
        "        \"tfidf__ngram_range\":[(1,1), (1,2)], #ngram (1,1) considère les mots seuls ; ngram (1,2) considère les mots seuls et les paires, là encore augmenter la complexité permet de saisir des relations plus complexes, mais peut nuire à la généralisabilité du modèle\n",
        "        \"tfidf__smooth_idf\":[True, False], #Le lissage smooth_idf évite qu'un mot très rare soit attribué un poids excessif. On teste avec et sans lissage\n",
        "        \"classifier\":[MultinomialNB()],\n",
        "        \"classifier__alpha\":[0.01, 0.1, 10],#alpha est le paramètre de régularisation, plus alpha est faible plus le modèle est autorisé à s'ajuster aux données et saisir des relations complexes. Un alpha plus élevé produit l'inverse.\n",
        "    },\n",
        "    {\n",
        "        \"cleaner\":[text_cleaning_transformer, text_cleaning_transformer_no_numbers],\n",
        "        \"tfidf__max_features\":[5000],\n",
        "        \"tfidf__ngram_range\":[(1,1), (1,2)],\n",
        "        \"tfidf__use_idf\":[True, False],#On active ou désactive l'utilisation du facteur IDF, qui réduit l'ilmportance des mots très fréquents dans les documents lorsqu'activé\n",
        "        \"tfidf__smooth_idf\": [True, False],\n",
        "        \"classifier\":[LogisticRegression(max_iter=1000, random_state=42)],\n",
        "        \"classifier__C\":[0.01, 0.1, 10],#C est l'inverse de la régularisation alpha : un C faible applique une forte régularisation, un C élevé donne plus de liberté au modèle\n",
        "        \"classifier__penalty\":[\"l2\"],#Il s'agit du type de régularisation appliquée, L2 pénalise les grands coefficients, il tend à les réduire sans les annuler complètement\n",
        "    },\n",
        "    {\n",
        "        \"cleaner\":[text_cleaning_transformer, text_cleaning_transformer_no_numbers],\n",
        "        \"tfidf__max_features\":[5000],\n",
        "        \"tfidf__ngram_range\":[(1,1), (1,2)],\n",
        "        \"tfidf__use_idf\":[True, False],\n",
        "        \"tfidf__smooth_idf\": [True, False],\n",
        "        \"classifier\":[LinearSVC(max_iter=1000, random_state=42)],\n",
        "        \"classifier__C\":[0.01, 0.1, 10],\n",
        "    }]"
      ],
      "metadata": {
        "id": "bW5FtizbKR3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Random grid search"
      ],
      "metadata": {
        "id": "FiTqL50Kx8En"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le code ci dessous exécute une recherche aléatoire sur les paramètres que nous avons indiqué dans param_grid[ ].\n",
        "\n",
        "Son exécution prends plusieurs heures, pour vous épargner le temps d'attente les résultats de la recherche sont déjà enregistrés, vous n'avez qu'à lancer la cellule suivante pour les observer."
      ],
      "metadata": {
        "id": "y1PAiZpRfyBK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Re0uGSn1prxE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "310af8f3-d4bb-4111-c526-459e289f18d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "skip\n"
          ]
        }
      ],
      "source": [
        "#Les plus téméraires pourront retirer la ligne %%script echo skip et lancer le code (temps d'exécution de plusieurs heures)\n",
        "\n",
        "%%script echo skip\n",
        "#Les paramètres du pipeline sont rentrés à titre indicatif pour que random grid search\n",
        "pipeline = Pipeline([\n",
        "    (\"cleaner\", text_cleaning_transformer), #Nettoyage et prétraitement du texte\n",
        "    (\"tfidf\", TfidfVectorizer()), #Transformation du texte en tokens\n",
        "    (\"classifier\", LogisticRegression(solver=\"liblinear\", random_state=42)) #Sélection du modèle de classification\n",
        "])\n",
        "\n",
        "scoring_metric = \"f1_weighted\" #Pondération du score F1 en fonction des tailles des classes pour ne pas favoriser la classe majoritaire\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "pipeline, #Utilisation du pipeline complet nettoyage + vectorisation + modèle\n",
        "param_grid, #Les paramètres à tester définis juste au dessus\n",
        "n_iter=10, #Nombre de combinaisons que random search va tester au hasard parmi toutes celles possibles\n",
        "cv=5, #Cross validation (ou validation croisée) : on sépare les données d'entraînement en 5 morceaux, on entraîne le modèle sur les 4/5 et on le teste sur le 5ème restant. On reproduit l'opération 5 fois et on fait la moyenne des 5 tests pour calculer le score final.\n",
        "n_jobs=-1, #On utilise tous les coeurs du processeur disponibles pour accélérer le calcul\n",
        "scoring=\"f1_weighted\",\n",
        "random_state=42) #On définit la seed à 42 pour la reproductibilité\n",
        "\n",
        "print(f\"Starting Random Search with {scoring_metric}\")\n",
        "\n",
        "#On lance la recherche\n",
        "random_search.fit(X_train, y_train)\n",
        "print(\"Random Search completed\")\n",
        "\n",
        "#On affiche les meilleurs paramètres trouvés\n",
        "print(f\"\\nBest Parameters found: {random_search.best_params_}\")\n",
        "print(f\"\\nBest Cross_Validation {scoring_metric} score: {random_search.best_score_:.2f}\")\n",
        "\n",
        "#On évalue le meilleur modèle sur le test set\n",
        "best_pipeline = random_search.best_estimator_\n",
        "y_pred_best = best_pipeline.predict(X_test)\n",
        "\n",
        "#On affiche les performances du meilleur modèle sur notre test set WELFake\n",
        "print(f\"\\nPerformance of the Best Model on the Test Set using {scoring_metric}:\")\n",
        "print(f\"Accuracy:{accuracy_score(y_test, y_pred_best):.4f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_best, target_names=['True News', 'Fake News']))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_best))\n",
        "\n",
        "\n",
        "#On sauvegarde nos résulats pour ne pas devoir relancer plusieurs heures de recherche à chaque fois\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "joblib.dump(random_search, \"random_search_results.joblib\")\n",
        "\n",
        "joblib.dump(random_search.best_estimator_, \"best_pipeline.joblib\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si notre objectif est d’obtenir un modèle performant sur un jeu de données totalement nouveau (par exemple notre df_fake_true) pourquoi ne pas appliquer directement la recherche d’hyperparamètres (Random Search) sur ces textes pour obtenir le meilleur modèle possible ?\n",
        "\n",
        "La réponse tient en un mot : overfitting.\n",
        "Optimiser un modèle directement sur un échantillon aussi réduit, ici 10 textes, reviendrait à adapter presque parfaitement les hyperparamètres à ce minuscule jeu de données rendant la généralisation à d’autres textes très difficile. Sur un si petit échantillon, la métrique obtenue n’a quasiment aucune valeur statistique.\n",
        "\n",
        "Le df_fake_true n’a donc pas vocation à servir de base d’optimisation ou d’évaluation robuste : il est simplement utilisé comme un jeu de test illustratif, pour montrer concrètement comment un modèle déjà entraîné se comporte sur des textes inédits. C’est un outil pédagogique, pas un échantillon fiable pour mesurer la performance réelle.\n",
        "\n",
        "En revanche, le dataset WELFake contient plusieurs dizaines de milliers de textes. En l’utilisant pour évaluer et sélectionner notre modèle, on obtient une estimation beaucoup plus stable et représentative de ses performances.\n",
        "Cette robustesse statistique est essentielle : dans une situation réelle de déploiement, on souhaite que le modèle conserve ses performances sur un large éventail de contenus, pas uniquement sur un micro-échantillon.\n",
        "\n",
        "La démarche correcte est donc :\n",
        "\n",
        "- Entraîner et optimiser le modèle sur un large dataset représentatif (WELFake), via validation croisée pour limiter l’overfitting.\n",
        "\n",
        "- Tester le modèle optimisé sur des données totalement nouvelles et indépendantes (df_fake_true) pour voir comment il se comporte en conditions réelles, tout en gardant à l’esprit que si l’échantillon est trop petit, ce test sera avant tout indicatif et pédagogique.\n",
        "\n"
      ],
      "metadata": {
        "id": "dhbot5mAvAye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Récupérons les mots les plus prédictifs de notre best_pipeline afin de les ajouter à la liste de stop_words\n",
        "\n",
        "best_pipeline = joblib.load(\"best_pipeline.joblib\")\n",
        "\n",
        "y_pred_best = best_pipeline.predict(texts_to_predict)\n",
        "probas = best_pipeline.predict_proba(texts_to_predict)\n",
        "\n",
        "tfidf_vectorizer = best_pipeline.named_steps[\"tfidf\"]\n",
        "classifier = best_pipeline.named_steps[\"classifier\"]\n",
        "\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "coefs = classifier.coef_[0]\n",
        "\n",
        "df_words = pd.DataFrame({\"word\":feature_names, \"score\":coefs})\n",
        "df_words = df_words.sort_values(by=\"score\", ascending=False)\n",
        "\n",
        "top_true_words = df_words.head(30)\n",
        "top_fake_words = df_words.tail(30)\n",
        "\n",
        "\n",
        "df_top_words = pd.concat([top_fake_words, top_true_words]).sort_values(by=\"score\")\n",
        "\n",
        "new_stop_words = initial_stop_words\n",
        "\n",
        "print(f\"Premiers stop_words avant ajout : {list(new_stop_words)[:30]}\")\n",
        "\n",
        "new_stop_words.update(list(df_top_words[\"word\"]))\n",
        "\n",
        "print(f\"Premiers stop_words après ajout : {list(new_stop_words)[:30]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQStYQbN0H0h",
        "outputId": "4e511a54-1d65-40f3-f141-307843eae3fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Premiers stop_words avant ajout : ['m', 'ma', 'until', 'again', 'few', 'if', 'will', 'o', 'each', 'him', 'he', \"she'd\", 'so', \"she's\", 'yourself', 'while', \"he'll\", 'only', 'their', \"they'd\", 'hadn', 'about', 'am', 'itself', \"you're\", \"didn't\", 'mustn', 'you', 'ours', 'from']\n",
            "Premiers stop_words après ajout : ['m', 'ma', 'until', 'com', 'again', 'few', 'if', 'will', 'o', 'each', 'him', 'entire', 'he', \"she'd\", 'said', 'dont', 'so', \"she's\", 'yourself', 'while', 'via', \"he'll\", 'only', 'monday', 'probably', 'their', \"they'd\", 'hadn', 'about', 'wednesday']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Application de notre meilleur modèle"
      ],
      "metadata": {
        "id": "H45Jpq30ypYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ajoutons nos stopwords trouvés plus tôt au modèle\n",
        "stop_words.update(new_stop_words)\n",
        "\n",
        "#On charge notre meilleur modèle enregistré dans le fichier best_pipeline.joblib\n",
        "best_pipeline = joblib.load(\"best_pipeline.joblib\")\n",
        "\n",
        "print(f\"Paramètres de notre meilleur modèle trouvé par random grid search :\\n{best_pipeline.get_params()}\")\n",
        "\n",
        "#On récupère les prédictions du modèle ainsi que son seuil de probabilité pour chaque prédiction\n",
        "y_pred_best = best_pipeline.predict(texts_to_predict)\n",
        "probas = best_pipeline.predict_proba(texts_to_predict)\n",
        "\n",
        "#On demande à notre modèle d'indiquer ses prédictions pour chaque texte\n",
        "for i, article in enumerate(texts_to_predict):\n",
        "  proba_fake = probas[i][0] * 100\n",
        "  proba_true = probas[i][1] * 100\n",
        "\n",
        "  predicted_class = 0 if proba_fake > proba_true else 1\n",
        "  predicted_veracity = \"Faux article\" if predicted_class == 0 else \"Vrai article\"\n",
        "\n",
        "  print(f\"\\nL'article {i+1} est vrai\" if true_labels[i] == 1 else f\"\\nL'article {i+1} est faux\")\n",
        "  print(f\"Probabilité 'Faux article': {proba_fake:.2f}%\")\n",
        "  print(f\"Probabilité 'Vrai article': {proba_true:.2f}%\")\n",
        "  print(f\"Prédiction finale: {predicted_veracity}\")\n",
        "\n",
        "print(\"\\n-- Performance du modèle sur les nouveaux articles\")\n",
        "print(classification_report(true_labels, y_pred_best, target_names=[\"Fake News\", \"True News\"]))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(true_labels, y_pred_best))\n",
        "\n",
        "report_best = classification_report(true_labels, y_pred_best, target_names=[\"Fake News\", \"True News\"], output_dict=True)\n",
        "df_best = pd.DataFrame(report_best).transpose()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTlMot0Fg1O6",
        "outputId": "00854e0d-a542-466d-a1a5-9286f2995376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paramètres de notre meilleur modèle trouvé par random grid search :\n",
            "{'memory': None, 'steps': [('cleaner', FunctionTransformer(func=<function apply_clean_text_no_numbers at 0x7a2641e53a60>)), ('tfidf', TfidfVectorizer(max_features=5000)), ('classifier', LogisticRegression(C=10, max_iter=1000, random_state=42))], 'transform_input': None, 'verbose': False, 'cleaner': FunctionTransformer(func=<function apply_clean_text_no_numbers at 0x7a2641e53a60>), 'tfidf': TfidfVectorizer(max_features=5000), 'classifier': LogisticRegression(C=10, max_iter=1000, random_state=42), 'cleaner__accept_sparse': False, 'cleaner__check_inverse': True, 'cleaner__feature_names_out': None, 'cleaner__func': <function apply_clean_text_no_numbers at 0x7a2641e53a60>, 'cleaner__inv_kw_args': None, 'cleaner__inverse_func': None, 'cleaner__kw_args': None, 'cleaner__validate': False, 'tfidf__analyzer': 'word', 'tfidf__binary': False, 'tfidf__decode_error': 'strict', 'tfidf__dtype': <class 'numpy.float64'>, 'tfidf__encoding': 'utf-8', 'tfidf__input': 'content', 'tfidf__lowercase': True, 'tfidf__max_df': 1.0, 'tfidf__max_features': 5000, 'tfidf__min_df': 1, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__preprocessor': None, 'tfidf__smooth_idf': True, 'tfidf__stop_words': None, 'tfidf__strip_accents': None, 'tfidf__sublinear_tf': False, 'tfidf__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'tfidf__tokenizer': None, 'tfidf__use_idf': True, 'tfidf__vocabulary': None, 'classifier__C': 10, 'classifier__class_weight': None, 'classifier__dual': False, 'classifier__fit_intercept': True, 'classifier__intercept_scaling': 1, 'classifier__l1_ratio': None, 'classifier__max_iter': 1000, 'classifier__multi_class': 'deprecated', 'classifier__n_jobs': None, 'classifier__penalty': 'l2', 'classifier__random_state': 42, 'classifier__solver': 'lbfgs', 'classifier__tol': 0.0001, 'classifier__verbose': 0, 'classifier__warm_start': False}\n",
            "\n",
            "L'article 1 est faux\n",
            "Probabilité 'Faux article': 66.63%\n",
            "Probabilité 'Vrai article': 33.37%\n",
            "Prédiction finale: Faux article\n",
            "\n",
            "L'article 2 est faux\n",
            "Probabilité 'Faux article': 12.21%\n",
            "Probabilité 'Vrai article': 87.79%\n",
            "Prédiction finale: Vrai article\n",
            "\n",
            "L'article 3 est faux\n",
            "Probabilité 'Faux article': 80.94%\n",
            "Probabilité 'Vrai article': 19.06%\n",
            "Prédiction finale: Faux article\n",
            "\n",
            "L'article 4 est faux\n",
            "Probabilité 'Faux article': 45.57%\n",
            "Probabilité 'Vrai article': 54.43%\n",
            "Prédiction finale: Vrai article\n",
            "\n",
            "L'article 5 est faux\n",
            "Probabilité 'Faux article': 18.62%\n",
            "Probabilité 'Vrai article': 81.38%\n",
            "Prédiction finale: Vrai article\n",
            "\n",
            "L'article 6 est vrai\n",
            "Probabilité 'Faux article': 32.33%\n",
            "Probabilité 'Vrai article': 67.67%\n",
            "Prédiction finale: Vrai article\n",
            "\n",
            "L'article 7 est vrai\n",
            "Probabilité 'Faux article': 0.06%\n",
            "Probabilité 'Vrai article': 99.94%\n",
            "Prédiction finale: Vrai article\n",
            "\n",
            "L'article 8 est vrai\n",
            "Probabilité 'Faux article': 2.17%\n",
            "Probabilité 'Vrai article': 97.83%\n",
            "Prédiction finale: Vrai article\n",
            "\n",
            "L'article 9 est vrai\n",
            "Probabilité 'Faux article': 26.63%\n",
            "Probabilité 'Vrai article': 73.37%\n",
            "Prédiction finale: Vrai article\n",
            "\n",
            "L'article 10 est vrai\n",
            "Probabilité 'Faux article': 32.74%\n",
            "Probabilité 'Vrai article': 67.26%\n",
            "Prédiction finale: Vrai article\n",
            "\n",
            "-- Performance du modèle sur les nouveaux articles\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Fake News       1.00      0.40      0.57         5\n",
            "   True News       0.62      1.00      0.77         5\n",
            "\n",
            "    accuracy                           0.70        10\n",
            "   macro avg       0.81      0.70      0.67        10\n",
            "weighted avg       0.81      0.70      0.67        10\n",
            "\n",
            "Confusion Matrix:\n",
            "[[2 3]\n",
            " [0 5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notre meilleur pipeline, obtenu via un random grid search, repose sur une séquence en trois étapes :\n",
        "\n",
        "- Nettoyage des textes via la fonction apply_clean_text_no_numbers, supprimant les chiffres et appliquant une normalisation de base. On note ici que random search a sélectionné le nettoyage sans les nombres sans doute car ceux-ci n'apportaient pas d'information pertinente pour les prédictions.\n",
        "\n",
        "- Vectorisation TF-IDF limitée à un vocabulaire de 5 000 mots les plus fréquents, avec normalisation L2 et prise en compte des unigrammes seulement (mot unique).\n",
        "\n",
        "- Classification par régression logistique (LogisticRegression) avec un paramètre de régularisation C = 10 et un maximum de 1 000 itérations, garantissant une convergence stable.\n",
        "\n",
        "Il est probable que la poursuite de l’exploration des hyperparamètres (par exemple en incluant des bigrammes, en élargissant le vocabulaire ou en testant des modèles plus complexes comme LinearSVC) aurait pu produire un best predictor différent, potentiellement capable de capturer davantage de complexité dans les données. Toutefois, cela aurait pu se traduire par une meilleure performance sur le jeu d’entraînement au détriment de la performance finale sur notre jeu d’évaluation externe (df_fake_true). Le modèle sélectionné constitue donc un compromis pertinent entre performance sur les données d’entraînement et généralisation.\n",
        "\n",
        "Les résultats de notre évaluation sur nos 10 articles sont les suivants :\n",
        "\n",
        "Articles faux : sur 5 cas, seuls 2 sont correctement détectés, soit un recall de 40 %.\n",
        "\n",
        "Articles vrais : sur 5 cas, tous sont correctement détectés (recall de 100 %), mais avec une précision de 62 %, ce qui indique que le modèle classe parfois des articles faux comme vrais.\n",
        "\n",
        "Le classification report confirme ces tendances :\n",
        "\n",
        "Fake News → précision : 1.00, recall : 0.40, f1-score : 0.57\n",
        "\n",
        "True News → précision : 0.62, recall : 1.00, f1-score : 0.77\n",
        "\n",
        "Accuracy globale : 70 %\n",
        "\n",
        "Moyenne pondérée du f1-score : 0.67\n",
        "\n",
        "Interprétation\n",
        "Ces résultats révèlent que le modèle a nettement progressé dans la détection des fake news par rapport à notre version brute initiale, qui affichait un recall nul pour cette classe. Notre pipeline optimisé, combiné à un meilleur nettoyage ciblé, a permis au modèle de surmonter en partie son biais initial en faveur de la classe “vrai”.\n",
        "\n",
        "Cependant, un déséquilibre persiste : la sensibilité (recall) pour les fake news reste inférieure à celle pour les vrais articles (40 % contre 100 %). En d’autres termes, le modèle reste plus performant pour identifier les articles authentiques que pour repérer les faux.\n",
        "\n",
        "Si l’on compare avec les performances initiales, la différence est notable :\n",
        "\n",
        "Avant optimisation : le modèle ne détectait aucune fake news (f1-score = 0 pour cette classe), avec une tendance forte à prédire “vrai” dans la majorité des cas.\n",
        "\n",
        "Après optimisation : la capacité à identifier des fake news existe désormais, mais la précision élevée pour cette classe (1.00) s’explique par le faible nombre de prédictions “faux” effectuées. Le modèle ne se trompe jamais sur nos 10 textes lorsqu'il prédit une fake news, car ses prédictions sont rares.\n",
        "\n",
        "En pratique, ce comportement traduit un modèle prudent dans la classification en “faux” : il ne l’attribue que lorsqu’il est très confiant, ce qui évite les faux positifs mais entraîne un nombre important de faux négatifs (fake news non détectées).\n",
        "\n",
        "Il existerait plusieurs manière d'améliorer nos résultats.\n",
        "- La manière sans doute la plus simple consisterait à déplacer le seuil de décision pour forcer le modèle à prédire plus souvent des fake news, quitte à perdre légèrement en précision.\n",
        "- Augmenter la diversité du training set : Ce serait très long et fastidieux, mais robuste. Il faudrait enrichir le dataset de centaines, voire de milliers d'articles sur lesquels on veut améliorer les prédictions de notre modèle.\n",
        "- Affiner les paramètres et revoir le prétraitement. On pourrait encore jouer avec les paramètres pour trouver une configuration plus efficace adaptée non pas pour WELFake, mais pour notre évaluation finale. Or comme nous l'avons vu, ce serait de l'overfitting. Nous pourrions aussi tenter une lemmatisation plus fine du texte.\n",
        "\n",
        "Seulement, notre but n'est pas de gonfler artificiellement les chiffres de notre modèle pour obtenir une performance fallacieuse. Nous cherchons à construire un détecteur de fake news efficace, tout en plongeant dans le fonctionnement des différents modèles et techniques possibles.\n",
        "Notre détecteur de fake news sera opérationnel lorsque nous aurons trouvé la configuration adéquate et que nous l'aurons évalué de manière rigoureuse sur un dataset de taille et de diversité suffisante.\n",
        "Tout comme nous avons ajusté au fur et à mesure et expérimenté de nombreuses possibilitées, notre futur modèle sera lui aussi amené à évoluer.\n",
        "\n",
        "Pour cloturer ce périple à travers le traitement de texte en machine learning, terminons ce notebook avec l'application d'une méthode pour plonger encore plus loin dans notre algorithme de régression linéaire. Cette dernière section qui se concentre plus sur l'éthique et l'ajout de détails didactiques est optionnelle. Le notebook que vous venez de parcourir est suffisant pour vous donner un premier aperçut de la construction d'un modèle de machine learning."
      ],
      "metadata": {
        "id": "J3mBFIPwlCl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = [\"precision\", \"recall\", \"f1-score\"]\n",
        "\n",
        "df_compare = pd.DataFrame({\n",
        "    \"Modèle brut\": df_brut.loc[\"weighted avg\", metrics],\n",
        "    \"Best pipeline\": df_best.loc[\"weighted avg\", metrics]\n",
        "})\n",
        "\n",
        "df_compare.plot(kind=\"bar\", figsize=(8,5))\n",
        "plt.title(\"Comparaison des performances globales\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.ylim(0, 1)\n",
        "plt.xticks(rotation=0)\n",
        "plt.legend(title=\"Modèle\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "U-QEQbxUPZip",
        "outputId": "0c3864b6-e708-46d7-f3d6-498f5d82f4c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En bonus, voici un graphique comparant les performances du modèle brut vs amélioré. Ces mesures représentent la capacité de notre modèle à généraliser sur de nouveaux textes. Notre F1-score n'est toujours pas idéal, mais nous avons vu comment améliorer la généralisabilité en quelques étapes simples, en veillant toujours à ne pas tomber dans le piège du surapprentissage sur le jeu d'entraînement, puis en modifiant les hyperparamètres pour trouver un modèle convenable. De plus, nous avons retiré les mots les plus prédictifs pour éviter le problème de data leakage.\n",
        "\n",
        "Ce modèle prototypique obtient déjà des résulats satisfaisants, mais les prochaines fois, nous définirons clairement la visée de notre projet *Détecteur de Fake News*, et nous tâcherons de le rendre opérationnel."
      ],
      "metadata": {
        "id": "bU52IMTrwdNx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Méthode LIME appliquée au modèle de régression logistique"
      ],
      "metadata": {
        "id": "3Lyf6tIYMr96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%script echo skip\n",
        "\n",
        "logistic_regression_pipeline = Pipeline([\n",
        "    (\"cleaner\", text_cleaning_transformer),\n",
        "    (\"tfidf\", TfidfVectorizer(max_features=10000, ngram_range=(1,2))),\n",
        "    (\"classifier\", LogisticRegression(C=0.1, max_iter=1000, random_state=random_state, solver=\"liblinear\"))\n",
        "])\n",
        "\n",
        "print(\"\\n---Entrainement du modèle Logistic Regression---\")\n",
        "logistic_regression_pipeline.fit(X_train, y_train)\n",
        "print(\"Modèle Logistic Regression entraîné\")\n",
        "\n",
        "def predict_proba_for_lime(texts):\n",
        "  return logistic_regression_pipeline.predict_proba(texts)\n",
        "\n",
        "class_names = ['Fake News', 'True News']\n",
        "\n",
        "explainer_lime = lime.lime_text.LimeTextExplainer(\n",
        "    kernel_width=0.75,\n",
        "    feature_selection=\"auto\",\n",
        "    class_names=class_names,\n",
        "    verbose=True,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "for i, article_text in enumerate(texts_to_predict):\n",
        "  proba_fake = logistic_regression_pipeline.predict_proba([article_text])[0][0] * 100\n",
        "  proba_true = logistic_regression_pipeline.predict_proba([article_text])[0][1] * 100\n",
        "  predicted_class_index = logistic_regression_pipeline.predict([article_text])[0]\n",
        "  predicted_veracity = class_names[predicted_class_index]\n",
        "\n",
        "  print(f\"\\nArticle {i+1} :\")\n",
        "  print(f\"Probabilité '{class_names[0]}': {proba_fake:.2f}%\")\n",
        "  print(f\"Probabilité '{class_names[1]}': {proba_true:.2f}%\")\n",
        "  print(f\"Prédiction finale: {predicted_veracity}\")\n",
        "\n",
        "\n",
        "  print(f\"\\n Explication LIME pour l'article {i+1} (Prédit: {predicted_veracity}:)\")\n",
        "\n",
        "  exp_lime = explainer_lime.explain_instance(\n",
        "      article_text,\n",
        "      predict_proba_for_lime,\n",
        "      num_features=10,\n",
        "      num_samples=2000,\n",
        "  )\n",
        "\n",
        "  print(\"Mots les plus influents et leurs poids\")\n",
        "  for word, weight in exp_lime.as_list():\n",
        "    print(f\" -{word}: {weight:.4f}\")\n",
        "\n",
        "  print(\"\\nVisualisation HTML LIME:\")\n",
        "  exp_lime.show_in_notebook(text=True)\n",
        "  print(\"-\" * 80)\n"
      ],
      "metadata": {
        "id": "UxbNyl_-O9yJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interprétation du modèle régression logistique avec LIME\n",
        "\n",
        "\n",
        "#**1. Fonctionnement et utilité de LIME**\n",
        "Lime est un outil d'interprétation permettant d'expliquer les résultats d'un modèle de manière locale.\n",
        "\n",
        "La méthode LIME est dite locale car elle se concentre sur un seul exemple (un texte) à la fois.\n",
        "\n",
        "LIME fonctionne en créant de multiples variations du texte original. Dans chaque variation il supprime aléatoirement certains mots et demande au modèle (régression logistique ici) de faire une prédiction sur chaque variation. En observant comment les prédictions changent en fonction des mots supprimés, LIME peut en déduire pour chaque texte quels mots sont les plus influents pour la décision du modèle.\n",
        "\n",
        "Cas typiques où LIME est utile :\n",
        "- Modèle sans interprétabilité native (deep learning, gradient boosting sans accès direct aux poids, modèles importés).\n",
        "- Vérifier la cohérence des décisions cas par cas (ex : vérifier qu’un diagnostic médical ne repose pas sur un artefact du texte ou de l’image).\n",
        "- Debug : comprendre pourquoi un modèle donne un résultat inattendu sur un exemple particulier.\n",
        "\n",
        "Il faut distinguer les résultats de LIME qui sont locaux, pour chaque article indépendants, de nos graphiques plus haut ou de nos mits les plus prédictifs qui étaient globaux.\n",
        "\n",
        "\n",
        "La force de LIME, à savoir sa simplicité, est aussi une de ses principales faiblesses. Comme la génération des variations est **aléatoire** l'interprétation obtenue peut changer à chaque exécution du code. Si le résultat obtenu n'est pas reproductible, celui-ci ne vaut pas grand chose en machine learning (ou en sciences plus généralement). Fort heureusement la manière dont fonctionne l'aléatoire dans les ordinateurs nous permet de contourner ce problème. Les ordinateurs ne pouvant pas générer de vrai hasard, on parle plutôt de pseudo-aléatoire. Le système se repose sur un nombre de départ, par exemple l'heure exacte de l'exécution du code en nanosecondes, puis un algorithme (PRNG) transforme ces nombres en une nouvelle séquence qui sera considérée comme notre séquence aléatoire. Le nombre de départ est appelé \"seed\" (graine en français), et si l'on fixe ce nombre, l'algorithme PRNG génèrera toujours le même nombre en sortie. La ligne *random_state=42* remplit cette fonction et sert à fixer la seed, 42 par convention.\n",
        "\n",
        "**En image :** Voyez le random_state comme les ingrédients et les quantités de votre gâteau, et l'algorithme PRNG comme la recette. Si vous utilisez toujours les mêmes ingrédients, vous obtiendrez toujours le même gâteau. Pour s'assurer d'avoir des résultats reproductibles, il est donc essentiel de fixer le seed pour que le \"gâteau\" de votre interprétation ne change jamais.\n",
        "\n",
        "N'importe quel nombre peut être utilisé comme seed, mais il est impératif qu'il reste le même d'une exécution à l'autre pour garantir que l'algorithme PRNG génère toujours la même séquence pseudo-aléatoire, et que vos résultats soient reproductibles.\n",
        "\n",
        "**Premier texte analysé par LIME :**\n",
        "\n",
        "Le modèle prédit qu'il s'agit d'une fake news avec 65.57% de probabilité. Les 5 premiers articles étant faux et les 5 derniers vrais, le modèle de régression logistique a vu juste pour ce premier exemple.\n",
        "LIME tâche ensuite d'expliquer pourquoi. Il affiche sur le graphique les 10 mots les plus influents (num_features) pour la décision du modèle. Les mots surlignés en bleu sont les mots prédicteurs de fake news pour le modèle (pour ce texte seulement) et les mots en orange les prédicteurs de vrais articles.\n",
        "\n",
        "Cette visualisation est très utile pour tenter d'expliquer le fonctionnement d'un modèle et comprendre comment il a prit sa décision. Voyons un autre exemple pour comprendre plus en profondeur tout ceci.\n",
        "\n",
        "**Texte deux analysé par LIME :**\n",
        "\n",
        "On remarque que le modèle s'est trompé ici, il classe avec 37.03% de probabilité l'article satirique comme vrai. Nous verrons plus loin les raisons possibles de cette erreur pour notre modèle de régression.\n",
        "Une manière de modifier l'output du modèle serait d'ajouter les mots fortement associés à la prédiction \"True news\" à la liste de stop_words. Ainsi, en ignorant ces mots le modèle deviendrait \"biaisé\" vers la réponse que nous souhaitons : à savoir classer cet article comme faux.\n",
        "L'image suivante présente le résultat de ce test, si vous voulez l'exécuter vous-même vous pouvez ajouter les mots \"revelations\", \"targeted\", \"real\", \"comes\" et \"sexual\" à la liste de stop_words, avant de relancer le code. Pensez à les retirer de la liste une fois le test effectué !\n",
        "Cette manipulation un peu barbare ne sert qu'à illustrer la manière dont fonctionne LIME. On voit bien qu'en ignorant deux mots associés aux vrais articles, les probabilités prédites par le modèle de régression logistique évoluent (passant de 37.03% de probabilité de fake news à 41.49%), montrant ainsi que les mots mis en avant par LIME ont effectivement un poids conséquent dans la décision du modèle.\n",
        "\n",
        "\n",
        "NB : Modifier de la sorte les paramètres est une forme d'outcome engineering. On modifie le modèle pour le forcer à donner la réponse qui nous intéresse localement (les autres prédictions ne sont pas ou peu affectées). Cette pratique, en plus d'être malhonête, n'améliore pas réellement le modèle.\n",
        "\n",
        "#**2. Comment intepréter nos résultats ?**\n",
        "\n",
        "Notre modèle semble être bon pour détecter les textes utilisant un langage scientifique ou académique en les classant presque à chaque fois comme vrais. Mais cette spécialisation peut jouer contre lui.\n",
        "\n",
        "**Cinquième texte :**\n",
        "\n",
        "Le 5ème texte est un article climato-sceptique. On constate que le modèle échoue à le classifier comme fake news. En effet, le modèle semble très efficace pour classer les textes en fonction de leur style d'écriture, mais il lui est plus difficile de repérer le sens et le contexte dans lequel ces mots sont employés. Si un article qui utilise un langage scientifique et soigné va à l'encontre du consensus scientifique, alors le modèle risque de se tromper, comme c'est le cas pour l'article 5. Il est crucial de retenir que le modèle n'a pas de compréhension réelle des textes, il ne *sait* pas que le réchauffement climatique est réel. Il ne peut que prédire si un texte est susceptible d'être vrai ou non en fonction des mots qu'il a vu lors de l'entraînement. Deux choses à noter ici :\n",
        "- Il serait possible de pallier cette lacune en entraînant le modèle sur les types de textes sur lesquels il échoue. Par exemple s'il échoue régulièrement sur les fake news pseudoscientifiques, on pourrait lui donner plus de textes de ce type lors de la phase d'entraînement. Même sans compréhension fine du langage, ses performances augmenteraient très probablement. Par exemple, il pourrait apprendre lors de son entraînement certains mots ou bigrammes (paire de mots) associés à un type de label ou l'autre. En vulgarisant, on peut imaginer que \"warmer before\" serait associé aux fake news tandis que \"temperatures rise\" serait associé aux vrais articles. Si le modèle retrouve ces termes ou d'autres similaires dans les textes qu'il doit classer, il saurait mieux se débrouiller.\n",
        "- Un autre aspect à considérer réside dans la nature même difficile et ambigüe de la tâche de détection. Qu'est ce qu'une fake news exactement ? Selon wikipédia les fake news \"*sont des nouvelles mensongères diffusées dans le but de manipuler ou de tromper le public*\". C'est en fonction de cette définition que nous jugerons si notre modèle est performant ou non. Mais d'autres pourraient estimer qu'une fake news est une information fausse peu importe l'intention derrière. Par exemple en 1999 beaucoup de médias ont transmis au grand public la peur des OGM, en se basant sur une étude fautive. L'intention n'était pas la désinformation, mais l'information était pourtant fausse. Fake news ou non ?\n",
        "[Un des articles en question](https://www.theguardian.com/uk/1999/feb/12/4).\n",
        "\n",
        "En machine learning, on utilise parfois la performance humaine (Human Level Performance) pour situer l'efficacité de notre algorithme. Il est fortement probable qu'en fournissant la liste d'articles du dataset df_fake_true, la majorité des gens n'obtiennent pas une accuracy de 100%. L'algorithme peut ainsi être considéré comme suffisamment bon en atteignant/dépassant la performance du meilleur humain ou celle d'un groupe d'experts. On peut aussi accepter une performance inférieure si l'algorithme s'avère utile. Par exemple même si un groupe d'experts obtient une accuracy de 98%, un modèle avec seulement 92% pourrait trouver son utilité auprès du public si la performance de ce dernier atteint à peine les 70%.\n",
        "\n",
        "#**3. Quelles limites LIME met en lumière**\n",
        "\n",
        "##L'importance de\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3H6BeLmufamR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DJ36DLCyiyOX"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNuhxOZjjH7W6OFsz1JKb2I",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}