{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PAGESK/Fake_news_detector/blob/main/main_fake_news_detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nature et int√©r√™t du projet\n",
        "\n",
        "**Chaque ann√©e, le co√ªt de la d√©sinformation est estim√© √† [78 milliards de dollars](https://www.odwyerpr.com/story/public/13448/2019-11-26/cost-fake-news-78-billion.html).**\n",
        "En 2018, en analysant les tweets de 3 millions d'internautes, une √©tude a d√©montr√© que les fake news se propagent [6 fois plus rapidement sur X](https://pubmed.ncbi.nlm.nih.gov/29590045/) (Twitter) que les vrais articles.\n",
        "\n",
        "\n",
        "\n",
        "* √Ä une √©poque o√π l'information n'a jamais √©t√© aussi accessible, sa qualit√© est menac√©e par la course au sensationnalisme et la rapidit√© des r√©seaux sociaux, ce qui rend de plus en plus difficile pour le public de distinguer le vrai du faux. R√©cemment, les IA sont arriv√©es sur le devant de la sc√®ne pour le public, soulevant de nouveaux enjeux, et amplifiant parfois les probl√©matiques d√©j√† pr√©sentes en permettant de g√©n√©rer un grand nombre de donn√©es, dont la v√©racit√© n'est pas toujours le premier crit√®re.\n",
        "* Face √† ce d√©fi, le d√©veloppement d'outils de d√©tection automatis√©e est devenu essentiel. Cependant, ces mod√®les d'IA, bien que performants, sont souvent per√ßus comme des \"bo√Ætes noires\" difficiles √† interpr√©ter. Ce projet vise √† construire un syst√®me de d√©tection de fake news efficace, tout en d√©mystifiant son fonctionnement, √©tape par √©tape.\n",
        "En parcourant ce projet, n'importe qui sera capable de comprendre le fonctionnement du mod√®le, ses limites ainsi que les enjeux √©thiques et s√©curitaires dans lesquels il s'inscrit.\n"
      ],
      "metadata": {
        "id": "loGlaEYfMA1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "github_token = userdata.get('github_token')"
      ],
      "metadata": {
        "id": "fTq7rNJVrJMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf Fake_news_detector"
      ],
      "metadata": {
        "id": "Urh7sAiWbkOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!git config --global user.name \"Anasviel\"\n",
        "!git config --global user.email \"kevinpages2002@gmail.com\"\n",
        "!git config --global credential.helper store"
      ],
      "metadata": {
        "id": "ihAfpzp6KTps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://Anasviel:{github_token}@github.com/Anasviel/Fake_news_detector.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wji5Ruo3pVm_",
        "outputId": "33842c1c-f326-48e2-ee31-9f457c2efdf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Fake_news_detector'...\n",
            "remote: Enumerating objects: 121, done.\u001b[K\n",
            "remote: Counting objects: 100% (121/121), done.\u001b[K\n",
            "remote: Compressing objects: 100% (101/101), done.\u001b[K\n",
            "remote: Total 121 (delta 61), reused 52 (delta 17), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (121/121), 4.19 MiB | 2.82 MiB/s, done.\n",
            "Resolving deltas: 100% (61/61), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Fake_news_detector/"
      ],
      "metadata": {
        "id": "1DGDDPpOLNvj",
        "outputId": "0d6c5617-0ea7-4868-be68-e85d552f94e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Fake_news_detector\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f82B7KXfcC47",
        "outputId": "0033386f-a63d-48da-b60a-549e97ab1430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWEAtAsutRql",
        "outputId": "3813dc4f-e600-4bbf-bbcc-1c4d6dcdf3e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main 7877c5e] Pull n√©cessaire d√ª √† une divergence sur github\n",
            "From https://github.com/Anasviel/Fake_news_detector\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add .\n",
        "!git commit -m\"Modification d'un article plus long et plus complet dans le df_fake_true\"\n",
        "!git push origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcC7LEEu4kjC",
        "outputId": "e0395505-b49a-4931-da21-276c97030cd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main ebadb22] Modification d'un article plus long et plus complet dans le df_fake_true\n",
            " 2 files changed, 6 insertions(+), 1 deletion(-)\n",
            " rewrite logistic_regression_pipeline.joblib (94%)\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 110.69 KiB | 10.06 MiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "remote: This repository moved. Please use the new location:\u001b[K\n",
            "remote:   https://github.com/PAGESK/Fake_news_detector.git\u001b[K\n",
            "To https://github.com/Anasviel/Fake_news_detector.git\n",
            "   c2be69a..ebadb22  main -> main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I. Construction des bases du D√©tecteur de Fake News"
      ],
      "metadata": {
        "id": "ZcOaCcdl-TXu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous commen√ßons par importer les biblioth√®ques Python requises pour ce projet. Ces modules contiennent des fonctions et des classes pr√©d√©finies qui nous permettent de r√©aliser des t√¢ches sp√©cifiques (comme la manipulation de donn√©es ou l'entra√Ænement de mod√®les de machine learning) de mani√®re efficace.\n",
        "\n",
        "Chaque biblioth√®que (ou module) est un ensemble d'outils sp√©cialis√©s. Ainsi, la biblioth√®que Pandas est utilis√©e pour lire et organiser nos donn√©es sous forme de tableaux, tandis que Scikit-learn regroupe toutes les fonctions dont nous avons besoin pour nos algorithmes de machine learning.\n",
        "\n",
        "Cette approche nous √©vite de r√©inventer la roue pour chaque √©tape. C'est l'√©quivalent, pour un d√©veloppeur, d'utiliser des outils sp√©cialis√©s pour une t√¢che donn√©e plut√¥t que de les construire √† partir de z√©ro."
      ],
      "metadata": {
        "id": "A_-j6Vzu-jxr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpMVp75IGdjL",
        "outputId": "37b8f3fb-3654-4121-ffdb-bdeffa55899f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lime\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/275.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from lime) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from lime) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from lime) (1.16.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from lime) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.12/dist-packages (from lime) (1.6.1)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.12/dist-packages (from lime) (0.25.2)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (11.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (2025.6.11)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.18->lime) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.18->lime) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.17.0)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283834 sha256=9d4c4bde37d2ace4ce9df7350967096fab118998cae1c5b6ecc2888681292fed\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/5d/0e/4b4fff9a47468fed5633211fb3b76d1db43fe806a17fb7486a\n",
            "Successfully built lime\n",
            "Installing collected packages: lime\n",
            "Successfully installed lime-0.2.0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "!pip install lime\n",
        "import lime\n",
        "import lime.lime_text\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 : Pr√©paration des donn√©es, nettoyage et s√©paration"
      ],
      "metadata": {
        "id": "fnljWhEj8Ovh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La premi√®re √©tape est de pr√©parer les donn√©es avec pandas (√† ne pas confondre avec l'animal üêº).\n",
        "\n",
        "Le dataframe WELFake comprend 72 134 articles tous labell√©s ou √©tiquet√©s, vrais (1) ou faux (0). Le second dataframe df_fake_true est un tableau contenant 10 textes s√©lectionn√©s al√©atoirement dans la mesure du possible, de mon c√¥t√©. Une fois notre mod√®le entra√Æn√© sur WELFake, il donnera ses pr√©dictions sur ces textes l√† afin de v√©rifier qu'il a bien appris.\n",
        "\n",
        "Une m√©taphore souvent utilis√©e est celle de l'√©l√®ve apprenant sa le√ßon. Pour v√©rifier qu'il a appris et **compris** son contenu, on le testera sur une le√ßon diff√©rente de celle qu'il a r√©vis√©. Si on le teste sur la m√™me le√ßon, l'√©l√®ve pourrait avoir appris par coeur sa le√ßon sans r√©ellement comprendre, c'est ce qu'on appelle le suraprentissage.\n",
        "\n",
        "Le but de ce df_fake_true est de tester (dans une optique de d√©monstration car 10 textes ne sont pas un √©chantillon suffisant en r√©alit√©) si le mod√®le est capable de transposer son apprentissage √† de nouvelles donn√©es ou s'il s'av√®re inefficace."
      ],
      "metadata": {
        "id": "7kfA6sQjCWf8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z35-0eHMIC-c"
      },
      "outputs": [],
      "source": [
        "df_welfake = pd.read_csv(\"/content/Fake_news_detector/WELFake_Dataset.csv\")\n",
        "df_custom = pd.read_csv(\"/content/Fake_news_detector/df_fake_true.csv\", sep=\";\")\n",
        "\n",
        "df_filtered = df_custom[df_custom[\"text\"].notnull() & df_custom[\"label\"].notnull()]\n",
        "texts_to_predict = df_filtered[\"text\"].tolist()\n",
        "true_labels = df_filtered[\"label\"].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Affichons le df welfake d'origine\n",
        "# head(10) affiche les 10 premi√®res lignes d'un dataframe\n",
        "df_welfake.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "SddK2YqkScWx",
        "outputId": "79bf4711-caa6-42cf-9cc5-da5adfeeaa02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                              title  \\\n",
              "0           0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...   \n",
              "1           1                                                NaN   \n",
              "2           2  UNBELIEVABLE! OBAMA‚ÄôS ATTORNEY GENERAL SAYS MO...   \n",
              "3           3  Bobby Jindal, raised Hindu, uses story of Chri...   \n",
              "4           4  SATAN 2: Russia unvelis an image of its terrif...   \n",
              "5           5  About Time! Christian Group Sues Amazon and SP...   \n",
              "6           6  DR BEN CARSON TARGETED BY THE IRS: ‚ÄúI never ha...   \n",
              "7           7  HOUSE INTEL CHAIR On Trump-Russia Fake Story: ...   \n",
              "8           8  Sports Bar Owner Bans NFL Games‚Ä¶Will Show Only...   \n",
              "9           9  Latest Pipeline Leak Underscores Dangers Of Da...   \n",
              "\n",
              "                                                text  label  \n",
              "0  No comment is expected from Barack Obama Membe...      1  \n",
              "1     Did they post their votes for Hillary already?      1  \n",
              "2   Now, most of the demonstrators gathered last ...      1  \n",
              "3  A dozen politically active pastors came here f...      0  \n",
              "4  The RS-28 Sarmat missile, dubbed Satan 2, will...      1  \n",
              "5  All we can say on this one is it s about time ...      1  \n",
              "6  DR. BEN CARSON TELLS THE STORY OF WHAT HAPPENE...      1  \n",
              "7                                                         1  \n",
              "8  The owner of the Ringling Bar, located south o...      1  \n",
              "9  FILE ‚Äì In this Sept. 15, 2005 file photo, the ...      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1264bb30-7114-4e9d-a409-ddc3ad4eb808\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>LAW ENFORCEMENT ON HIGH ALERT Following Threat...</td>\n",
              "      <td>No comment is expected from Barack Obama Membe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Did they post their votes for Hillary already?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>UNBELIEVABLE! OBAMA‚ÄôS ATTORNEY GENERAL SAYS MO...</td>\n",
              "      <td>Now, most of the demonstrators gathered last ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Bobby Jindal, raised Hindu, uses story of Chri...</td>\n",
              "      <td>A dozen politically active pastors came here f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>SATAN 2: Russia unvelis an image of its terrif...</td>\n",
              "      <td>The RS-28 Sarmat missile, dubbed Satan 2, will...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>About Time! Christian Group Sues Amazon and SP...</td>\n",
              "      <td>All we can say on this one is it s about time ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>DR BEN CARSON TARGETED BY THE IRS: ‚ÄúI never ha...</td>\n",
              "      <td>DR. BEN CARSON TELLS THE STORY OF WHAT HAPPENE...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>HOUSE INTEL CHAIR On Trump-Russia Fake Story: ...</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>Sports Bar Owner Bans NFL Games‚Ä¶Will Show Only...</td>\n",
              "      <td>The owner of the Ringling Bar, located south o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>Latest Pipeline Leak Underscores Dangers Of Da...</td>\n",
              "      <td>FILE ‚Äì In this Sept. 15, 2005 file photo, the ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1264bb30-7114-4e9d-a409-ddc3ad4eb808')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1264bb30-7114-4e9d-a409-ddc3ad4eb808 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1264bb30-7114-4e9d-a409-ddc3ad4eb808');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-381fa5d7-76b8-4969-a57b-c34e72df2b48\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-381fa5d7-76b8-4969-a57b-c34e72df2b48')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-381fa5d7-76b8-4969-a57b-c34e72df2b48 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_welfake",
              "summary": "{\n  \"name\": \"df_welfake\",\n  \"rows\": 72134,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20823,\n        \"min\": 0,\n        \"max\": 72133,\n        \"num_unique_values\": 72134,\n        \"samples\": [\n          61370,\n          2189,\n          60609\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 62347,\n        \"samples\": [\n          \"BBC Under Fire for \\u2018Transgender Diaries\\u2019 Program Aimed at Children as Young as Six\",\n          \" Hillary\\u2019s Running Mate Tim Kaine: The NRA Hates Him, And He Kicked Their Butts (VIDEO)\",\n          \" Trump Outrageously Refers To Elizabeth Warren As \\u2018Pocahontas\\u2019 During Meeting With Senators\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 62718,\n        \"samples\": [\n          \"WASHINGTON (Reuters) - Michael Cohen, one of President Donald Trump\\u2019s closest business advisers, said on Sunday he would testify on Tuesday to the U.S. Senate Intelligence Committee, as the panel investigates alleged Russian interference in the 2016 U.S. election. The timing of Cohen\\u2019s testimony was first reported by NBC. Cohen confirmed that he would testify to the committee on Tuesday and said he did not know whether it would be in a closed session or public. Aides to the committee\\u2019s leaders did not immediately respond to requests for comment. Cohen said previously he had received a subpoena from at least one of the congressional committees investigating what U.S. intelligence has determined were Russia\\u2019s efforts to influence the election on Trump\\u2019s behalf, and whether Trump associates colluded with Russia. Russia denies such activity. The White House denies any collusion, but concerns about the issue and Trump\\u2019s ties to Russia have shadowed the first months of the Republican\\u2019s presidency. Cohen, a personal attorney to Trump, would be one of a series of close associates of the president to testify in Congress. Members of both the Senate and House of Representatives committees conducting investigations have said they expect to call more. Trump\\u2019s oldest son, Donald Trump Jr., testified to the Senate Judiciary Committee earlier this month. \",\n          \"HARARE (Reuters) - Zimbabwe s main opposition leader said on Monday President Robert Mugabe s refusal to resign had dampened people s spirits and called for an inclusive political process in the aftermath of a military intervention last week. Morgan Tsvangirai said there should be an all-stakeholders meeting to chart the country s future and that the next elections due next year should be supervised by the international community. \",\n          \"There is no word yet about whether or not the Hispanics in question were referred to by the plaintiff as  White Hispanics, (the George Zimmerman variety) Legendary restaurant Roscoe s House of Chicken  n Waffles has to cough up $1.6 million in an unlawful termination suit to an African American man who claimed he was discriminated against because he was black.The claim proves to be somewhat ironic given that the owner of the eatery, where President Barack Obama once dined when visiting Compton, is African American.CBS Los Angeles reported that Daniel Beasley sued Roscoe s for firing him after he complained to human resources that the managers harassed him for being black and gave preferential treatment, such as better work hours, to the Hispanic employees. It s owned by an African American owner, but he gives full authority to the Hispanics to run it,  Beasley told reporters.  It just caught me by surprise because here I am getting fired when I m trying to fix the problem. Beasley was frustrated that his complaints to management never got addressed, so he sued.  It s owned by an African American owner, but he gives full authority to the Hispanics to run it,  he told reporters.  It just caught me by surprise because here I am getting fired when I m trying to fix the problem. Beasley explained to CBS that he became homeless after he lost his job, so the hefty settlement becomes a huge victory for the grandfather from Compton.His lawyer Scott Cummings hopes that this win sends a message to other businesses out there.  Racism, racial harassment can occur really anywhere even in a black-owned business,  he asserted. Beasley added,  You can t treat people like that and get away with it constantly.  Via: Breitbart News\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour des raisons de clart√©, nous renommons d'abord la colonne label en veracity. Cette colonne est notre variable cible (y), que nous cherchons √† pr√©dire : un article vrai (1) ou faux (0).\n",
        "\n",
        "Ensuite, nous m√©langeons l'ensemble du DataFrame. La m√©thode sample(frac=1) s√©lectionne de mani√®re al√©atoire 100% des lignes, ce qui permet de r√©organiser l'int√©gralit√© des donn√©es. Cette √©tape est cruciale pour √©viter tout biais d'entra√Ænement. En fixant le random_state √† 42, nous nous assurons que ce m√©lange soit toujours identique, garantissant ainsi la reproductibilit√© de nos r√©sultats. En modifiant la valeur 42 manuellement vous pouvez observer que le m√©lange sera toujours identique pour le nombre que vous fixez.\n",
        "\n",
        "Nous d√©velopperons cette notion de reproductibilit√© plus en d√©tail par la suite.\n"
      ],
      "metadata": {
        "id": "JrZsyzBdS1rE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEsQ6MnPLQEz"
      },
      "outputs": [],
      "source": [
        "df_news = df_welfake\n",
        "df_news.rename(columns={\"label\":\"veracity\"}, inplace=True)\n",
        "random_state = 42\n",
        "df_news = df_news.sample(frac=1, random_state=random_state).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "578Lm2XSLiDH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "a729cc8c-4b50-4b17-8a7e-57d8f25b522f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                              title  \\\n",
              "0       61370  ARNOLD SCHWARZENEGGER Sends A Message To Liber...   \n",
              "1        2189  WOW! ‚ÄúWe Mexicans Need To Kill Donald Trump Be...   \n",
              "2       60609  Jimmy Carter recovers from dehydration scare i...   \n",
              "3       51565  2 Friars‚Äô Mission: Reviving a Brooklyn Church ...   \n",
              "4       39431  Boy With Autism Makes His First Friend Ever An...   \n",
              "5       47839   Something Truly Extraordinary, And Refreshing...   \n",
              "6       42729                      #Hashtag Hell & The Fake Left   \n",
              "7       37882  Vice President-elect Pence says 'new hope dawn...   \n",
              "8       10893  Trump to Republican senators: Don't leave town...   \n",
              "9       46977  White House: Obama May Leave the Country if Tr...   \n",
              "\n",
              "                                                text  veracity  \n",
              "0                                                            1  \n",
              "1  And now a message of peace and unity from one ...         1  \n",
              "2  WINNIPEG, Manitoba (Reuters) - Former U.S. Pre...         0  \n",
              "3  The two Franciscan friars, complete with   rob...         0  \n",
              "4  Approximately 1 in 68 children has an autism s...         1  \n",
              "5  The CNN debate between Democratic candidates H...         1  \n",
              "6   By Dady Chery and Gilbert MercierAll writers ...         1  \n",
              "7  WASHINGTON (Reuters) - U.S. Vice President-ele...         0  \n",
              "8  WASHINGTON (Reuters) - U.S. President Donald T...         0  \n",
              "9  0 comments \\nThe White house is refusing to de...         1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4be3009e-104e-483c-ae96-97ae2cadbda1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>veracity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>61370</td>\n",
              "      <td>ARNOLD SCHWARZENEGGER Sends A Message To Liber...</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2189</td>\n",
              "      <td>WOW! ‚ÄúWe Mexicans Need To Kill Donald Trump Be...</td>\n",
              "      <td>And now a message of peace and unity from one ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60609</td>\n",
              "      <td>Jimmy Carter recovers from dehydration scare i...</td>\n",
              "      <td>WINNIPEG, Manitoba (Reuters) - Former U.S. Pre...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>51565</td>\n",
              "      <td>2 Friars‚Äô Mission: Reviving a Brooklyn Church ...</td>\n",
              "      <td>The two Franciscan friars, complete with   rob...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>39431</td>\n",
              "      <td>Boy With Autism Makes His First Friend Ever An...</td>\n",
              "      <td>Approximately 1 in 68 children has an autism s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>47839</td>\n",
              "      <td>Something Truly Extraordinary, And Refreshing...</td>\n",
              "      <td>The CNN debate between Democratic candidates H...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>42729</td>\n",
              "      <td>#Hashtag Hell &amp; The Fake Left</td>\n",
              "      <td>By Dady Chery and Gilbert MercierAll writers ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>37882</td>\n",
              "      <td>Vice President-elect Pence says 'new hope dawn...</td>\n",
              "      <td>WASHINGTON (Reuters) - U.S. Vice President-ele...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>10893</td>\n",
              "      <td>Trump to Republican senators: Don't leave town...</td>\n",
              "      <td>WASHINGTON (Reuters) - U.S. President Donald T...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>46977</td>\n",
              "      <td>White House: Obama May Leave the Country if Tr...</td>\n",
              "      <td>0 comments \\nThe White house is refusing to de...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4be3009e-104e-483c-ae96-97ae2cadbda1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4be3009e-104e-483c-ae96-97ae2cadbda1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4be3009e-104e-483c-ae96-97ae2cadbda1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4370d29f-1de4-4fa4-9e7d-cb3f7d3f4fb6\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4370d29f-1de4-4fa4-9e7d-cb3f7d3f4fb6')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4370d29f-1de4-4fa4-9e7d-cb3f7d3f4fb6 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_news",
              "summary": "{\n  \"name\": \"df_news\",\n  \"rows\": 72134,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20823,\n        \"min\": 0,\n        \"max\": 72133,\n        \"num_unique_values\": 72134,\n        \"samples\": [\n          42039,\n          18874,\n          30203\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 62347,\n        \"samples\": [\n          \" Trump Accidentally Says He Wants Single Payer In Latest Tweet \\u2013 Twitter Lets Him Know (TWEETS)\",\n          \"(VIDEO) JUDGE JEANINE: FREE SPEECH IS NON-NEGOTIABLE \\u2013 PERIOD!\",\n          \"Hispanic claims victory in Harlem race to replace Rangel in U.S. Congress\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 62718,\n        \"samples\": [\n          \"For some reason, Donald Trump decided to speak to a group of women at a women s empowerment event on Wednesday, on one of the final days of Women s History Month. It didn t go well.First he bragged about the number of women in his cabinet. There are six women. Out of 24. That s 25 percent. Less than half of what would be representative of the nation as a whole. It s also the whitest and most male cabinet since Ronald Reagan.It got worse. Trump went on to name women, famous women, although there s no indication that Trump knew why many of them were famous. The first part wasn t soooooo bad: Since the very beginning, women have driven, and I mean, each generation of Americans, towards a more free and more prosperous future,  Trump said.  These patriots are women like the legendary Abigail Adams, right? Who, during the founding, urged her husband to remember the rights of women. She was very much a pioneer in that way. We ve been blessed with courageous heroes like Harriet Tubman who escaped slavery. And went on to deliver hundreds of others to freedom, first in the underground railroad and then as a spy for the union army. She was very, very courageous, believe me. Source: Raw StoryIt very quickly became clear he was out of his intellectual element when he completed that thought with:Around we ve had leaders like Susan B. Anthony. Have you heard of Susan B. Anthony? I m shocked that you ve heard of her   who dreamed of a much more fair and equal future and an America where women themselves as she said helped to make laws and elect the lawmakers, and that s what s happening more and more. Of course, it s not shocking at all that a group of women have in fact heard of the suffragette and all around social justice warrior. There was even a coin with her face on it, but to be fair, it s doubtful Trump carries cash. Other people pay all of his bills.Trump, though, had clearly never heard of Anthony, at least before someone briefed him right before the event.Here s the video:Perhaps Trump s handlers (whoever they are) need to remind the orange dictator that he should never, ever speak to people who aren t white and male.Featured image via video screen capture\",\n          \"President-elect Donald J. Trump s economic advisor Steve Moore told Neil Cavuto the incoming administration may introduce two separate tax bills to increase chances of prompt Congressional approval. Moore says Trump s tax reform plan should primarily focus on slashing the corporate tax rate to somewhere between 15% and 20%. \",\n          \"The majestic giraffe, the world\\u2019s tallest land mammal and a prime attraction at zoos worldwide, is threatened with extinction because of illegal hunting and a loss of its habitat, according to a report published on Thursday by an international monitoring group. The giraffe population has declined by 40 percent over the past three decades and now stands at about 97, 600, according to the findings by the International Union for the Conservation of Nature, which designates endangered species. While the largest giraffe populations reside in national parks and reserves, those protected areas have proved to be inadequate, one of several alarming conclusions about the animals\\u2019 future in the group\\u2019s latest Red List of Threatened Species report. \\u201cWhile global attention has been on threats to elephants and rhinos, giraffes have been off the radar, and we\\u2019ve been losing them in significant numbers,\\u201d said Liz Bennett, the vice president for species conservation for the Wildlife Conservation Society, which was not involved in the report. \\u201cPeople and governments need to start acting to save giraffes, fast. \\u201d With their soaring heights of up to 20 feet and their stunning necks, which are typically about six feet long, giraffes have long been the stuff of dreams  \\u2014   for children who love to draw them and for adults who retain an awe for the otherworldly creatures. Their tongues can extend a foot or more, making feeding times an especially popular sight at zoos and on safari. Yet the animals\\u2019 rare size and regal visage have made them a prime target of poachers in Africa, who drop   snares from tree canopies or stalk and shoot giraffes with rifles, wildlife experts say. The threat to giraffes is so great that the Red List upgraded the species from the \\u201cleast concern\\u201d category to \\u201cvulnerable,\\u201d skipping over the intermediary \\u201c \\u201d designation. Graver categories include \\u201ccritically endangered,\\u201d \\u201cextinct in the wild\\u201d and, ultimately, \\u201cextinct. \\u201d The animals are divided into nine subspecies according to the Red List report, five have decreasing populations, three are on the increase, and one is stable. One bright spot: The numbers of West African giraffes are on the rise, numbering about 400 now, up from 50 in the 1990s. This remains the smallest of the subspecies. Asked if it was possible for giraffes to become extinct in the wild in the next 20 years if nothing is done, Derek Lee, an ecologist who contributed to the Red List report, paused for several moments during a phone interview on Thursday from Tanzania. He then said, \\u201cI think we\\u2019d see drastic declines at the very least. \\u201d Giraffes are found mostly in southern and eastern Africa, with smaller populations in West and Central Africa. Some of those populations are particularly vulnerable because of war and other civil unrest in countries on the Continent, like Sudan. Poaching and the loss of habitat are \\u201cequally dangerous threats that vary in degree from place to place,\\u201d said Dr. Lee, who is a founder of the Wild Nature Institute. While governments and organizations could take stronger actions against poaching by enforcing laws and animal protection rules, habitat loss can be harder to stop because it involves curbing economic activity, such as land development, mining and scavenging. \\u201cThese are problems everywhere for giraffes,\\u201d Dr. Lee said. \\u201cYou need to stop both threats. \\u201d The threat to giraffes is not expected to affect their numbers at zoos in New York and other cities around the world, wildlife specialists said, because zookeepers have a good record helping the animals with reproduction. Still, zoo leaders are likely to consider changing signs at their exhibits to stress the animals\\u2019 vulnerability to extinction as a way to raise public awareness. \\u201cThat would be the best way to get the word out to people that we need to do more to protect these animals,\\u201d said Dr. Bennett, of the conservation society, which runs the Bronx Zoo, the New York Aquarium and other zoos in the city.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"veracity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#Pour comparer les changements, affichons les 10 premi√®re lignes apr√®s shuffle et modification de la colonne label\n",
        "#Si tout a fonctionn√© correctment, la premi√®re ligne affich√©e contient le nom d'un c√©l√®bre bodybuilder (avec random_state=42)\n",
        "df_news.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La premi√®re √©tape est le pr√©traitement des donn√©es. Pour que notre mod√®le puisse interpr√©ter et apprendre de nos textes, nous devons d'abord les nettoyer et les formater correctement. La fonction stop_words.update([ ]) contient une liste de mots que nous pourrons ajouter plus tard pour √©carter d'autres mots.\n",
        "\n",
        "Les stop words, comme \"we\", \"the\" ou \"is\", sont des mots tr√®s fr√©quents en anglais qui n'apportent pas d'informations pertinentes pour la classification. Comme ils sont tr√®s fr√©quents dans tous les types de textes, le mod√®le ne peut pas discriminer la nature d'un texte √† partir de ceux-ci. Les supprimer permet de r√©duire le bruit dans nos donn√©es.\n",
        "\n",
        "Nous utilisons √©galement la lemmatisation, une technique qui consiste √† r√©duire les mots √† leur forme de base ou \"racine\". Par exemple, \"dancing\" et \"danced\" deviennent \"dance\", et \"is\" devient \"be\". Cela simplifie le vocabulaire du texte et am√©liore la capacit√© du mod√®le √† g√©n√©raliser ses apprentissages."
      ],
      "metadata": {
        "id": "sSVEdwuOVFtN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLkmrRXZLrSa"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words(\"english\"))\n",
        "initial_stop_words = stop_words.copy()\n",
        "stop_words.update([\"words to replace\"])\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Une √©tape cruciale du pr√©traitement des donn√©es est la cr√©ation d‚Äôune fonction de nettoyage personnalis√©e üßπ.\n",
        "\n",
        "Le code ci-dessous d√©finit une telle fonction, qui pr√©pare nos textes pour l‚Äôanalyse en effectuant plusieurs op√©rations :\n",
        "\n",
        "\n",
        "\n",
        "Uniformiser le texte : chaque texte est converti en minuscules pour que le mod√®le traite \"The\" et \"the\" comme un seul et m√™me mot.\n",
        "\n",
        "\n",
        "\n",
        "G√©rer les nombres : tous les chiffres sont remplac√©s par un token unique (_num_). Cette approche permet au mod√®le de reconna√Ætre la pr√©sence d‚Äôun nombre sans se concentrer sur sa valeur exacte.\n",
        "\n",
        "\n",
        "\n",
        "Nettoyer la ponctuation : les caract√®res sp√©ciaux et la ponctuation sont supprim√©s afin de ne garder que les lettres.\n",
        "\n",
        "\n",
        "\n",
        "Lemmatisation et suppression des stop words : le texte est tokenis√© (divis√© en mots).\n",
        "\n",
        "\n",
        "Exemple : \"Le chat mange la souris.\" : [\"Le\", \"chat\", \"mange\", \"la\", \"souris\", \".\"]\n",
        "\n",
        "Puis chaque mot est ramen√© √† sa forme de base (lemmatisation) et les stop words sont retir√©s.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Ce code d√©finit √©galement une seconde fonction de nettoyage, qui effectue les m√™mes √©tapes mais supprime compl√®tement les nombres au lieu de les remplacer. Cette variante nous permettra de tester plus tard si la pr√©sence de chiffres am√©liore les pr√©dictions du mod√®le ou les impacte n√©gativement.\n",
        "\n",
        "Enfin, les deux fonctions sont encapsul√©es dans un FunctionTransformer.\n",
        "\n",
        "Cet outil de Scikit-learn est indispensable, car il nous permet d‚Äôint√©grer nos fonctions de pr√©traitement personnalis√©es directement dans le pipeline du mod√®le, rendant ainsi le processus plus fluide et standardis√©.\n",
        "\n",
        "üëâ M√©taphore : imaginez que nous voulions nettoyer une surface.\n",
        "\n",
        "Nous cr√©ons deux m√©langes nettoyants pour supprimer les corps gras, les taches de fruitsrouges  et √©liminer les bact√©ries.\n",
        "\n",
        "Nous ne sommes pas certains du dosage exact d‚Äôun des produits, alors nous allons d√©finir deux m√©langes identiques, √† l‚Äôexception de ce produit.\n",
        "\n",
        "Puis nous testerons ces deux m√©langes pour voir lequel est le plus efficace, avant de l‚Äôutiliser sur la surface √† nettoyer."
      ],
      "metadata": {
        "id": "SMDPcwhUY60D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1cSf4FUSMTc"
      },
      "outputs": [],
      "source": [
        "def clean_text_func(text):\n",
        "  if not isinstance(text, str):\n",
        "        return \"\"\n",
        "  text = text.lower()\n",
        "  text = re.sub(r'\\d+', '_num_', text)\n",
        "  text = re.sub(r'[^a-z0-9\\s_]', '', text)\n",
        "  words = nltk.word_tokenize(text)\n",
        "  words = [lemmatizer.lemmatize(word, pos='n') for word in words if word not in stop_words]\n",
        "  return ' '.join(words)\n",
        "\n",
        "def apply_clean_text(texts):\n",
        "    return [clean_text_func(text) for text in texts]\n",
        "text_cleaning_transformer = FunctionTransformer(apply_clean_text, validate=False, accept_sparse=False)\n",
        "\n",
        "\n",
        "def clean_text_no_numbers(text):\n",
        "  if not isinstance(text, str):\n",
        "        return \"\"\n",
        "  text = text.lower()\n",
        "  text = re.sub(r'\\d+', '', text)\n",
        "  text = re.sub(r'[^a-z0-9\\s_]', '', text)\n",
        "  words = nltk.word_tokenize(text)\n",
        "  words = [lemmatizer.lemmatize(word, pos='n') for word in words if word not in stop_words]\n",
        "  return ' '.join(words)\n",
        "\n",
        "def apply_clean_text_no_numbers(texts):\n",
        "    return [clean_text_no_numbers(text) for text in texts]\n",
        "text_cleaning_transformer_no_numbers = FunctionTransformer(apply_clean_text_no_numbers, validate=False, accept_sparse=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En machine learning, on distingue les donn√©es d'entr√©e (X ou features ou input) de la variable cible (y ou labels ou output). L'input (X) repr√©sente les donn√©es utilis√©es pour entra√Æner le mod√®le (dans notre cas, le texte des articles), tandis que l'output (y) est la r√©ponse que le mod√®le doit apprendre √† pr√©dire (la v√©racit√© de l'article).\n",
        "\n",
        "√âtant donn√© que notre colonne \"v√©racit√©\" est d√©j√† enti√®rement √©tiquet√©e, nous disposons de la v√©rit√© terrain. Le mod√®le va faire ses pr√©dictions sur ces donn√©es, et nous pourrons ensuite comparer ses r√©ponses (y pr√©dit) aux √©tiquettes r√©elles (y r√©el) pour √©valuer sa performance.\n",
        "\n",
        "On parle d'apprentissage supervis√© car les labels sont d√©j√† connues. C'est la m√©thode que nous utilisons pour notre d√©tecteur de fausses nouvelles. Il existe d'autres types d'apprentissage mais nous nous concentrerons exclusivement sur l'apprentissage supervis√© pour notre d√©tecteur de fake news."
      ],
      "metadata": {
        "id": "9in5Y1L6C0YS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVgG_L3dS2-y"
      },
      "outputs": [],
      "source": [
        "X = df_news[\"text\"]\n",
        "y = df_news[\"veracity\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous utilisons la fonction train_test_split de la biblioth√®que Scikit-learn pour diviser notre jeu de donn√©es en deux parties :\n",
        "\n",
        "Un ensemble d'entra√Ænement (X_train, y_train), sur lequel le mod√®le apprendra √† faire le lien entre le texte et la v√©racit√©.\n",
        "\n",
        "Un ensemble de test (X_test, y_test), qui sera utilis√© pour √©valuer la performance du mod√®le sur des donn√©es qu'il n'a jamais vues.\n",
        "\n",
        "Cette approche est essentielle pour √©viter le surapprentissage. C'est comme si, pour un ensemble de 10 exercices de math√©matiques, on donnait √† un √©l√®ve 8 exercices avec le corrig√© pour ses r√©visions, puis qu'on l'√©valuait sur les 2 exercices restants, sans lui fournir le corrig√© cette fois.\n",
        "\n",
        "Analyse des ensembles de donn√©es\n",
        "La commande .shape permet de v√©rifier les dimensions de nos jeux de donn√©es. Nous pouvons ainsi confirmer que l'ensemble de test (X_test) repr√©sente bien 20% des donn√©es (comme sp√©cifi√© par l'argument test_size=0.2), tandis que 80% sont allou√©s √† l'entra√Ænement.\n",
        "\n",
        "L'argument stratify=y est crucial : il garantit que la r√©partition des labels (la proportion d'articles vrais et faux) est la m√™me dans l'ensemble d'entra√Ænement et de test. Cela assure que notre mod√®le n'est pas biais√© et que l'√©valuation est juste. Comme le montrent les r√©sultats ci-dessous, la distribution des labels 0 et 1 est relativement √©quilibr√©e et coh√©rente entre les deux ensembles."
      ],
      "metadata": {
        "id": "Uf_6NiXnLsEf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hRdyexRHNkO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db18fac4-3e69-4d67-9de2-e04f29bb554d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original data shape : (72134,)\n",
            "Training data shape : (57707,)\n",
            "Testing data shape : (14427,) \n",
            "\n",
            "Training labels distribution: \n",
            " veracity\n",
            "1    29685\n",
            "0    28022\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Testing labels distribution: \n",
            " veracity\n",
            "1    7421\n",
            "0    7006\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "print(f\"Original data shape : {X.shape}\")\n",
        "print(f\"Training data shape : {X_train.shape}\")\n",
        "print(f\"Testing data shape : {X_test.shape} \\n\")\n",
        "print(f\"Training labels distribution: \\n {y_train.value_counts()}\\n\")\n",
        "print(f\"Testing labels distribution: \\n {y_test.value_counts()}\")\n",
        "\n",
        "df_news[\"text\"] = df_news[\"text\"].fillna('')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tout au long de ce notebook, trois mod√®les diff√©rents seront mentionn√©s. Nous travaillerons principalement avec un seul de ces trois, mais si vous d√©sirez comprendre leurs sp√©cificit√©s, cette fiche explicative est faite pour vous :\n",
        "\n",
        "## 2 : Fiche explicative des trois mod√®les üìÑ\n",
        "**1. MultinomialNB (Na√Øve Bayes multinomial)**\n",
        "\n",
        "C‚Äôest l‚Äôalgorithme le plus ¬´ simple ¬ª des trois.\n",
        "Il repose sur une hypoth√®se forte : les mots d‚Äôun texte sont ind√©pendants les uns des autres.\n",
        "Pour chaque classe (vrai / faux), le mod√®le calcule la probabilit√© de chaque mot d‚Äôappartenir √† cette classe.\n",
        "Pour pr√©dire la classe d‚Äôun texte, il additionne ces probabilit√©s (ou plus exactement les log-probabilit√©s) pour chaque mot, puis choisit la classe la plus probable.\n",
        "\n",
        "- Avantages : rapide, facile √† comprendre, fonctionne bien avec des donn√©es textuelles simples.\n",
        "- Limites : l‚Äôhypoth√®se d‚Äôind√©pendance est rarement vraie et peut ignorer des relations importantes entre les mots.\n",
        "\n",
        "**2. Logistic Regression**\n",
        "\n",
        "La r√©gression logistique attribue un poids √† chaque mot, refl√©tant son influence sur la probabilit√© qu‚Äôun texte appartienne √† la classe vrai ou faux.\n",
        "Elle combine ensuite ces poids pour calculer directement la probabilit√© de chaque classe pour un texte donn√©.\n",
        "\n",
        "Diff√©rence cl√© avec Na√Øve Bayes :\n",
        "\n",
        "- Avantages : rapide √† entra√Æner, robuste, fonctionne bien sur du texte\n",
        "- Inconv√©nients : suppose que la relation est lin√©aire, peut manquer des relations plus complexes\n",
        "\n",
        "Na√Øve Bayes part de la classe et estime la probabilit√© des mots (P(mots | classe)). On dit \"Quelle est la probabilit√© de trouver ce mot, sachant la probabilit√© de cette classe ?\"\n",
        "\n",
        "La r√©gression logistique estime directement la probabilit√© de la classe √† partir des mots (P(classe | mots)) : \"Quelle est la probabilit√© de cette classe, sachant ce mot ?\"\n",
        "\n",
        "**M√©taphore :** si ces mod√®les √©taient des d√©tectives,\n",
        "\n",
        "Na√Øve Bayes additionnerait les probabilit√©s de chaque indice ind√©pendamment.\n",
        "\n",
        "R√©gression logistique analyserait le poids combin√© de tous les indices pour d√©cider du verdict.\n",
        "\n",
        "**3. LinearSVC (Linear Support Vector Machine)**\n",
        "\n",
        "LinearSVC cherche √©galement √† s√©parer les textes vrais des textes faux, mais sa strat√©gie est diff√©rente.\n",
        "Il trace une fronti√®re de d√©cision (hyperplan) dans un espace √† plusieurs dimensions (une dimension par mot), de mani√®re √† maximiser la marge entre cette fronti√®re et les textes les plus proches (appel√©s vecteurs de support).\n",
        "\n",
        "- Avantages : robuste aux donn√©es bruit√©es, efficace pour des jeux de donn√©es complexes.\n",
        "- Limites : ne donne pas directement de probabilit√©s, n√©cessite un r√©glage attentif des hyperparam√®tres et plus long √† entra√Æner."
      ],
      "metadata": {
        "id": "2-K9RpumNyGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Note : Ce code n'est pas n√©cessaire au fonctionnement du mod√®le. Il sert √† afficher les graphiques pour mieux visualier le fonctionnement de nos trois algorithmes.\n",
        "#Par d√©faut, la cellule ne s'ex√©cute pas pour permettre un parcours plus efficace du notebook,\n",
        "#Si vous souhaitez tout de m√™me lancer le code, retirer la ligne bleue : %%script echo skip.\n",
        "#Pensez √† r√©√©crire la ligne une fois le code ex√©cut√©, sinon cette cellule de code optionnelle s'ex√©cutera inutilement √† chaque lancement du notebook.\n",
        "\n",
        "random_state = 42\n",
        "models = [\n",
        "    (\"MultinomialNB\", MultinomialNB(alpha=1, fit_prior=False, class_prior=[0.5, 0.5])),\n",
        "    (\"Logistic Regression\", LogisticRegression(C=0.1, max_iter=1000, random_state=random_state, solver=\"liblinear\")),\n",
        "    (\"LinearSVC\", LinearSVC(C=0.1, max_iter=1000, random_state=random_state))\n",
        "]\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "for ax, (name, clf) in zip(axes, models):\n",
        "    pipeline = Pipeline([\n",
        "        (\"cleaner\", text_cleaning_transformer),\n",
        "        (\"tfidf\", TfidfVectorizer(max_features=1000, ngram_range=(1,1))),\n",
        "        (\"classifier\", clf)\n",
        "    ])\n",
        "\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    vectorizer = pipeline.named_steps[\"tfidf\"]\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "    if name == \"MultinomialNB\":\n",
        "        log_prob_fake = clf.feature_log_prob_[0]\n",
        "        log_prob_true = clf.feature_log_prob_[1]\n",
        "        scores = log_prob_true - log_prob_fake\n",
        "    else:\n",
        "        scores = pipeline.named_steps[\"classifier\"].coef_[0]\n",
        "\n",
        "    df_scores = pd.DataFrame({\"word\": feature_names, \"score\": scores})\n",
        "    top_words = pd.concat([df_scores.nsmallest(10, \"score\"), df_scores.nlargest(10, \"score\")]).sort_values(by=\"score\")\n",
        "\n",
        "    colors = [\"red\" if s < 0 else \"green\" for s in top_words[\"score\"]]\n",
        "    ax.barh(top_words[\"word\"], top_words[\"score\"], color=colors)\n",
        "    ax.set_title(name, fontsize=14)\n",
        "    ax.set_xlabel(\"Score / Poids\")\n",
        "    ax.axvline(0, color=\"black\", linewidth=0.8)\n",
        "\n",
        "fig.suptitle(\"Mots les plus influents par algorithme\", fontsize=18)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "id": "pz-XXZuvTmgV",
        "outputId": "ec087ffe-8cb1-4e2c-d097-cfbc0819b93e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2144544176.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     ])\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tfidf\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0mrouted_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_method_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrouted_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pipeline\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, routed_params, raw_params)\u001b[0m\n\u001b[1;32m    586\u001b[0m             )\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[1;32m    589\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[1;32m   1549\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m             res = transformer.fit(X, y, **params.get(\"fit\", {})).transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    919\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/preprocessing/_function_transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \"\"\"\n\u001b[1;32m    259\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkw_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m         \u001b[0moutput_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_output_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"transform\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dense\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/preprocessing/_function_transformer.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, X, func, kw_args)\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_identity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkw_args\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkw_args\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__sklearn_is_fitted__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3493367763.py\u001b[0m in \u001b[0;36mapply_clean_text\u001b[0;34m(texts)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapply_clean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclean_text_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mtext_cleaning_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapply_clean_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3493367763.py\u001b[0m in \u001b[0;36mclean_text_func\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\d+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_num_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'[^a-z0-9\\s_]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/re/__init__.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[0;32m--> 186\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x600 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 : Visualisation des r√©sultats des mod√®les"
      ],
      "metadata": {
        "id": "h6Sp7fwFZZs_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Graphique MultinomialNB :**\n",
        "\n",
        "On observe ici le fonctionnement du mod√®le MultinomialNB, qui attribue √† chaque mot de notre corpus un score de probabilit√© logarithmique. On peut voir ce score comme une empreinte num√©rique indiquant √† quel point un mot est \"typique\" d‚Äôune classe donn√©e (vrai ou faux article).\n",
        "\n",
        "En calculant la diff√©rence entre ces scores pour les deux classes, on met en √©vidence les mots les plus discriminants. Ces mots jouent un r√¥le semblable √† celui d‚Äôindices dans une enqu√™te polici√®re : certains sont anodins, d‚Äôautres permettent de r√©soudre l‚Äô√©nigme presque √† eux seuls.\n",
        "\n",
        "On note par exemple la pr√©sence de termes tr√®s pr√©dictifs comme \"reuters\", qui trahissent une fuite de donn√©es (data leakage). Le mod√®le utilise ici des indices qu‚Äôil n‚Äôaurait pas d√ª avoir √† disposition pour pr√©dire la classe, ce qui menace sa capacit√© √† g√©n√©raliser √† de nouvelles donn√©es. Nous verrons plus loin comment corriger ce biais.\n",
        "\n",
        "**Graphique Logistic Regression :**\n",
        "\n",
        "Dans ce graphique, le mod√®le de r√©gression logisitique utilise un autre m√©canisme : il assigne un poids (ou coefficient) √† chaque mot, plut√¥t qu‚Äôun score probabiliste. On peut l‚Äôimaginer comme un syst√®me de balance : les mots √† poids √©lev√© penchent fortement la pr√©diction vers une classe donn√©e.\n",
        "\n",
        "On constate que les mots jug√©s les plus pr√©dictifs ne sont pas exactement les m√™mes que pour MultinomialNB, ce qui illustre la diff√©rence de fonctionnement entre les deux mod√®les. Pourtant, les termes en t√™te, tels que \"reuters\", \"via\" et \"image\", sont identiques √† ceux du mod√®le pr√©c√©dent et affichent un poids bien sup√©rieur aux autres.\n",
        "\n",
        "Cela renforce l‚Äôhypoth√®se d‚Äôun data leakage : ces termes ne font pas partie du contenu s√©mantique de l‚Äôarticle, mais sont des m√©tadonn√©es (indices li√©s √† la source ou au format). Un mod√®le qui fonctionne ainsi ne distingue pas vraiment le vrai du faux sur le fond, mais sur la forme.\n",
        "\n",
        "Cette strat√©gie peut donner d‚Äôexcellents r√©sultats sur un jeu de donn√©es comme WELFake, mais elle √©chouera face √† de nouveaux articles plus vari√©s.\n",
        "\n",
        "**Graphique LinearSVC :**\n",
        "\n",
        "Enfin, pour LinearSVC, on observe la m√™me tendance : malgr√© des diff√©rences internes dans leur m√©canique, les trois classifieurs (MultinomialNB, Logistic Regression, LinearSVC) placent √©tonnamment les m√™mes mots au sommet : \"reuters\", \"via\", \"image\".\n",
        "\n",
        "Ces termes sont des marqueurs externes, pas du contenu. Leur forte corr√©lation avec les √©tiquettes de classe agit comme une marque invisible qui oriente directement la pr√©diction.\n",
        "\n",
        "Ce ph√©nom√®ne, appel√© surapprentissage (overfitting), donne l‚Äôillusion d‚Äôun mod√®le performant : il brille sur l‚Äôentra√Ænement, mais se r√©v√®le fragile face √† l‚Äôinconnu. Tant que ce data leakage n‚Äôest pas corrig√©, il est impossible de juger de la v√©ritable efficacit√© de nos mod√®les."
      ],
      "metadata": {
        "id": "_fa8cVRlYOPN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# II. Premi√®re impl√©mentation de notre D√©tecteur de Fake News   "
      ],
      "metadata": {
        "id": "B2Yix5-0M8jy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous allons proc√©der en plusieurs √©tapes :    \n",
        "\n",
        "\n",
        "*   1. Explication synth√©tique du fonctionnement du code (Logistic Regression)\n",
        "*   2. Ex√©cution du code et observation de ses pr√©dictions\n",
        "*   3. R√©solution du probl√®me de data leakage\n",
        "*   4. Nouvelle √©valuation du mod√®le\n",
        "*   5. Am√©liorations\n",
        "\n",
        "\n",
        "## 1 : Explication synth√©tique du fonctionnement du code (Logistic Regression)\n",
        "\n",
        "Habituellement, apr√®s avoir nettoy√© le texte, il est vectoris√© puis le mod√®le est entra√Æn√© et √©valu√©. La cellule de code optionnelle ci-dessus a d√©j√† utilis√© trois mod√®les afin d'illustrer leurs diff√©rences graphiquement. Ces graphiques nous ont aussi permis de mettre en √©vidence un probl√®me important : le data leakage (fuite de donn√©es). Abstraction faite de cette cellule de code, revenons sur l'architecture logique de notre mod√®le en suivant l'ordre :\n",
        "\n",
        "nettoyage ‚úÖ --> vectorisation ‚úÖ --> entra√Ænement ‚è≥ (nous allons entamer cette √©tape) --> √©valuation ‚è≥\n",
        "\n",
        "\n",
        "**Le pipeline : Un processus en cha√Æne** ‚õì\n",
        "\n",
        "Imaginez que la pr√©paration et l'entra√Ænement de votre mod√®le soient une cha√Æne de montage. Un pipeline est un outil qui vous permet d'assembler toutes les √©tapes de cette cha√Æne en une seule s√©quence logique, de l'entr√©e √† la sortie.\n",
        "\n",
        "Votre pipeline est compos√© de trois √©tapes qui s'ex√©cutent automatiquement dans l'ordre, chacune passant son r√©sultat √† la suivante :\n",
        "\n",
        "(\"cleaner\", text_cleaning_transformer) : La phase de nettoyage\n",
        "\n",
        "Cette premi√®re √©tape prend les textes bruts de vos articles. Elle les fait passer par notre fonction de nettoyage personnalis√©e d√©finie plus haut (text_cleaning_transformer), qui se charge de les uniformiser, de supprimer la ponctuation et les mots non pertinents, et de les lemmatiser.\n",
        "\n",
        "Le texte ressort de cette √©tape propre et pr√™t √† √™tre analys√©.\n",
        "\n",
        "(\"tfidf\", TfidfVectorizer()) : La phase de vectorisation\n",
        "\n",
        "Les mod√®les de machine learning ne comprennent pas le texte, ils travaillent avec des nombres. Chaque mot sera transform√© en une suite de nombres. Cette √©tape utilise le TfidfVectorizer pour convertir chaque texte nettoy√© en un tableau de nombres.\n",
        "\n",
        "Le TF-IDF (Text Frequency - Inverse Document Frequency) est une m√©thode puissante qui attribue un score √† chaque mot en fonction de son importance dans le document et dans l'ensemble du jeu de donn√©es. Plus le mot est pr√©sent dans un document et rare dans l'ensemble du corpus, plus le mot aura un poids important pour le mod√®le. Inversement, les mots fr√©quents dans le corpus ont un poids faible.\n",
        "\n",
        "(\"classifier\", MultinomialNB()) : La phase d'entra√Ænement\n",
        "\n",
        "Le tableau de nombres g√©n√©r√© par l'√©tape pr√©c√©dente est transmis √† l'algorithme de classification.\n",
        "\n",
        "Ici, la r√©gression logistique est le \"cerveau\" de votre pipeline. C'est un algorithme simple, mais tr√®s efficace pour des t√¢ches de classification de texte comme la d√©tection de fake news. Il apprend √† pr√©dire la v√©racit√© d'un article √† partir des scores TF-IDF.\n",
        "\n",
        "L'un des grands avantages du pipeline est qu'il permet de changer facilement d'algorithme de classification (par exemple, LinearSVC ou Logistic Regression). Cette flexibilit√© nous permettra de tester automatiquement diff√©rentes configurations pour notre mod√®le et de conserver la plus optimale, une √©tape que nous aborderons prochainement.\n",
        "\n"
      ],
      "metadata": {
        "id": "NBzv8h2TmIuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ex√©cutez cette cellule et les deux suivantes pour observer les pr√©dictions du mod√®le \"brut\"\n",
        "\n",
        "random_state = 42\n",
        "\n",
        "logistic_regression_pipeline = Pipeline([\n",
        "    (\"cleaner\", text_cleaning_transformer),\n",
        "\n",
        "    #max_features repr√©sente le nombre de mots que le mod√®le doit apprendre. Plus le nombre est √©lev√© plus le mod√®le pourra saisir des relations complexes, mais plus il risque le surapprentissage.\n",
        "    #ngram_range indique combien de mots successifs le mod√®le doit apprendre (1, 2 ou plus). Ce param√®tre permet lui aussi de saisir des relations plus complexes et peut augmenter le surapprentissage\n",
        "    (\"tfidf\", TfidfVectorizer(max_features=5000, ngram_range=(1,2))),\n",
        "\n",
        "    #Ici, la valeur de C oblige le mod√®le √† choisir des coefficients plus petits et r√©duire le surapprentissage\n",
        "    #random_state sert √† fixer le pseudo-al√©atoire du mod√®le et ainsi obtenir toujours les m√™mes r√©sultats\n",
        "    #class_weight p√©nalise plus les erreurs de pr√©dictions sur la classe minoritaire pour √©viter que le mod√®le pr√©dise plus la classe majoritaire\n",
        "    (\"classifier\", LogisticRegression(C=1, max_iter=1000, random_state=random_state, solver=\"liblinear\", class_weight=\"balanced\"))\n",
        "])"
      ],
      "metadata": {
        "id": "_WrVtm1jmHMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 : Ex√©cution du code et observation de ses pr√©dictions"
      ],
      "metadata": {
        "id": "NaNOoFKRo-Yd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ex√©cutez cette cellule et la suivante pour observer les r√©sultats du mod√®le \"brut\"\n",
        "\n",
        "#L'entrainement du mod√®le prendra quelques minutes (5 environ).\n",
        "#Si l'ex√©cution est vraiment trop longue ou que vous rencontrer un probl√®me, relancez la cellule. Si cela ne fonctionne pas, relancez le notebook.\n",
        "\n",
        "#NB : Les prints() ne sont pas n√©cessaires au code,\n",
        "#ils affichent seulement le message ou le code contenu entre parenth√®se pour un meilleur suivi dans la console\n",
        "\n",
        "print(\"\\n---Entrainement du mod√®le Logistic Regression---\")\n",
        "\n",
        "#Cette ligne aussi courte soit-elle est la pierre angulaire du mod√®le.\n",
        "#C'est ici qu'il s'entra√Æne sur le dataset WELFake en comparant les articles avec leurs labels, il apprend les mots les plus pr√©dictifs de chaque classe.\n",
        "logistic_regression_pipeline.fit(X_train, y_train)\n",
        "print(\"Mod√®le Logistic Regression entra√Æn√©\")\n",
        "\n",
        "\n",
        "#Le mod√®le effectue ses pr√©dictions sur le set de test (les 20% d'articles non vus lors de l'entra√Ænement). C'est ici qu'il pr√©dit si le texte est vrai ou faux.\n",
        "y_pred_test = logistic_regression_pipeline.predict(X_test)\n",
        "\n",
        "#Le mod√®le donne un seuil de confiance en probabilit√© pour chacune de ses pr√©dictions.\n",
        "y_proba_test = logistic_regression_pipeline.predict_proba(X_test)\n",
        "\n",
        "\n",
        "print(f\"\\n---Performance du mod√®le sur le test set sans ajout des stop_words\")\n",
        "\n",
        "#Notre algorithme compare les y_test (les vrais labels par ex : [0, 1, 0, 0, 0, 1...] aux y_pred_test (soit les labels pr√©dits par le mod√®le par ex : [0, 1, 0, 0, 0, 0...] ))\n",
        "#Il se corrige seul, comme un √©l√®ve √† qui l'on donnerait la correction apr√®s l'examen, pour comparer ses r√©ponses avec le corrig√©. L'accuracy (ou pr√©cision) calcul√©e repr√©sente le nombre de pr√©dictions correctes divis√© par le nombre total de labels.\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_test):.2f}\")\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "\n",
        "#La ligne ci-dessous permet d'afficher un \"rapport\" contenant la pr√©cision, et le recall (rappel). Le rappel repr√©sente le nombre de r√©ponses correctes que le mod√®le a trouv√©es pour une classe donn√©e,\n",
        "# divis√© par le nombre total de r√©ponses qui √©taient r√©ellement correctes pour cette classe.\n",
        "print(classification_report(y_test, y_pred_test, target_names=[\"Fake News\", \"True News\"]))\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "\n",
        "\n",
        "#La matrice de confusion est un tableau √† deux entr√©es qui compare les labels aux pr√©dictions du mod√®le. On rencence les vrais n√©gatifs, les faux positifs, les faux n√©gatifs et les vrais positifs.\n",
        "#On parle aussi de correct rejection, false alarm, miss, et hit.\n",
        "print(confusion_matrix(y_test, y_pred_test))\n",
        "\n",
        "\n",
        "\n",
        "#On utilise ces lignes de code pour r√©cup√©rer les 60 mots les plus influents pour le mod√®le.\n",
        "#Cela nous permettra d'avoir un aper√ßut correct des mots √† supprimer ensuite\n",
        "tfidf_vectorizer = logistic_regression_pipeline.named_steps[\"tfidf\"]\n",
        "classifier = logistic_regression_pipeline.named_steps[\"classifier\"]\n",
        "\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "coefs = classifier.coef_[0]\n",
        "\n",
        "df_words = pd.DataFrame({\"word\":feature_names, \"score\":coefs})\n",
        "df_words = df_words.sort_values(by=\"score\", ascending=False)\n",
        "\n",
        "top_true_words = df_words.head(30)\n",
        "top_fake_words = df_words.tail(30)\n",
        "\n",
        "df_top_words = pd.concat([top_fake_words, top_true_words]).sort_values(by=\"score\")\n",
        "\n",
        "df_top_words[\"pr√©dicteur\"] = np.where(df_top_words[\"score\"] > 0, \"pr√©dicteur de vrai article\", \"pr√©dicteur de faux article\")\n",
        "\n",
        "df_top_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qQHoxtwKm29v",
        "outputId": "7d37fbbf-447b-4df5-8ebe-60fe1cb07069"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---Entrainement du mod√®le Logistic Regression---\n",
            "Mod√®le Logistic Regression entra√Æn√©\n",
            "\n",
            "---Performance du mod√®le sur le test set sans ajout des stop_words\n",
            "Accuracy: 0.95\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Fake News       0.95      0.95      0.95      7006\n",
            "   True News       0.95      0.95      0.95      7421\n",
            "\n",
            "    accuracy                           0.95     14427\n",
            "   macro avg       0.95      0.95      0.95     14427\n",
            "weighted avg       0.95      0.95      0.95     14427\n",
            "\n",
            "Confusion Matrix:\n",
            "[[6627  379]\n",
            " [ 349 7072]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    word      score                  pr√©dicteur\n",
              "3759             reuters -25.810711  pr√©dicteur de faux article\n",
              "3853                said -13.745006  pr√©dicteur de faux article\n",
              "1783              follow -10.642283  pr√©dicteur de faux article\n",
              "4657             twitter  -9.009893  pr√©dicteur de faux article\n",
              "4841  washington reuters  -8.621352  pr√©dicteur de faux article\n",
              "3375    president donald  -8.511300  pr√©dicteur de faux article\n",
              "864                  com  -7.688359  pr√©dicteur de faux article\n",
              "1355                dont  -6.087939  pr√©dicteur de faux article\n",
              "4467               thats  -5.537480  pr√©dicteur de faux article\n",
              "3028              obamas  -5.243709  pr√©dicteur de faux article\n",
              "3264         pic twitter  -5.170396  pr√©dicteur de faux article\n",
              "1276               didnt  -5.112724  pr√©dicteur de faux article\n",
              "4472               there  -5.057216  pr√©dicteur de faux article\n",
              "2880                  mr  -5.033035  pr√©dicteur de faux article\n",
              "2032                  he  -5.006892  pr√©dicteur de faux article\n",
              "4505            thursday  -4.888430  pr√©dicteur de faux article\n",
              "588      breitbart texas  -4.810182  pr√©dicteur de faux article\n",
              "2181                  im  -4.802096  pr√©dicteur de faux article\n",
              "1850              friday  -4.765643  pr√©dicteur de faux article\n",
              "4644             tuesday  -4.682629  pr√©dicteur de faux article\n",
              "4335              sunday  -4.662987  pr√©dicteur de faux article\n",
              "2846              monday  -4.566343  pr√©dicteur de faux article\n",
              "4477              theyre  -4.442361  pr√©dicteur de faux article\n",
              "3263                 pic  -4.354327  pr√©dicteur de faux article\n",
              "586            breitbart  -4.218722  pr√©dicteur de faux article\n",
              "4861           wednesday  -4.114933  pr√©dicteur de faux article\n",
              "2804                milo  -3.969329  pr√©dicteur de faux article\n",
              "2331       islamic state  -3.751137  pr√©dicteur de faux article\n",
              "1784      follow twitter  -3.729568  pr√©dicteur de faux article\n",
              "4923              womens  -3.702977  pr√©dicteur de faux article\n",
              "233              america   2.732090  pr√©dicteur de vrai article\n",
              "277               anyone   2.803352  pr√©dicteur de vrai article\n",
              "3380     president trump   2.839095  pr√©dicteur de vrai article\n",
              "2141             however   2.885535  pr√©dicteur de vrai article\n",
              "3830                  rt   2.924919  pr√©dicteur de vrai article\n",
              "4523               today   2.960062  pr√©dicteur de vrai article\n",
              "723         century wire   3.153753  pr√©dicteur de vrai article\n",
              "4910                wire   3.238696  pr√©dicteur de vrai article\n",
              "4146              source   3.298266  pr√©dicteur de vrai article\n",
              "1684                 fbi   3.307834  pr√©dicteur de vrai article\n",
              "4672                  uk   3.329160  pr√©dicteur de vrai article\n",
              "1135                  dc   3.354484  pr√©dicteur de vrai article\n",
              "1350              donate   3.406064  pr√©dicteur de vrai article\n",
              "2454                know   3.433735  pr√©dicteur de vrai article\n",
              "3290              please   3.444630  pr√©dicteur de vrai article\n",
              "4025               share   3.692985  pr√©dicteur de vrai article\n",
              "58              _num_the   3.813054  pr√©dicteur de vrai article\n",
              "62          _num_yearold   4.039455  pr√©dicteur de vrai article\n",
              "1518              entire   4.270647  pr√©dicteur de vrai article\n",
              "3010            november   4.531253  pr√©dicteur de vrai article\n",
              "50       _num__num__num_   5.031178  pr√©dicteur de vrai article\n",
              "3024               obama   5.649007  pr√©dicteur de vrai article\n",
              "42            _num__num_   5.698836  pr√©dicteur de vrai article\n",
              "3049             october   6.031343  pr√©dicteur de vrai article\n",
              "2079             hillary   6.943174  pr√©dicteur de vrai article\n",
              "2184           image via   7.234105  pr√©dicteur de vrai article\n",
              "3050       october _num_   7.458940  pr√©dicteur de vrai article\n",
              "3011      november _num_   8.007087  pr√©dicteur de vrai article\n",
              "2183               image   8.809948  pr√©dicteur de vrai article\n",
              "4761                 via  14.756388  pr√©dicteur de vrai article"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-02a16db4-09b9-42ff-ad1d-01af2776eb20\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>score</th>\n",
              "      <th>pr√©dicteur</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3759</th>\n",
              "      <td>reuters</td>\n",
              "      <td>-25.810711</td>\n",
              "      <td>pr√©dicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3853</th>\n",
              "      <td>said</td>\n",
              "      <td>-13.745006</td>\n",
              "      <td>pr√©dicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1783</th>\n",
              "      <td>follow</td>\n",
              "      <td>-10.642283</td>\n",
              "      <td>pr√©dicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4657</th>\n",
              "      <td>twitter</td>\n",
              "      <td>-9.009893</td>\n",
              "      <td>pr√©dicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4841</th>\n",
              "      <td>washington reuters</td>\n",
              "      <td>-8.621352</td>\n",
              "      <td>pr√©dicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3375</th>\n",
              "      <td>president donald</td>\n",
              "      <td>-8.511300</td>\n",
              "      <td>pr√©dicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>864</th>\n",
              "      <td>com</td>\n",
              "      <td>-7.688359</td>\n",
              "      <td>pr√©dicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1355</th>\n",
              "      <td>dont</td>\n",
              "      <td>-6.087939</td>\n",
              "      <td>pr√©dicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4467</th>\n",
              "      <td>thats</td>\n",
              "      <td>-5.537480</td>\n",
              "      <td>pr√©dicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3028</th>\n",
              "      <td>obamas</td>\n",
              "      <td>-5.243709</td>\n",
              "      <td>pr√©dicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3264</th>\n",
              "      <td>pic twitter</td>\n",
              "      <td>-5.170396</td>\n",
              "      <td>pr√©dicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1276</th>\n",
              "      <td>didnt</td>\n",
              "      <td>-5.112724</td>\n",
              "      <td>pr√©dicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4472</th>\n",
              "      <td>there</td>\n",
              "      <td>-5.057216</td>\n",
              "      <td>pr√©dicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2880</th>\n",
              "      <td>mr</td>\n",
              "      <td>-5.033035</td>\n",
              "      <td>pr√©dicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2032</th>\n",
              "      <td>he</td>\n",
              "      <td>-5.006892</td>\n",
              "      <td>pr√©dicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4505</th>\n",
              "      <td>thursday</td>\n",
              "      <td>-4.888430</td>\n",
              "      <td>pr√©dicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>588</th>\n",
              "      <td>breitbart texas</td>\n",
              "      <td>-4.810182</td>\n",
              "      <td>pr√©dicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2181</th>\n",
              "      <td>im</td>\n",
              "      <td>-4.802096</td>\n",
              "      <td>pr√©dicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1850</th>\n",
              "      <td>friday</td>\n",
              "      <td>-4.765643</td>\n",
              "      <td>pr√©dicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4644</th>\n",
              "      <td>tuesday</td>\n",
              "      <td>-4.682629</td>\n",
              "      <td>pr√©dicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4335</th>\n",
              "      <td>sunday</td>\n",
              "      <td>-4.662987</td>\n",
              "      <td>pr√©dicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2846</th>\n",
              "      <td>monday</td>\n",
              "      <td>-4.566343</td>\n",
              "      <td>pr√©dicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4477</th>\n",
              "      <td>theyre</td>\n",
              "      <td>-4.442361</td>\n",
              "      <td>pr√©dicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3263</th>\n",
              "      <td>pic</td>\n",
              "      <td>-4.354327</td>\n",
              "      <td>pr√©dicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>586</th>\n",
              "      <td>breitbart</td>\n",
              "      <td>-4.218722</td>\n",
              "      <td>pr√©dicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4861</th>\n",
              "      <td>wednesday</td>\n",
              "      <td>-4.114933</td>\n",
              "      <td>pr√©dicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2804</th>\n",
              "      <td>milo</td>\n",
              "      <td>-3.969329</td>\n",
              "      <td>pr√©dicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2331</th>\n",
              "      <td>islamic state</td>\n",
              "      <td>-3.751137</td>\n",
              "      <td>pr√©dicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1784</th>\n",
              "      <td>follow twitter</td>\n",
              "      <td>-3.729568</td>\n",
              "      <td>pr√©dicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4923</th>\n",
              "      <td>womens</td>\n",
              "      <td>-3.702977</td>\n",
              "      <td>pr√©dicteur de faux article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>america</td>\n",
              "      <td>2.732090</td>\n",
              "      <td>pr√©dicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>277</th>\n",
              "      <td>anyone</td>\n",
              "      <td>2.803352</td>\n",
              "      <td>pr√©dicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3380</th>\n",
              "      <td>president trump</td>\n",
              "      <td>2.839095</td>\n",
              "      <td>pr√©dicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2141</th>\n",
              "      <td>however</td>\n",
              "      <td>2.885535</td>\n",
              "      <td>pr√©dicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3830</th>\n",
              "      <td>rt</td>\n",
              "      <td>2.924919</td>\n",
              "      <td>pr√©dicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4523</th>\n",
              "      <td>today</td>\n",
              "      <td>2.960062</td>\n",
              "      <td>pr√©dicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>723</th>\n",
              "      <td>century wire</td>\n",
              "      <td>3.153753</td>\n",
              "      <td>pr√©dicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4910</th>\n",
              "      <td>wire</td>\n",
              "      <td>3.238696</td>\n",
              "      <td>pr√©dicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4146</th>\n",
              "      <td>source</td>\n",
              "      <td>3.298266</td>\n",
              "      <td>pr√©dicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1684</th>\n",
              "      <td>fbi</td>\n",
              "      <td>3.307834</td>\n",
              "      <td>pr√©dicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4672</th>\n",
              "      <td>uk</td>\n",
              "      <td>3.329160</td>\n",
              "      <td>pr√©dicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1135</th>\n",
              "      <td>dc</td>\n",
              "      <td>3.354484</td>\n",
              "      <td>pr√©dicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1350</th>\n",
              "      <td>donate</td>\n",
              "      <td>3.406064</td>\n",
              "      <td>pr√©dicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2454</th>\n",
              "      <td>know</td>\n",
              "      <td>3.433735</td>\n",
              "      <td>pr√©dicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3290</th>\n",
              "      <td>please</td>\n",
              "      <td>3.444630</td>\n",
              "      <td>pr√©dicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4025</th>\n",
              "      <td>share</td>\n",
              "      <td>3.692985</td>\n",
              "      <td>pr√©dicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>_num_the</td>\n",
              "      <td>3.813054</td>\n",
              "      <td>pr√©dicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>_num_yearold</td>\n",
              "      <td>4.039455</td>\n",
              "      <td>pr√©dicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1518</th>\n",
              "      <td>entire</td>\n",
              "      <td>4.270647</td>\n",
              "      <td>pr√©dicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3010</th>\n",
              "      <td>november</td>\n",
              "      <td>4.531253</td>\n",
              "      <td>pr√©dicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>_num__num__num_</td>\n",
              "      <td>5.031178</td>\n",
              "      <td>pr√©dicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3024</th>\n",
              "      <td>obama</td>\n",
              "      <td>5.649007</td>\n",
              "      <td>pr√©dicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>_num__num_</td>\n",
              "      <td>5.698836</td>\n",
              "      <td>pr√©dicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3049</th>\n",
              "      <td>october</td>\n",
              "      <td>6.031343</td>\n",
              "      <td>pr√©dicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2079</th>\n",
              "      <td>hillary</td>\n",
              "      <td>6.943174</td>\n",
              "      <td>pr√©dicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2184</th>\n",
              "      <td>image via</td>\n",
              "      <td>7.234105</td>\n",
              "      <td>pr√©dicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3050</th>\n",
              "      <td>october _num_</td>\n",
              "      <td>7.458940</td>\n",
              "      <td>pr√©dicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3011</th>\n",
              "      <td>november _num_</td>\n",
              "      <td>8.007087</td>\n",
              "      <td>pr√©dicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2183</th>\n",
              "      <td>image</td>\n",
              "      <td>8.809948</td>\n",
              "      <td>pr√©dicteur de vrai article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4761</th>\n",
              "      <td>via</td>\n",
              "      <td>14.756388</td>\n",
              "      <td>pr√©dicteur de vrai article</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02a16db4-09b9-42ff-ad1d-01af2776eb20')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-02a16db4-09b9-42ff-ad1d-01af2776eb20 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-02a16db4-09b9-42ff-ad1d-01af2776eb20');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0a6460dd-e1bd-44de-95a4-d369bd958b4d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0a6460dd-e1bd-44de-95a4-d369bd958b4d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0a6460dd-e1bd-44de-95a4-d369bd958b4d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_d8cf18e3-813c-4aab-9769-7a4ec082db2f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_top_words')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d8cf18e3-813c-4aab-9769-7a4ec082db2f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_top_words');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_top_words",
              "summary": "{\n  \"name\": \"df_top_words\",\n  \"rows\": 60,\n  \"fields\": [\n    {\n      \"column\": \"word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 60,\n        \"samples\": [\n          \"reuters\",\n          \"president donald\",\n          \"century wire\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.641061492658534,\n        \"min\": -25.810710673094665,\n        \"max\": 14.756388394891026,\n        \"num_unique_values\": 60,\n        \"samples\": [\n          -25.810710673094665,\n          -8.511299792332865,\n          3.1537530287828472\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pr\\u00e9dicteur\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"pr\\u00e9dicteur de vrai article\",\n          \"pr\\u00e9dicteur de faux article\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "√Ä pr√©sent que notre algorithme est entra√Æn√© et a donn√© ses pr√©dictions (pour les articles non vus lors de l'entra√Ænement) sur le dataset WELFake, examinons ses r√©ponses.\n",
        "\n",
        "üëâ Notons aussi que nous avons r√©cup√©r√© les 60 mots les plus pr√©dictifs pour l'algorithme pour pouvoir r√©gler le probl√®me de data leakage.\n",
        "\n",
        "L'accuracy est indiqu√©e √† 95 % : le mod√®le a correctement class√© 95 % des articles du set de test, ce qui est une tr√®s bonne performance.\n",
        "\n",
        "Le classification_report fournit des m√©triques plus d√©taill√©es. Pour la classe \"True News\", la pr√©cision (precision ici, √† distinguer de l‚Äôaccuracy : il s‚Äôagit de la proportion de r√©ponses correctes parmi toutes les pr√©dictions de cette m√™me classe) et le rappel (recall) sont √† 95 %, tandis que pour la classe \"Fake News\", la pr√©cision et le rappel sont √©galement √† 95 %. Cela signifie que le mod√®le est tr√®s performant et √©quilibr√© dans sa capacit√© √† identifier correctement les articles des deux cat√©gories.\n",
        "\n",
        "Enfin, la matrice de confusion nous permet de voir que la r√©gression logistique a correctement pr√©dit 7072 vrais articles (vrais positifs) et 6627 faux articles (vrais n√©gatifs). Elle s‚Äôest tromp√©e pour 349 vrais articles (faux n√©gatifs) et 379 faux articles (faux positifs).\n",
        "\n",
        "Un rapide calcul nous permet de retrouver le nombre total d'articles.\n",
        "\n",
        "- La ligne du bas de la matrice de confusion repr√©sente les vrais articles (349 + 7072 = 7421)\n",
        "\n",
        "- La ligne du haut repr√©sente les faux articles (6627 + 379 = 7006)\n",
        "\n",
        "Ces nombres sont affich√©s dans la colonne support de notre classification report.\n",
        "\n",
        "7006 + 7421 = 14 427 articles au total pour le set de test.\n",
        "Nous avons utilis√© 20 % de nos donn√©es (articles) pour le set de test. Multiplier 14 427 par 5 devrait nous donner notre nombre d'articles initial (5 * 20 % = 100 %).\n",
        "\n",
        "14 427 * 5 = 72 135.\n",
        "Le compte est bon.\n",
        "Notre DataFrame WELFake contient 72 134 : lors de notre split de donn√©es, scikit-learn a simplement arrondi 14 426,8 au sup√©rieur, ce qui explique la diff√©rence.\n",
        "\n",
        "Cependant, nous ne savons toujours pas si notre mod√®le est performant dans un contexte r√©el. Il aurait pu apprendre par c≈ìur les donn√©es de WELFake sans √™tre capable de g√©n√©raliser √† de nouveaux textes diff√©rents.\n",
        "\n",
        "C'est pour cette raison que nous allons le tester sur des articles ind√©pendants du dataset WELFake üëá\n"
      ],
      "metadata": {
        "id": "CnDuo94Vc9ke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Nous r√©cup√©rons les pr√©dictions du mod√®le sur nos nouveaux textes\n",
        "y_pred_new = logistic_regression_pipeline.predict(texts_to_predict)\n",
        "#Nous r√©cup√©rons le seuil de confiance du mod√®le pour chaque article afin de pouvoir les afficher ensuite\n",
        "new_probabilities = logistic_regression_pipeline.predict_proba(texts_to_predict)\n",
        "\n",
        "#Une boucle va parcourir chaque texte de notre df custom (soit 10 articles)\n",
        "#Pour chacun de ces articles nous r√©cup√©rons son index et sa pr√©diction avec enumerate\n",
        "for i, article in enumerate(texts_to_predict):\n",
        "\n",
        "  # Les probabilit√©s sont r√©cup√©r√©es pour les deux classes :\n",
        "  # classe 0 (faux) et classe 1 (vrai)\n",
        "  # [i][0] est une mani√®re courante d'acc√©der √† un √©l√©ment en python. [i] indique le i + 1√®me √©l√©ment (soit les 10 textes, un par un) et [0] indique la probabilit√© \"fake\",\n",
        "  # car la fonction predict_proba renvoie des tableaux de probabilit√©s [0.439 0.561] par exemple pour le premier article. [0] acc√®de au premier √©l√©ment et [1] au deuxi√®me.\n",
        "  proba_fake = new_probabilities[i][0] * 100\n",
        "  proba_true = new_probabilities[i][1] * 100\n",
        "\n",
        "  #On indique que si la probabilit√© fake est sup√©rieure √† la probabilit√© vrai, alors le texte est class√© comme faux, sinon il est vrai.\n",
        "  predicted_class = 0 if proba_fake > proba_true else 1\n",
        "  predicted_veracity = \"Faux article\" if predicted_class == 0 else \"Vrai article\"\n",
        "  #On affiche simplement nos r√©sultats, les noms de chaque texte, leur vrai label, leur probabilit√© selon le mod√®le et sa pr√©diction finale\n",
        "  print(f\"\\nL'article {i+1} est vrai\" if true_labels[i] == 1 else f\"\\nL'article {i+1} est faux\")\n",
        "  print(f\"Probabilit√© 'Faux article': {proba_fake:.2f}%\")\n",
        "  print(f\"Probabilit√© 'Vrai article': {proba_true:.2f}%\")\n",
        "  print(f\"Pr√©diction finale du mod√®le: {predicted_veracity}\")\n",
        "\n",
        "#Enfin, on affiche un rapport de classification pour √©valuer la performance globale du mod√®le sur les nouveaux articles\n",
        "report_brut = classification_report(true_labels, y_pred_new, target_names=[\"Fake News\", \"True News\"], output_dict=True)\n",
        "df_brut = pd.DataFrame(report_brut).transpose()\n",
        "\n",
        "print(\"\\n-- Performance du mod√®le sur les nouveaux articles\")\n",
        "print(classification_report(true_labels, y_pred_new, target_names=[\"Fake News\", \"True News\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfu6yfPDqmim",
        "outputId": "a27b9cd2-2739-4b9d-ba18-8bff8f120a00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "L'article 1 est faux\n",
            "Probabilit√© 'Faux article': 58.46%\n",
            "Probabilit√© 'Vrai article': 41.54%\n",
            "Pr√©diction finale du mod√®le: Faux article\n",
            "\n",
            "L'article 2 est faux\n",
            "Probabilit√© 'Faux article': 37.59%\n",
            "Probabilit√© 'Vrai article': 62.41%\n",
            "Pr√©diction finale du mod√®le: Vrai article\n",
            "\n",
            "L'article 3 est faux\n",
            "Probabilit√© 'Faux article': 34.96%\n",
            "Probabilit√© 'Vrai article': 65.04%\n",
            "Pr√©diction finale du mod√®le: Vrai article\n",
            "\n",
            "L'article 4 est faux\n",
            "Probabilit√© 'Faux article': 5.51%\n",
            "Probabilit√© 'Vrai article': 94.49%\n",
            "Pr√©diction finale du mod√®le: Vrai article\n",
            "\n",
            "L'article 5 est faux\n",
            "Probabilit√© 'Faux article': 9.91%\n",
            "Probabilit√© 'Vrai article': 90.09%\n",
            "Pr√©diction finale du mod√®le: Vrai article\n",
            "\n",
            "L'article 6 est vrai\n",
            "Probabilit√© 'Faux article': 66.11%\n",
            "Probabilit√© 'Vrai article': 33.89%\n",
            "Pr√©diction finale du mod√®le: Faux article\n",
            "\n",
            "L'article 7 est vrai\n",
            "Probabilit√© 'Faux article': 1.83%\n",
            "Probabilit√© 'Vrai article': 98.17%\n",
            "Pr√©diction finale du mod√®le: Vrai article\n",
            "\n",
            "L'article 8 est vrai\n",
            "Probabilit√© 'Faux article': 4.63%\n",
            "Probabilit√© 'Vrai article': 95.37%\n",
            "Pr√©diction finale du mod√®le: Vrai article\n",
            "\n",
            "L'article 9 est vrai\n",
            "Probabilit√© 'Faux article': 27.08%\n",
            "Probabilit√© 'Vrai article': 72.92%\n",
            "Pr√©diction finale du mod√®le: Vrai article\n",
            "\n",
            "L'article 10 est vrai\n",
            "Probabilit√© 'Faux article': 19.67%\n",
            "Probabilit√© 'Vrai article': 80.33%\n",
            "Pr√©diction finale du mod√®le: Vrai article\n",
            "\n",
            "-- Performance du mod√®le sur les nouveaux articles\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Fake News       0.50      0.20      0.29         5\n",
            "   True News       0.50      0.80      0.62         5\n",
            "\n",
            "    accuracy                           0.50        10\n",
            "   macro avg       0.50      0.50      0.45        10\n",
            "weighted avg       0.50      0.50      0.45        10\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Au premier regard, on constate que notre mod√®le est tr√®s mauvais pour d√©tecter les fake news, en r√©alit√©, il n'en d√©tecte qu'une (recall fake news : 0.20). De l'autre c√¥t√©, bien qu'il soit biais√© vers la classe \"vrai\" il √©choue √† classer le 6√®me article comme vrai.\n",
        "\n",
        "Le classification report est int√©ressant car il nous permet de voir le tableau dans son ensemble. Bien que le recall soit de 80% pour les vrais articles, la pr√©cision du mod√®le est seulement de 50% pour cette classe. Le mod√®le est parvenu √† d√©tecter 80% des vrais articles, ce qui para√Æt convenable, mais la pr√©cision nous sugg√®re que le mod√®le est trop optimiste, il tend √† dire \"vrai\" trop souvent.\n",
        "\n",
        "Pour les fake news, le recall et √† 20% et la pr√©cision √† 50% car m√™me au sein de ses rares articles classifi√©s en tant que fake news il se trompe une fois sur deux.\n",
        "\n",
        "Le score f1 global est √† 0.45, bien en dessous d'un seuil acceptable qui devrait se rapprocher de 1.\n",
        "\n",
        "Avec une telle chute de performance, passant d'un f1-score de 95% √† 45%, on comprends l'importance de tester le mod√®le sur de nouvelles donn√©es. Une performance √©lev√©e sur le jeu de donn√©es initial ne signifie pas que le mod√®le sera capable de g√©n√©raliser dans un contexte r√©el.\n",
        "\n",
        "Pour am√©liorer la g√©n√©ralisabilit√© du mod√®le, occupons-nous du probl√®me de data leakage.\n",
        "\n",
        "\n",
        "Ex√©cutons √† pr√©sent l'exact m√™me code, en ajoutant √† la liste de stop_words, (les mots que le mod√®le doit ignorer), les 60 mots que nous avons r√©cup√©r√© juste au-dessus."
      ],
      "metadata": {
        "id": "OLyf9u5amzve"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 : R√©solution du probl√®me de data leakage"
      ],
      "metadata": {
        "id": "Sf5OtnVf6NYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# On met √† jour la liste de stop_words √† partir des mots observ√©s sur le graphique pour le mod√®le de r√©gression lin√©aire car c'est celui que nous utilisons actuellement\n",
        "stop_words.update([\n",
        "    'reuters', 'said', 'follow', 'twitter', 'washington', 'president donald', 'com',\n",
        "    'dont', 'thats', 'obamas', 'pic twitter', 'didnt', 'there', 'mr', 'he',\n",
        "    'thursday', 'breitbart texas', 'im', 'friday', 'tuesday', 'sunday', 'monday',\n",
        "    'theyre', 'pic', 'breitbart', 'wednesday', 'milo', 'islamic state',\n",
        "    'follow twitter', 'womens', 'america', 'anyone', 'president trump', 'however',\n",
        "    'rt', 'today', 'century wire', 'wire', 'source', 'fbi', 'uk', 'dc',\n",
        "    'donate', 'know', 'please', 'share', 'the', 'yearold', 'entire',\n",
        "    'november', 'obama', 'october', 'hillary', 'image via', 'image', 'via'\n",
        "])\n",
        "\n",
        "#On ex√©cute le m√™me code pour obtenir nos nouvelles pr√©dictions sans data leakage\n",
        "\n",
        "logistic_regression_pipeline = Pipeline([\n",
        "    (\"cleaner\", text_cleaning_transformer),\n",
        "    (\"tfidf\", TfidfVectorizer(max_features=5000, ngram_range=(1,2), stop_words=list(stop_words))),\n",
        "    (\"classifier\", LogisticRegression(C=1, max_iter=1000, random_state=random_state, solver=\"liblinear\", class_weight=\"balanced\"))\n",
        "])\n",
        "\n",
        "print(\"\\n---Entrainement du mod√®le Logistic Regression---\")\n",
        "logistic_regression_pipeline.fit(X_train, y_train)\n",
        "print(\"Mod√®le Logistic Regression entra√Æn√©\")\n",
        "\n",
        "new_probabilities = logistic_regression_pipeline.predict_proba(texts_to_predict)\n",
        "\n",
        "y_pred_test = logistic_regression_pipeline.predict(X_test)\n",
        "y_proba_test = logistic_regression_pipeline.predict_proba(X_test)\n",
        "\n",
        "print(f\"\\n---Performance du mod√®le sur le test set apr√®s correction des stop_words\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_test):.2f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_test, target_names=['Fake News', 'True News']))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_test))\n",
        "\n",
        "\n",
        "y_pred_new = logistic_regression_pipeline.predict(texts_to_predict)\n",
        "\n",
        "for i, article in enumerate(texts_to_predict):\n",
        "  proba_fake = new_probabilities[i][0] * 100\n",
        "  proba_true = new_probabilities[i][1] * 100\n",
        "  predicted_class = 0 if proba_fake > proba_true else 1\n",
        "  predicted_veracity = \"Faux article\" if predicted_class == 0 else \"Vrai article\"\n",
        "\n",
        "  print(f\"\\nArticle {i+1} :\")\n",
        "  print(f\"Probabilit√© 'Faux article': {proba_fake:.2f}%\")\n",
        "  print(f\"Probabilit√© 'Vrai article': {proba_true:.2f}%\")\n",
        "  print(f\"Pr√©diction finale: {predicted_veracity}\")\n",
        "\n",
        "print(\"\\n-- Performance du mod√®le sur les nouveaux articles\")\n",
        "print(f\"Accuracy: {accuracy_score(true_labels, y_pred_new):.2f}\")\n",
        "print(classification_report(true_labels, y_pred_new, target_names=[\"Fake News\", \"True News\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eREUyIY9myIW",
        "outputId": "cbb91c0b-e01f-4f50-bb29-3d267cb072a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---Entrainement du mod√®le Logistic Regression---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['century', 'donald', 'islamic', 'president', 'replace', 'state', 'texas', 'trump', 'words'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mod√®le Logistic Regression entra√Æn√©\n",
            "\n",
            "---Performance du mod√®le sur le test set apr√®s correction des stop_words\n",
            "Accuracy: 0.92\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Fake News       0.91      0.92      0.91      7006\n",
            "   True News       0.92      0.92      0.92      7421\n",
            "\n",
            "    accuracy                           0.92     14427\n",
            "   macro avg       0.92      0.92      0.92     14427\n",
            "weighted avg       0.92      0.92      0.92     14427\n",
            "\n",
            "Confusion Matrix:\n",
            "[[6414  592]\n",
            " [ 600 6821]]\n",
            "\n",
            "Article 1 :\n",
            "Probabilit√© 'Faux article': 82.32%\n",
            "Probabilit√© 'Vrai article': 17.68%\n",
            "Pr√©diction finale: Faux article\n",
            "\n",
            "Article 2 :\n",
            "Probabilit√© 'Faux article': 36.22%\n",
            "Probabilit√© 'Vrai article': 63.78%\n",
            "Pr√©diction finale: Vrai article\n",
            "\n",
            "Article 3 :\n",
            "Probabilit√© 'Faux article': 53.46%\n",
            "Probabilit√© 'Vrai article': 46.54%\n",
            "Pr√©diction finale: Faux article\n",
            "\n",
            "Article 4 :\n",
            "Probabilit√© 'Faux article': 6.47%\n",
            "Probabilit√© 'Vrai article': 93.53%\n",
            "Pr√©diction finale: Vrai article\n",
            "\n",
            "Article 5 :\n",
            "Probabilit√© 'Faux article': 21.90%\n",
            "Probabilit√© 'Vrai article': 78.10%\n",
            "Pr√©diction finale: Vrai article\n",
            "\n",
            "Article 6 :\n",
            "Probabilit√© 'Faux article': 85.87%\n",
            "Probabilit√© 'Vrai article': 14.13%\n",
            "Pr√©diction finale: Faux article\n",
            "\n",
            "Article 7 :\n",
            "Probabilit√© 'Faux article': 3.09%\n",
            "Probabilit√© 'Vrai article': 96.91%\n",
            "Pr√©diction finale: Vrai article\n",
            "\n",
            "Article 8 :\n",
            "Probabilit√© 'Faux article': 13.83%\n",
            "Probabilit√© 'Vrai article': 86.17%\n",
            "Pr√©diction finale: Vrai article\n",
            "\n",
            "Article 9 :\n",
            "Probabilit√© 'Faux article': 32.22%\n",
            "Probabilit√© 'Vrai article': 67.78%\n",
            "Pr√©diction finale: Vrai article\n",
            "\n",
            "Article 10 :\n",
            "Probabilit√© 'Faux article': 20.02%\n",
            "Probabilit√© 'Vrai article': 79.98%\n",
            "Pr√©diction finale: Vrai article\n",
            "\n",
            "-- Performance du mod√®le sur les nouveaux articles\n",
            "Accuracy: 0.60\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Fake News       0.67      0.40      0.50         5\n",
            "   True News       0.57      0.80      0.67         5\n",
            "\n",
            "    accuracy                           0.60        10\n",
            "   macro avg       0.62      0.60      0.58        10\n",
            "weighted avg       0.62      0.60      0.58        10\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous avons choisi d'ajouter plusieurs mots √† la liste des stop_words, afin de limiter le data leakage. Ce faisant, on rend le mod√®le un peu moins performant sur le training set (et le test set), mais cela nous permet d'√©viter qu'il apprenne par coeur. Retirer les mots doit se faire de mani√®re r√©fl√©chie, car on pourrait retirer par malchance un ou plusieurs mots qui n'√©taient pas de la fuite de donn√©es et qui auraient vraiment permis au mod√®le de g√©n√©raliser. Nous aurions pu envisager de retirer certains mots de mani√®re s√©lective, en fonction de notre appr√©ciation de sa pertinence ou non, mais cela aurait l√† aussi introduit une forme de biais de subjectivit√©.\n",
        "\n",
        "\n",
        "En supprimant les mots les plus importants, nous privons le mod√®le des indices les plus forts sur lesquels il se basait pour effectuer ses pr√©dictions, et esp√©rons que cela l'obligera √† se concentrer sur des indices s√©mantiques plus subtils pr√©sents dans le training set et par cons√©quent d'autres articles.\n",
        "\n",
        "## 4 : Nouvelle √©valuation du mod√®le\n",
        "\n",
        "Le mod√®le obtient un f1-score de 58% ce qui est une am√©lioration notable par rapport √† sa version pr√©c√©dente (45%). Soyons prudents dans notre interpr√©tation n√©anmoins, car la faible taille de l'√©chantillon ne permet pas de g√©n√©raliser.\n",
        "En r√©alit√©, la seule diff√©rence est que le troisi√®me article est d√©sormais correctement classifi√© comme faux. Pour obtenir un r√©sultat rigoureux nous aurions besoin d'un √©chantillon bien plus vaste.\n",
        "\n",
        "Cependant, pour les besoins de notre d√©monstration cette diff√©rence est suffisante pour mettre en √©vidence un changement dans les pr√©dictions de notre mod√®le.\n",
        "\n",
        "Malheureusement une accuracy de 60% et un f1-score de 58% peuvent difficilement √™tre consid√©r√©s comme de bonnes m√©triques dans un contexte r√©el."
      ],
      "metadata": {
        "id": "Uuln-_HnBfPA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# III. Am√©liorations"
      ],
      "metadata": {
        "id": "QGlG2WfuBU76"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##1 : Param√®tres de recherche\n",
        "\n",
        "Maintenant que notre probl√®me de data leakage est r√©solu, notre objectif est d‚Äôam√©liorer le d√©tecteur de fake news afin d‚Äôobtenir de meilleures performances sur notre df_fake_true (texts_to_predict).\n",
        "Un mod√®le d‚Äôapprentissage automatique peut √™tre ajust√© gr√¢ce √† diff√©rents param√®tres appel√©s hyperparam√®tres, qui influencent la mani√®re dont il apprend et prend ses d√©cisions.\n",
        "Plut√¥t que de tester toutes les configurations manuellement, nous allons demander √† l‚Äôordinateur d‚Äôexplorer automatiquement plusieurs combinaisons d‚Äôhyperparam√®tres, puis de s√©lectionner celle offrant les meilleures performances.\n",
        "\n",
        "Au lieu de tester toutes les combinaisons manuellement (ce qui serait long et fastidieux), nous allons utiliser un outil int√©gr√© √† scikit-learn : RandomGridSearch. Cet outil permet d‚Äôautomatiser la recherche de la meilleure combinaison d‚Äôhyperparam√®tres parmi celles que nous lui indiquons.\n",
        "\n",
        "Cependant, il est important de ne pas tester un nombre excessif de combinaisons. Si nous explorons trop de possibilit√©s, nous risquons d‚Äôoptimiser uniquement sur notre jeu d‚Äôentra√Ænement et donc de cr√©er un mod√®le qui a ‚Äúappris par c≈ìur‚Äù ce jeu de donn√©es (surapprentissage ou overfitting)."
      ],
      "metadata": {
        "id": "9k-KNsGB-JZt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si vous vous souvenez de la m√©taphore du m√©lange nettoyant, c‚Äôest ici que nous allons mettre en place la structure qui permettra de d√©cider quel m√©langes (quels hyperparam√®tres et quel mod√®le) est le plus efficace.\n",
        "\n",
        "Pour plus de lisibilit√©, le code ci-dessous est organis√© en trois blocs :\n",
        "chaque bloc correspond √† un mod√®le de machine learning diff√©rent, indiqu√© √† la ligne \"classifier\". Ce sont trois mod√®les dont nous avons √©clair√© le fonctionnement dans la fiche explicative üìÑ\n"
      ],
      "metadata": {
        "id": "8duLNAXYH69j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = [\n",
        "    {\n",
        "        \"cleaner\":[text_cleaning_transformer, text_cleaning_transformer_no_numbers],\n",
        "        \"tfidf__max_features\":[5000], #max_features est le nombre maximal de mots appris par le mod√®le, l'augmenter peut augmenter la performance mais aussi l'overfitting\n",
        "        \"tfidf__ngram_range\":[(1,1), (1,2)], #ngram (1,1) consid√®re les mots seuls ; ngram (1,2) consid√®re les mots seuls et les paires, l√† encore augmenter la complexit√© permet de saisir des relations plus complexes, mais peut nuire √† la g√©n√©ralisabilit√© du mod√®le\n",
        "        \"tfidf__smooth_idf\":[True, False], #Le lissage smooth_idf √©vite qu'un mot tr√®s rare soit attribu√© un poids excessif. On teste avec et sans lissage\n",
        "        \"classifier\":[MultinomialNB()],\n",
        "        \"classifier__alpha\":[0.01, 0.1, 10],#alpha est le param√®tre de r√©gularisation, plus alpha est faible plus le mod√®le est autoris√© √† s'ajuster aux donn√©es et saisir des relations complexes. Un alpha plus √©lev√© produit l'inverse.\n",
        "    },\n",
        "    {\n",
        "        \"cleaner\":[text_cleaning_transformer, text_cleaning_transformer_no_numbers],\n",
        "        \"tfidf__max_features\":[5000],\n",
        "        \"tfidf__ngram_range\":[(1,1), (1,2)],\n",
        "        \"tfidf__use_idf\":[True, False],#On active ou d√©sactive l'utilisation du facteur IDF, qui r√©duit l'ilmportance des mots tr√®s fr√©quents dans les documents lorsqu'activ√©\n",
        "        \"tfidf__smooth_idf\": [True, False],\n",
        "        \"classifier\":[LogisticRegression(max_iter=1000, random_state=42)],\n",
        "        \"classifier__C\":[0.01, 0.1, 10],#C est l'inverse de la r√©gularisation alpha : un C faible applique une forte r√©gularisation, un C √©lev√© donne plus de libert√© au mod√®le\n",
        "        \"classifier__penalty\":[\"l2\"],#Il s'agit du type de r√©gularisation appliqu√©e, L2 p√©nalise les grands coefficients, il tend √† les r√©duire sans les annuler compl√®tement\n",
        "    },\n",
        "    {\n",
        "        \"cleaner\":[text_cleaning_transformer, text_cleaning_transformer_no_numbers],\n",
        "        \"tfidf__max_features\":[5000],\n",
        "        \"tfidf__ngram_range\":[(1,1), (1,2)],\n",
        "        \"tfidf__use_idf\":[True, False],\n",
        "        \"tfidf__smooth_idf\": [True, False],\n",
        "        \"classifier\":[LinearSVC(max_iter=1000, random_state=42)],\n",
        "        \"classifier__C\":[0.01, 0.1, 10],\n",
        "    }]"
      ],
      "metadata": {
        "id": "bW5FtizbKR3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 : Recherche al√©atoire avec Random Grid Search"
      ],
      "metadata": {
        "id": "FiTqL50Kx8En"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le code ci dessous ex√©cute une recherche al√©atoire sur les param√®tres que nous avons indiqu√© dans param_grid[ ].\n",
        "\n",
        "Son ex√©cution prends plusieurs heures, pour vous √©pargner le temps d'attente les r√©sultats de la recherche sont d√©j√† enregistr√©s, vous n'avez qu'√† lancer la cellule suivante pour les observer."
      ],
      "metadata": {
        "id": "y1PAiZpRfyBK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Re0uGSn1prxE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "310af8f3-d4bb-4111-c526-459e289f18d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "skip\n"
          ]
        }
      ],
      "source": [
        "#Les plus t√©m√©raires pourront retirer la ligne %%script echo skip et lancer le code (temps d'ex√©cution de plusieurs heures)\n",
        "\n",
        "%%script echo skip\n",
        "#Les param√®tres du pipeline sont rentr√©s √† titre indicatif pour que random grid search\n",
        "pipeline = Pipeline([\n",
        "    (\"cleaner\", text_cleaning_transformer), #Nettoyage et pr√©traitement du texte\n",
        "    (\"tfidf\", TfidfVectorizer()), #Transformation du texte en tokens\n",
        "    (\"classifier\", LogisticRegression(solver=\"liblinear\", random_state=42)) #S√©lection du mod√®le de classification\n",
        "])\n",
        "\n",
        "scoring_metric = \"f1_weighted\" #Pond√©ration du score F1 en fonction des tailles des classes pour ne pas favoriser la classe majoritaire\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "pipeline, #Utilisation du pipeline complet nettoyage + vectorisation + mod√®le\n",
        "param_grid, #Les param√®tres √† tester d√©finis juste au dessus\n",
        "n_iter=10, #Nombre de combinaisons que random search va tester au hasard parmi toutes celles possibles\n",
        "cv=5, #Cross validation (ou validation crois√©e) : on s√©pare les donn√©es d'entra√Ænement en 5 morceaux, on entra√Æne le mod√®le sur les 4/5 et on le teste sur le 5√®me restant. On reproduit l'op√©ration 5 fois et on fait la moyenne des 5 tests pour calculer le score final.\n",
        "n_jobs=-1, #On utilise tous les coeurs du processeur disponibles pour acc√©l√©rer le calcul\n",
        "scoring=\"f1_weighted\",\n",
        "random_state=42) #On d√©finit la seed √† 42 pour la reproductibilit√©\n",
        "\n",
        "print(f\"Starting Random Search with {scoring_metric}\")\n",
        "\n",
        "#On lance la recherche\n",
        "random_search.fit(X_train, y_train)\n",
        "print(\"Random Search completed\")\n",
        "\n",
        "#On affiche les meilleurs param√®tres trouv√©s\n",
        "print(f\"\\nBest Parameters found: {random_search.best_params_}\")\n",
        "print(f\"\\nBest Cross_Validation {scoring_metric} score: {random_search.best_score_:.2f}\")\n",
        "\n",
        "#On √©value le meilleur mod√®le sur le test set\n",
        "best_pipeline = random_search.best_estimator_\n",
        "y_pred_best = best_pipeline.predict(X_test)\n",
        "\n",
        "#On affiche les performances du meilleur mod√®le sur notre test set WELFake\n",
        "print(f\"\\nPerformance of the Best Model on the Test Set using {scoring_metric}:\")\n",
        "print(f\"Accuracy:{accuracy_score(y_test, y_pred_best):.4f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_best, target_names=['True News', 'Fake News']))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_best))\n",
        "\n",
        "\n",
        "#On sauvegarde nos r√©sulats pour ne pas devoir relancer plusieurs heures de recherche √† chaque fois\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "joblib.dump(random_search, \"random_search_results.joblib\")\n",
        "\n",
        "joblib.dump(random_search.best_estimator_, \"best_pipeline.joblib\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si notre objectif est d‚Äôobtenir un mod√®le performant sur un jeu de donn√©es totalement nouveau (par exemple notre df_fake_true) pourquoi ne pas appliquer directement la recherche d‚Äôhyperparam√®tres (RandomGridSearch) sur ces textes pour obtenir le meilleur mod√®le possible ?\n",
        "\n",
        "La r√©ponse tient en un mot : overfitting.\n",
        "Optimiser un mod√®le directement sur un √©chantillon aussi r√©duit, ici 10 textes, reviendrait √† adapter presque parfaitement les hyperparam√®tres √† ce minuscule jeu de donn√©es rendant la g√©n√©ralisation √† d‚Äôautres textes tr√®s difficile. Sur un si petit √©chantillon, la m√©trique obtenue n‚Äôa quasiment aucune valeur statistique.\n",
        "\n",
        "Le df_fake_true n‚Äôa donc pas vocation √† servir de base d‚Äôoptimisation ou d‚Äô√©valuation robuste : il est simplement utilis√© comme un jeu de test illustratif, pour montrer concr√®tement comment un mod√®le d√©j√† entra√Æn√© se comporte sur des textes in√©dits. C‚Äôest un outil p√©dagogique, pas un √©chantillon fiable pour mesurer la performance r√©elle.\n",
        "\n",
        "En revanche, le dataset WELFake contient plusieurs dizaines de milliers de textes. En l‚Äôutilisant pour √©valuer et s√©lectionner notre mod√®le, on obtient une estimation beaucoup plus stable et repr√©sentative de ses performances.\n",
        "Cette robustesse statistique est essentielle : dans une situation r√©elle de d√©ploiement, on souhaite que le mod√®le conserve ses performances sur un large √©ventail de contenus, pas uniquement sur un micro-√©chantillon.\n",
        "\n",
        "La d√©marche correcte est donc :\n",
        "\n",
        "- Entra√Æner et optimiser le mod√®le sur un large dataset repr√©sentatif (WELFake), via validation crois√©e pour limiter l‚Äôoverfitting.\n",
        "\n",
        "- Tester le mod√®le optimis√© sur des donn√©es totalement nouvelles et ind√©pendantes (df_fake_true) pour voir comment il se comporte en conditions r√©elles, tout en gardant √† l‚Äôesprit que si l‚Äô√©chantillon est trop petit, ce test sera avant tout indicatif et p√©dagogique."
      ],
      "metadata": {
        "id": "dhbot5mAvAye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#R√©cup√©rons les mots les plus pr√©dictifs de notre best_pipeline afin de les ajouter √† la liste de stop_words\n",
        "\n",
        "best_pipeline = joblib.load(\"best_pipeline.joblib\")\n",
        "\n",
        "y_pred_best = best_pipeline.predict(texts_to_predict)\n",
        "probas = best_pipeline.predict_proba(texts_to_predict)\n",
        "\n",
        "tfidf_vectorizer = best_pipeline.named_steps[\"tfidf\"]\n",
        "classifier = best_pipeline.named_steps[\"classifier\"]\n",
        "\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "coefs = classifier.coef_[0]\n",
        "\n",
        "df_words = pd.DataFrame({\"word\":feature_names, \"score\":coefs})\n",
        "df_words = df_words.sort_values(by=\"score\", ascending=False)\n",
        "\n",
        "top_true_words = df_words.head(30)\n",
        "top_fake_words = df_words.tail(30)\n",
        "\n",
        "\n",
        "df_top_words = pd.concat([top_fake_words, top_true_words]).sort_values(by=\"score\")\n",
        "\n",
        "new_stop_words = initial_stop_words\n",
        "\n",
        "print(f\"Premiers stop_words avant ajout : {list(new_stop_words)[:30]}\")\n",
        "\n",
        "new_stop_words.update(list(df_top_words[\"word\"]))\n",
        "\n",
        "print(f\"Premiers stop_words apr√®s ajout : {list(new_stop_words)[:30]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQStYQbN0H0h",
        "outputId": "4e511a54-1d65-40f3-f141-307843eae3fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Premiers stop_words avant ajout : ['m', 'ma', 'until', 'again', 'few', 'if', 'will', 'o', 'each', 'him', 'he', \"she'd\", 'so', \"she's\", 'yourself', 'while', \"he'll\", 'only', 'their', \"they'd\", 'hadn', 'about', 'am', 'itself', \"you're\", \"didn't\", 'mustn', 'you', 'ours', 'from']\n",
            "Premiers stop_words apr√®s ajout : ['m', 'ma', 'until', 'com', 'again', 'few', 'if', 'will', 'o', 'each', 'him', 'entire', 'he', \"she'd\", 'said', 'dont', 'so', \"she's\", 'yourself', 'while', 'via', \"he'll\", 'only', 'monday', 'probably', 'their', \"they'd\", 'hadn', 'about', 'wednesday']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 : Application de notre meilleur mod√®le"
      ],
      "metadata": {
        "id": "H45Jpq30ypYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ajoutons nos stopwords trouv√©s plus t√¥t au mod√®le\n",
        "stop_words.update(new_stop_words)\n",
        "\n",
        "#On charge notre meilleur mod√®le enregistr√© dans le fichier best_pipeline.joblib\n",
        "best_pipeline = joblib.load(\"best_pipeline.joblib\")\n",
        "\n",
        "print(f\"Param√®tres de notre meilleur mod√®le trouv√© par random grid search :\\n{best_pipeline.get_params()}\")\n",
        "\n",
        "#On r√©cup√®re les pr√©dictions du mod√®le ainsi que son seuil de probabilit√© pour chaque pr√©diction\n",
        "y_pred_best = best_pipeline.predict(texts_to_predict)\n",
        "probas = best_pipeline.predict_proba(texts_to_predict)\n",
        "\n",
        "#On demande √† notre mod√®le d'indiquer ses pr√©dictions pour chaque texte\n",
        "for i, article in enumerate(texts_to_predict):\n",
        "  proba_fake = probas[i][0] * 100\n",
        "  proba_true = probas[i][1] * 100\n",
        "\n",
        "  predicted_class = 0 if proba_fake > proba_true else 1\n",
        "  predicted_veracity = \"Faux article\" if predicted_class == 0 else \"Vrai article\"\n",
        "\n",
        "  print(f\"\\nL'article {i+1} est vrai\" if true_labels[i] == 1 else f\"\\nL'article {i+1} est faux\")\n",
        "  print(f\"Probabilit√© 'Faux article': {proba_fake:.2f}%\")\n",
        "  print(f\"Probabilit√© 'Vrai article': {proba_true:.2f}%\")\n",
        "  print(f\"Pr√©diction finale: {predicted_veracity}\")\n",
        "\n",
        "print(\"\\n-- Performance du mod√®le sur les nouveaux articles\")\n",
        "print(classification_report(true_labels, y_pred_best, target_names=[\"Fake News\", \"True News\"]))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(true_labels, y_pred_best))\n",
        "\n",
        "report_best = classification_report(true_labels, y_pred_best, target_names=[\"Fake News\", \"True News\"], output_dict=True)\n",
        "df_best = pd.DataFrame(report_best).transpose()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTlMot0Fg1O6",
        "outputId": "00854e0d-a542-466d-a1a5-9286f2995376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Param√®tres de notre meilleur mod√®le trouv√© par random grid search :\n",
            "{'memory': None, 'steps': [('cleaner', FunctionTransformer(func=<function apply_clean_text_no_numbers at 0x7a2641e53a60>)), ('tfidf', TfidfVectorizer(max_features=5000)), ('classifier', LogisticRegression(C=10, max_iter=1000, random_state=42))], 'transform_input': None, 'verbose': False, 'cleaner': FunctionTransformer(func=<function apply_clean_text_no_numbers at 0x7a2641e53a60>), 'tfidf': TfidfVectorizer(max_features=5000), 'classifier': LogisticRegression(C=10, max_iter=1000, random_state=42), 'cleaner__accept_sparse': False, 'cleaner__check_inverse': True, 'cleaner__feature_names_out': None, 'cleaner__func': <function apply_clean_text_no_numbers at 0x7a2641e53a60>, 'cleaner__inv_kw_args': None, 'cleaner__inverse_func': None, 'cleaner__kw_args': None, 'cleaner__validate': False, 'tfidf__analyzer': 'word', 'tfidf__binary': False, 'tfidf__decode_error': 'strict', 'tfidf__dtype': <class 'numpy.float64'>, 'tfidf__encoding': 'utf-8', 'tfidf__input': 'content', 'tfidf__lowercase': True, 'tfidf__max_df': 1.0, 'tfidf__max_features': 5000, 'tfidf__min_df': 1, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__preprocessor': None, 'tfidf__smooth_idf': True, 'tfidf__stop_words': None, 'tfidf__strip_accents': None, 'tfidf__sublinear_tf': False, 'tfidf__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'tfidf__tokenizer': None, 'tfidf__use_idf': True, 'tfidf__vocabulary': None, 'classifier__C': 10, 'classifier__class_weight': None, 'classifier__dual': False, 'classifier__fit_intercept': True, 'classifier__intercept_scaling': 1, 'classifier__l1_ratio': None, 'classifier__max_iter': 1000, 'classifier__multi_class': 'deprecated', 'classifier__n_jobs': None, 'classifier__penalty': 'l2', 'classifier__random_state': 42, 'classifier__solver': 'lbfgs', 'classifier__tol': 0.0001, 'classifier__verbose': 0, 'classifier__warm_start': False}\n",
            "\n",
            "L'article 1 est faux\n",
            "Probabilit√© 'Faux article': 66.63%\n",
            "Probabilit√© 'Vrai article': 33.37%\n",
            "Pr√©diction finale: Faux article\n",
            "\n",
            "L'article 2 est faux\n",
            "Probabilit√© 'Faux article': 12.21%\n",
            "Probabilit√© 'Vrai article': 87.79%\n",
            "Pr√©diction finale: Vrai article\n",
            "\n",
            "L'article 3 est faux\n",
            "Probabilit√© 'Faux article': 80.94%\n",
            "Probabilit√© 'Vrai article': 19.06%\n",
            "Pr√©diction finale: Faux article\n",
            "\n",
            "L'article 4 est faux\n",
            "Probabilit√© 'Faux article': 45.57%\n",
            "Probabilit√© 'Vrai article': 54.43%\n",
            "Pr√©diction finale: Vrai article\n",
            "\n",
            "L'article 5 est faux\n",
            "Probabilit√© 'Faux article': 18.62%\n",
            "Probabilit√© 'Vrai article': 81.38%\n",
            "Pr√©diction finale: Vrai article\n",
            "\n",
            "L'article 6 est vrai\n",
            "Probabilit√© 'Faux article': 32.33%\n",
            "Probabilit√© 'Vrai article': 67.67%\n",
            "Pr√©diction finale: Vrai article\n",
            "\n",
            "L'article 7 est vrai\n",
            "Probabilit√© 'Faux article': 0.06%\n",
            "Probabilit√© 'Vrai article': 99.94%\n",
            "Pr√©diction finale: Vrai article\n",
            "\n",
            "L'article 8 est vrai\n",
            "Probabilit√© 'Faux article': 2.17%\n",
            "Probabilit√© 'Vrai article': 97.83%\n",
            "Pr√©diction finale: Vrai article\n",
            "\n",
            "L'article 9 est vrai\n",
            "Probabilit√© 'Faux article': 26.63%\n",
            "Probabilit√© 'Vrai article': 73.37%\n",
            "Pr√©diction finale: Vrai article\n",
            "\n",
            "L'article 10 est vrai\n",
            "Probabilit√© 'Faux article': 32.74%\n",
            "Probabilit√© 'Vrai article': 67.26%\n",
            "Pr√©diction finale: Vrai article\n",
            "\n",
            "-- Performance du mod√®le sur les nouveaux articles\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Fake News       1.00      0.40      0.57         5\n",
            "   True News       0.62      1.00      0.77         5\n",
            "\n",
            "    accuracy                           0.70        10\n",
            "   macro avg       0.81      0.70      0.67        10\n",
            "weighted avg       0.81      0.70      0.67        10\n",
            "\n",
            "Confusion Matrix:\n",
            "[[2 3]\n",
            " [0 5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notre meilleur pipeline, obtenu via un random grid search, repose sur une s√©quence en trois √©tapes :\n",
        "\n",
        "- Nettoyage des textes via la fonction apply_clean_text_no_numbers, supprimant les chiffres et appliquant une normalisation de base. On note ici que random search a s√©lectionn√© le nettoyage sans les nombres sans doute car ceux-ci n'apportaient pas d'information pertinente pour les pr√©dictions.\n",
        "\n",
        "- Vectorisation TF-IDF limit√©e √† un vocabulaire de 5 000 mots les plus fr√©quents, avec normalisation L2 et prise en compte des unigrammes seulement (mot unique).\n",
        "\n",
        "- Classification par r√©gression logistique (LogisticRegression) avec un param√®tre de r√©gularisation C = 10 et un maximum de 1 000 it√©rations, garantissant une convergence stable.\n",
        "\n",
        "Il est probable que la poursuite de l‚Äôexploration des hyperparam√®tres (par exemple en incluant des bigrammes, en √©largissant le vocabulaire ou en testant des mod√®les plus complexes comme LinearSVC) aurait pu produire un best predictor diff√©rent, potentiellement capable de capturer davantage de complexit√© dans les donn√©es. Toutefois, cela aurait pu se traduire par une meilleure performance sur le jeu d‚Äôentra√Ænement au d√©triment de la performance finale sur notre jeu d‚Äô√©valuation externe (df_fake_true). Le mod√®le s√©lectionn√© constitue donc un compromis pertinent entre performance sur les donn√©es d‚Äôentra√Ænement et g√©n√©ralisation.\n",
        "\n",
        "Les r√©sultats de notre √©valuation sur nos 10 articles sont les suivants :\n",
        "\n",
        "Articles faux : sur 5 cas, seuls 2 sont correctement d√©tect√©s, soit un recall de 40 %.\n",
        "\n",
        "Articles vrais : sur 5 cas, tous sont correctement d√©tect√©s (recall de 100 %), mais avec une pr√©cision de 62 %, ce qui indique que le mod√®le classe parfois des articles faux comme vrais.\n",
        "\n",
        "Le classification report confirme ces tendances :\n",
        "\n",
        "Fake News ‚Üí pr√©cision : 1.00, recall : 0.40, f1-score : 0.57\n",
        "\n",
        "True News ‚Üí pr√©cision : 0.62, recall : 1.00, f1-score : 0.77\n",
        "\n",
        "Accuracy globale : 70 %\n",
        "\n",
        "Moyenne pond√©r√©e du f1-score : 0.67\n",
        "\n",
        "Interpr√©tation\n",
        "Ces r√©sultats r√©v√®lent que le mod√®le a nettement progress√© dans la d√©tection des fake news par rapport √† notre version brute initiale, qui affichait un recall nul pour cette classe. Notre pipeline optimis√©, combin√© √† un meilleur nettoyage cibl√©, a permis au mod√®le de surmonter en partie son biais initial en faveur de la classe ‚Äúvrai‚Äù.\n",
        "\n",
        "Cependant, un d√©s√©quilibre persiste : la sensibilit√© (recall) pour les fake news reste inf√©rieure √† celle pour les vrais articles (40 % contre 100 %). En d‚Äôautres termes, le mod√®le reste plus performant pour identifier les articles authentiques que pour rep√©rer les faux.\n",
        "\n",
        "Si l‚Äôon compare avec les performances initiales, la diff√©rence est notable :\n",
        "\n",
        "Avant optimisation : le mod√®le ne d√©tectait aucune fake news (f1-score = 0 pour cette classe), avec une tendance forte √† pr√©dire ‚Äúvrai‚Äù dans la majorit√© des cas.\n",
        "\n",
        "Apr√®s optimisation : la capacit√© √† identifier des fake news existe d√©sormais, mais la pr√©cision √©lev√©e pour cette classe (1.00) s‚Äôexplique par le faible nombre de pr√©dictions ‚Äúfaux‚Äù effectu√©es. Le mod√®le ne se trompe jamais sur nos 10 textes lorsqu'il pr√©dit une fake news, car ses pr√©dictions sont rares.\n",
        "\n",
        "En pratique, ce comportement traduit un mod√®le prudent dans la classification en ‚Äúfaux‚Äù : il ne l‚Äôattribue que lorsqu‚Äôil est tr√®s confiant, ce qui √©vite les faux positifs mais entra√Æne un nombre important de faux n√©gatifs (fake news non d√©tect√©es).\n",
        "\n",
        "Il existerait plusieurs mani√®re d'am√©liorer nos r√©sultats.\n",
        "- La mani√®re sans doute la plus simple consisterait √† d√©placer le seuil de d√©cision pour forcer le mod√®le √† pr√©dire plus souvent des fake news, quitte √† perdre l√©g√®rement en pr√©cision.\n",
        "- Augmenter la diversit√© du training set : Ce serait tr√®s long et fastidieux, mais robuste. Il faudrait enrichir le dataset de centaines, voire de milliers d'articles sur lesquels on veut am√©liorer les pr√©dictions de notre mod√®le.\n",
        "- Affiner les param√®tres et revoir le pr√©traitement. On pourrait encore jouer avec les param√®tres pour trouver une configuration plus efficace adapt√©e non pas pour WELFake, mais pour notre √©valuation finale. Or comme nous l'avons vu, ce serait de l'overfitting. Nous pourrions aussi tenter une lemmatisation plus fine du texte.\n",
        "\n",
        "Seulement, notre but n'est pas de gonfler artificiellement les chiffres de notre mod√®le pour obtenir une performance fallacieuse. Nous cherchons √† construire un d√©tecteur de fake news efficace, tout en plongeant dans le fonctionnement des diff√©rents mod√®les et techniques possibles.\n",
        "Notre d√©tecteur de fake news sera op√©rationnel lorsque nous aurons trouv√© la configuration ad√©quate et que nous l'aurons √©valu√© de mani√®re rigoureuse sur un dataset de taille et de diversit√© suffisante.\n",
        "Tout comme nous avons ajust√© au fur et √† mesure et exp√©riment√© de nombreuses possibilit√©es, notre futur mod√®le sera lui aussi amen√© √† √©voluer.\n",
        "\n",
        "Pour cloturer ce p√©riple √† travers le traitement de texte en machine learning, terminons ce notebook avec l'application d'une m√©thode pour plonger encore plus loin dans notre algorithme de r√©gression lin√©aire. Cette derni√®re section qui se concentre plus sur l'√©thique et l'ajout de d√©tails didactiques est optionnelle. Le notebook que vous venez de parcourir est suffisant pour vous donner un premier aper√ßut de la construction d'un mod√®le de machine learning."
      ],
      "metadata": {
        "id": "J3mBFIPwlCl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = [\"precision\", \"recall\", \"f1-score\"]\n",
        "\n",
        "df_compare = pd.DataFrame({\n",
        "    \"Mod√®le brut\": df_brut.loc[\"weighted avg\", metrics],\n",
        "    \"Best pipeline\": df_best.loc[\"weighted avg\", metrics]\n",
        "})\n",
        "\n",
        "df_compare.plot(kind=\"bar\", figsize=(8,5))\n",
        "plt.title(\"Comparaison des performances globales\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.ylim(0, 1)\n",
        "plt.xticks(rotation=0)\n",
        "plt.legend(title=\"Mod√®le\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "U-QEQbxUPZip",
        "outputId": "0c3864b6-e708-46d7-f3d6-498f5d82f4c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En bonus, voici un graphique comparant les performances du mod√®le brut vs am√©lior√©. Ces mesures repr√©sentent la capacit√© de notre mod√®le √† g√©n√©raliser sur de nouveaux textes. Notre F1-score n'est toujours pas id√©al, mais nous avons vu comment am√©liorer la g√©n√©ralisabilit√© en quelques √©tapes simples, en veillant toujours √† ne pas tomber dans le pi√®ge du surapprentissage sur le jeu d'entra√Ænement, puis en modifiant les hyperparam√®tres pour trouver un mod√®le convenable. De plus, nous avons retir√© les mots les plus pr√©dictifs pour √©viter le probl√®me de data leakage.\n",
        "\n",
        "Ce mod√®le prototypique obtient d√©j√† des r√©sulats satisfaisants, mais les prochaines fois, nous d√©finirons clairement la vis√©e de notre projet *D√©tecteur de Fake News*, et nous t√¢cherons de le rendre op√©rationnel."
      ],
      "metadata": {
        "id": "bU52IMTrwdNx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#IV. M√©thode LIME appliqu√©e au mod√®le de r√©gression logistique"
      ],
      "metadata": {
        "id": "3Lyf6tIYMr96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%script echo skip\n",
        "\n",
        "logistic_regression_pipeline = Pipeline([\n",
        "    (\"cleaner\", text_cleaning_transformer),\n",
        "    (\"tfidf\", TfidfVectorizer(max_features=10000, ngram_range=(1,2))),\n",
        "    (\"classifier\", LogisticRegression(C=0.1, max_iter=1000, random_state=random_state, solver=\"liblinear\"))\n",
        "])\n",
        "\n",
        "print(\"\\n---Entrainement du mod√®le Logistic Regression---\")\n",
        "logistic_regression_pipeline.fit(X_train, y_train)\n",
        "print(\"Mod√®le Logistic Regression entra√Æn√©\")\n",
        "\n",
        "def predict_proba_for_lime(texts):\n",
        "  return logistic_regression_pipeline.predict_proba(texts)\n",
        "\n",
        "class_names = ['Fake News', 'True News']\n",
        "\n",
        "explainer_lime = lime.lime_text.LimeTextExplainer(\n",
        "    kernel_width=0.75,\n",
        "    feature_selection=\"auto\",\n",
        "    class_names=class_names,\n",
        "    verbose=True,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "for i, article_text in enumerate(texts_to_predict):\n",
        "  proba_fake = logistic_regression_pipeline.predict_proba([article_text])[0][0] * 100\n",
        "  proba_true = logistic_regression_pipeline.predict_proba([article_text])[0][1] * 100\n",
        "  predicted_class_index = logistic_regression_pipeline.predict([article_text])[0]\n",
        "  predicted_veracity = class_names[predicted_class_index]\n",
        "\n",
        "  print(f\"\\nArticle {i+1} :\")\n",
        "  print(f\"Probabilit√© '{class_names[0]}': {proba_fake:.2f}%\")\n",
        "  print(f\"Probabilit√© '{class_names[1]}': {proba_true:.2f}%\")\n",
        "  print(f\"Pr√©diction finale: {predicted_veracity}\")\n",
        "\n",
        "\n",
        "  print(f\"\\n Explication LIME pour l'article {i+1} (Pr√©dit: {predicted_veracity}:)\")\n",
        "\n",
        "  exp_lime = explainer_lime.explain_instance(\n",
        "      article_text,\n",
        "      predict_proba_for_lime,\n",
        "      num_features=10,\n",
        "      num_samples=2000,\n",
        "  )\n",
        "\n",
        "  print(\"Mots les plus influents et leurs poids\")\n",
        "  for word, weight in exp_lime.as_list():\n",
        "    print(f\" -{word}: {weight:.4f}\")\n",
        "\n",
        "  print(\"\\nVisualisation HTML LIME:\")\n",
        "  exp_lime.show_in_notebook(text=True)\n",
        "  print(\"-\" * 80)"
      ],
      "metadata": {
        "id": "UxbNyl_-O9yJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "##1 : Fonctionnement et utilit√© de LIME\n",
        "Lime est un outil d'interpr√©tation permettant d'expliquer les r√©sultats d'un mod√®le de mani√®re locale.\n",
        "\n",
        "La m√©thode LIME est dite locale car elle se concentre sur un seul exemple (un texte) √† la fois.\n",
        "\n",
        "LIME fonctionne en cr√©ant de multiples variations du texte original. Dans chaque variation il supprime al√©atoirement certains mots et demande au mod√®le (r√©gression logistique ici) de faire une pr√©diction sur chaque variation. En observant comment les pr√©dictions changent en fonction des mots supprim√©s, LIME peut en d√©duire pour chaque texte quels mots sont les plus influents pour la d√©cision du mod√®le.\n",
        "\n",
        "Cas typiques o√π LIME est utile :\n",
        "- Mod√®le sans interpr√©tabilit√© native (deep learning, gradient boosting sans acc√®s direct aux poids, mod√®les import√©s).\n",
        "- V√©rifier la coh√©rence des d√©cisions cas par cas (ex : v√©rifier qu‚Äôun diagnostic m√©dical ne repose pas sur un artefact du texte ou de l‚Äôimage).\n",
        "- Debug : comprendre pourquoi un mod√®le donne un r√©sultat inattendu sur un exemple particulier.\n",
        "\n",
        "Il faut distinguer les r√©sultats de LIME qui sont locaux, pour chaque article ind√©pendants, de nos graphiques plus haut ou de nos mits les plus pr√©dictifs qui √©taient globaux.\n",
        "\n",
        "\n",
        "La force de LIME, √† savoir sa simplicit√©, est aussi une de ses principales faiblesses. Comme la g√©n√©ration des variations est **al√©atoire** l'interpr√©tation obtenue peut changer √† chaque ex√©cution du code. Si le r√©sultat obtenu n'est pas reproductible, celui-ci ne vaut pas grand chose en machine learning (ou en sciences plus g√©n√©ralement). Fort heureusement la mani√®re dont fonctionne l'al√©atoire dans les ordinateurs nous permet de contourner ce probl√®me. Les ordinateurs ne pouvant pas g√©n√©rer de vrai hasard, on parle plut√¥t de pseudo-al√©atoire. Le syst√®me se repose sur un nombre de d√©part, par exemple l'heure exacte de l'ex√©cution du code en nanosecondes, puis un algorithme (PRNG) transforme ces nombres en une nouvelle s√©quence qui sera consid√©r√©e comme notre s√©quence al√©atoire. Le nombre de d√©part est appel√© \"seed\" (graine en fran√ßais), et si l'on fixe ce nombre, l'algorithme PRNG g√©n√®rera toujours le m√™me nombre en sortie. La ligne *random_state=42* remplit cette fonction et sert √† fixer la seed, 42 par convention.\n",
        "\n",
        "**En image :** Voyez le random_state comme les ingr√©dients et les quantit√©s de votre g√¢teau, et l'algorithme PRNG comme la recette. Si vous utilisez toujours les m√™mes ingr√©dients, vous obtiendrez toujours le m√™me g√¢teau. Pour s'assurer d'avoir des r√©sultats reproductibles, il est donc essentiel de fixer le seed pour que le \"g√¢teau\" de votre interpr√©tation ne change jamais.\n",
        "\n",
        "N'importe quel nombre peut √™tre utilis√© comme seed, mais il est imp√©ratif qu'il reste le m√™me d'une ex√©cution √† l'autre pour garantir que l'algorithme PRNG g√©n√®re toujours la m√™me s√©quence pseudo-al√©atoire, et que vos r√©sultats soient reproductibles.\n",
        "\n",
        "**Premier texte analys√© par LIME :**\n",
        "\n",
        "Le mod√®le pr√©dit qu'il s'agit d'une fake news avec 65.57% de probabilit√©. Les 5 premiers articles √©tant faux et les 5 derniers vrais, le mod√®le de r√©gression logistique a vu juste pour ce premier exemple.\n",
        "LIME t√¢che ensuite d'expliquer pourquoi. Il affiche sur le graphique les 10 mots les plus influents (num_features) pour la d√©cision du mod√®le. Les mots surlign√©s en bleu sont les mots pr√©dicteurs de fake news pour le mod√®le (pour ce texte seulement) et les mots en orange les pr√©dicteurs de vrais articles.\n",
        "\n",
        "Cette visualisation est tr√®s utile pour tenter d'expliquer le fonctionnement d'un mod√®le et comprendre comment il a prit sa d√©cision. Voyons un autre exemple pour comprendre plus en profondeur tout ceci.\n",
        "\n",
        "**Texte deux analys√© par LIME :**\n",
        "\n",
        "On remarque que le mod√®le s'est tromp√© ici, il classe avec 37.03% de probabilit√© l'article satirique comme vrai. Nous verrons plus loin les raisons possibles de cette erreur pour notre mod√®le de r√©gression.\n",
        "Une mani√®re de modifier l'output du mod√®le serait d'ajouter les mots fortement associ√©s √† la pr√©diction \"True news\" √† la liste de stop_words. Ainsi, en ignorant ces mots le mod√®le deviendrait \"biais√©\" vers la r√©ponse que nous souhaitons : √† savoir classer cet article comme faux.\n",
        "L'image suivante pr√©sente le r√©sultat de ce test, si vous voulez l'ex√©cuter vous-m√™me vous pouvez ajouter les mots \"revelations\", \"targeted\", \"real\", \"comes\" et \"sexual\" √† la liste de stop_words, avant de relancer le code. Pensez √† les retirer de la liste une fois le test effectu√© !\n",
        "Cette manipulation un peu barbare ne sert qu'√† illustrer la mani√®re dont fonctionne LIME. On voit bien qu'en ignorant deux mots associ√©s aux vrais articles, les probabilit√©s pr√©dites par le mod√®le de r√©gression logistique √©voluent (passant de 37.03% de probabilit√© de fake news √† 41.49%), montrant ainsi que les mots mis en avant par LIME ont effectivement un poids cons√©quent dans la d√©cision du mod√®le.\n",
        "\n",
        "\n",
        "NB : Modifier de la sorte les param√®tres est une forme d'outcome engineering. On modifie le mod√®le pour le forcer √† donner la r√©ponse qui nous int√©resse localement (les autres pr√©dictions ne sont pas ou peu affect√©es). Cette pratique, en plus d'√™tre malhon√™te, n'am√©liore pas r√©ellement le mod√®le.\n",
        "\n",
        "## 2 : Comment intepr√©ter nos r√©sultats ?\n",
        "\n",
        "Notre mod√®le semble √™tre bon pour d√©tecter les textes utilisant un langage scientifique ou acad√©mique en les classant presque √† chaque fois comme vrais. Mais cette sp√©cialisation peut jouer contre lui.\n",
        "\n",
        "**Cinqui√®me texte :**\n",
        "\n",
        "Le 5√®me texte est un article climato-sceptique. On constate que le mod√®le √©choue √† le classifier comme fake news. En effet, le mod√®le semble tr√®s efficace pour classer les textes en fonction de leur style d'√©criture, mais il lui est plus difficile de rep√©rer le sens et le contexte dans lequel ces mots sont employ√©s. Si un article qui utilise un langage scientifique et soign√© va √† l'encontre du consensus scientifique, alors le mod√®le risque de se tromper, comme c'est le cas pour l'article 5. Il est crucial de retenir que le mod√®le n'a pas de compr√©hension r√©elle des textes, il ne *sait* pas que le r√©chauffement climatique est r√©el. Il ne peut que pr√©dire si un texte est susceptible d'√™tre vrai ou non en fonction des mots qu'il a vu lors de l'entra√Ænement. Deux choses √† noter ici :\n",
        "- Il serait possible de pallier cette lacune en entra√Ænant le mod√®le sur les types de textes sur lesquels il √©choue. Par exemple s'il √©choue r√©guli√®rement sur les fake news pseudoscientifiques, on pourrait lui donner plus de textes de ce type lors de la phase d'entra√Ænement. M√™me sans compr√©hension fine du langage, ses performances augmenteraient tr√®s probablement. Par exemple, il pourrait apprendre lors de son entra√Ænement certains mots ou bigrammes (paire de mots) associ√©s √† un type de label ou l'autre. En vulgarisant, on peut imaginer que \"warmer before\" serait associ√© aux fake news tandis que \"temperatures rise\" serait associ√© aux vrais articles. Si le mod√®le retrouve ces termes ou d'autres similaires dans les textes qu'il doit classer, il saurait mieux se d√©brouiller.\n",
        "- Un autre aspect √† consid√©rer r√©side dans la nature m√™me difficile et ambig√ºe de la t√¢che de d√©tection. Qu'est ce qu'une fake news exactement ? Selon wikip√©dia les fake news \"*sont des nouvelles mensong√®res diffus√©es dans le but de manipuler ou de tromper le public*\". C'est en fonction de cette d√©finition que nous jugerons si notre mod√®le est performant ou non. Mais d'autres pourraient estimer qu'une fake news est une information fausse peu importe l'intention derri√®re. Par exemple en 1999 beaucoup de m√©dias ont transmis au grand public la peur des OGM, en se basant sur une √©tude fautive. L'intention n'√©tait pas la d√©sinformation, mais l'information √©tait pourtant fausse. Fake news ou non ?\n",
        "[Un des articles en question](https://www.theguardian.com/uk/1999/feb/12/4).\n",
        "\n",
        "En machine learning, on utilise parfois la performance humaine (Human Level Performance) pour situer l'efficacit√© de notre algorithme. Il est fortement probable qu'en fournissant la liste d'articles du dataset df_fake_true, la majorit√© des gens n'obtiennent pas une accuracy de 100%. L'algorithme peut ainsi √™tre consid√©r√© comme suffisamment bon en atteignant/d√©passant la performance du meilleur humain ou celle d'un groupe d'experts. On peut aussi accepter une performance inf√©rieure si l'algorithme s'av√®re utile. Par exemple m√™me si un groupe d'experts obtient une accuracy de 98%, un mod√®le avec seulement 92% pourrait trouver son utilit√© aupr√®s du public si la performance de ce dernier atteint √† peine les 70%.\n",
        "\n",
        "#3 : Quelles limites LIME met en lumi√®re ?\n",
        "\n",
        "##L'importance de"
      ],
      "metadata": {
        "id": "3H6BeLmufamR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DJ36DLCyiyOX"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMVGZIraWEFjrabIEoJMCtX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}